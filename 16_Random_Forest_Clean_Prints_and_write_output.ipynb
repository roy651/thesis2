{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# IMPORTS\n",
    "# Pandas is used for data manipulation\n",
    "import pandas as pd\n",
    "# Use numpy to convert to arrays\n",
    "import numpy as np\n",
    "# Using Skicit-learn to split data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Import tools needed for visualization\n",
    "from sklearn.tree import export_graphviz\n",
    "import pydot\n",
    "# Import the model we are using\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "# Utility to store and load model from disk\n",
    "from sklearn.externals import joblib\n",
    "# write csv files\n",
    "import csv\n",
    "# Import charting lib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# UTIL\n",
    "def test_model(forest_model, test_features, test_labels):\n",
    "    # Use the forest's predict method on the test data\n",
    "    predictions = np.round(forest_model.predict(test_features))\n",
    "\n",
    "    # Calculate the absolute errors\n",
    "    errors = abs(predictions - test_labels)\n",
    "\n",
    "    # Print out the mean absolute error (mae)\n",
    "    print('Mean Absolute Error:', round(np.mean(errors), 2))\n",
    "\n",
    "    # Calculate mean absolute percentage error (MAPE)\n",
    "    mape = 100 * (errors / test_labels)\n",
    "\n",
    "    # Calculate and display accuracy\n",
    "    accuracy = 100 - np.mean(mape)\n",
    "    print('Accuracy:', round(accuracy, 2), '%.')\n",
    "\n",
    "    # Pull out one tree from the forest\n",
    "    #tree = forest_model.estimators_[5]\n",
    "    # print('The depth of this tree is:', tree.tree_.max_depth)\n",
    "\n",
    "    total_trues = sum(x == 2 for x in test_labels)\n",
    "    total_predictions = sum(x == 2 for x in predictions)\n",
    "    total_errors = sum(x == 1 for x in errors)\n",
    "    print('Total Samples:', len(test_labels))\n",
    "    print('Total Trues:', total_trues)\n",
    "    print('Total Predictions:', total_predictions)\n",
    "    print('Total Errors:', total_errors)\n",
    "\n",
    "    false_positive = sum(predict > label for predict, label in zip(predictions, test_labels))\n",
    "    false_negative = sum(predict < label for predict, label in zip(predictions, test_labels))\n",
    "    true_positive = total_predictions - false_positive\n",
    "    print('false_positive:', false_positive)\n",
    "    print('false_negative:', false_negative)\n",
    "    print('true_positive:', true_positive)\n",
    "    \n",
    "    print('>>>>>>>>>>>>>>>>>>>>')\n",
    "    for index, value in enumerate(zip(predictions, test_labels)):\n",
    "        if value[0] < value[1]:\n",
    "            print(test_features_[index,0])\n",
    "    print('>>>>>>>>>>>>>>>>>>>>')\n",
    "    \n",
    "    \n",
    "    precision = true_positive / total_predictions\n",
    "    recall = true_positive / (true_positive + false_negative)\n",
    "    print('precision:', precision)\n",
    "    print('recall:', recall)\n",
    "    return precision, recall\n",
    "\n",
    "def draw_tree(forest_model, test_features, test_labels): \n",
    "    importances = forest_model.feature_importances_\n",
    "    std = np.std([tree.feature_importances_ for tree in forest_model.estimators_],\n",
    "                 axis=0)\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "\n",
    "    # Print the feature ranking\n",
    "    print(\"Feature ranking:\")\n",
    "\n",
    "    for f in range(test_features.shape[1]):\n",
    "        print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))\n",
    "\n",
    "    # Plot the feature importances of the forest\n",
    "    plt.figure()\n",
    "    plt.title(\"Feature importances\")\n",
    "    plt.bar(range(test_features.shape[1]), importances[indices],\n",
    "           color=\"r\", yerr=std[indices], align=\"center\")\n",
    "    plt.xticks(range(test_features.shape[1]), indices)\n",
    "    plt.xlim([-1, test_features.shape[1]])\n",
    "    plt.show()    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fragmanetAndSide',\n",
       " 'fragmentTotal',\n",
       " 'fragmentVote',\n",
       " 'devideVoteByTotal',\n",
       " 'fragmentAndSideVote',\n",
       " 'devideSideVoteBySideTotal',\n",
       " 'fragmentAndSideTrendVote',\n",
       " 'devideSideTrendVoteBySideTotal',\n",
       " 'fragmentAndSideTrendVoteStrict',\n",
       " 'devideSideTrendVoteStrictBySideTotal',\n",
       " 'fragmentAndSideTrendVoteSync',\n",
       " 'devideSideTrendVoteSyncBySideTotal']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare the source data\n",
    "features = pd.read_csv('20181007_072858_votes_cubes_match_synt_75.csv')\n",
    "\n",
    "# Remove the irrelevant texts from the features\n",
    "# axis 1 refers to the columns\n",
    "# features = features.drop('fragmanetAndSide', axis = 1)\n",
    "features = features.drop('fragment', axis = 1)\n",
    "features = features.drop('fragmentAndSideTotal', axis = 1)\n",
    "features = features.drop('fragmentAndSideTrend', axis = 1)\n",
    "features = features.drop('fragmentAndSideCubes', axis = 1)\n",
    "features = features.drop('fragmentAndSideDrawRect', axis = 1)\n",
    "features = features.drop('fragmentAndSideMatchPoint', axis = 1)\n",
    "features = features.drop('origCoordinates', axis = 1)\n",
    "features = features.drop(\"firstFileName\", axis = 1)\n",
    "features = features.drop(\"firstCroppedWidth\", axis = 1)\n",
    "features = features.drop(\"firstOffsetX\", axis = 1)\n",
    "features = features.drop(\"firstOffsetY\", axis = 1)\n",
    "features = features.drop(\"firstHorizontalFlip\", axis = 1)\n",
    "features = features.drop(\"secondFileName\", axis = 1)\n",
    "features = features.drop(\"secondCroppedWidth\", axis = 1)\n",
    "features = features.drop(\"secondOffsetX\", axis = 1)\n",
    "features = features.drop(\"secondOffsetY\", axis = 1)\n",
    "features = features.drop(\"secondHorizontalFlip\", axis = 1)\n",
    "\n",
    "# features = features.drop('fragmentTotal', axis = 1)\n",
    "# features = features.drop('fragmentAndSideVote', axis = 1)\n",
    "# features = features.drop('fragmentAndSideTrendVote', axis = 1)\n",
    "\n",
    "# One-hot encode categorical features\n",
    "#features = pd.get_dummies(features)\n",
    "\n",
    "# Labels are the values we want to predict\n",
    "labels = np.array(features['class'])\n",
    "labels = labels + 1\n",
    "\n",
    "# Remove the labels from the features\n",
    "# axis 1 refers to the columns\n",
    "features= features.drop('class', axis = 1)\n",
    "\n",
    "# Saving feature names for later use\n",
    "feature_list = list(features.columns)\n",
    "\n",
    "# Convert to numpy array\n",
    "features = np.array(features)\n",
    "\n",
    "feature_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.02\n",
      "Accuracy: 98.89 %.\n",
      "Total Samples: 812\n",
      "Total Trues: 29\n",
      "Total Predictions: 20\n",
      "Total Errors: 15\n",
      "false_positive: 3\n",
      "false_negative: 12\n",
      "true_positive: 17\n",
      ">>>>>>>>>>>>>>>>>>>>\n",
      "PX303Fg006_6X3_0X2_1_PX303Fg006_6X3_1X2_0\n",
      "PX303Fg006_4X3_0X0_1_PX303Fg006_4X3_1X0_0\n",
      "PX303Fg006_6X3_0X1_1_PX303Fg006_6X3_1X1_0\n",
      "PX303Fg006_7X3_3X2_1_PX303Fg006_7X3_4X2_0\n",
      "PX303Fg006_6X3_2X2_1_PX303Fg006_6X3_3X2_0\n",
      "PX303Fg006_4X3_0X1_1_PX303Fg006_4X3_1X1_0\n",
      "PX303Fg006_6X3_0X0_1_PX303Fg006_6X3_1X0_0\n",
      "PX303Fg006_7X3_2X1_1_PX303Fg006_7X3_3X1_0\n",
      "PX303Fg006_5X3_1X1_1_PX303Fg006_5X3_2X1_0\n",
      "PX303Fg006_4X2_1X0_1_PX303Fg006_4X2_2X0_0\n",
      "PX303Fg006_7X3_1X2_1_PX303Fg006_7X3_2X2_0\n",
      "PX303Fg006_6X2_0X0_1_PX303Fg006_6X2_1X0_0\n",
      ">>>>>>>>>>>>>>>>>>>>\n",
      "precision: 0.85\n",
      "recall: 0.586206896552\n",
      "Feature ranking:\n",
      "1. feature 3 (0.227869)\n",
      "2. feature 5 (0.188040)\n",
      "3. feature 0 (0.097849)\n",
      "4. feature 1 (0.073030)\n",
      "5. feature 7 (0.067134)\n",
      "6. feature 9 (0.065809)\n",
      "7. feature 6 (0.065473)\n",
      "8. feature 4 (0.061075)\n",
      "9. feature 8 (0.059119)\n",
      "10. feature 10 (0.056381)\n",
      "11. feature 2 (0.038220)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAEKCAYAAAD6q1UVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nooWS/CMiWijJPyKihZL8IyJa6P8DNDnTkGgziloAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x113ecc748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Random Forest 1st model\n",
    "# Split the data into training and testing sets\n",
    "train_features_, test_features_, train_labels, test_labels = train_test_split(features, labels, test_size = 0.3)\n",
    "\n",
    "train_features = train_features_[:,1:] # remove the fragmentAndSide column which is the label\n",
    "test_features = test_features_[:,1:] # remove the fragmentAndSide column which is the label\n",
    "\n",
    "# Instantiate model \n",
    "rf = RandomForestClassifier(n_estimators= 1000, random_state=42, n_jobs=-1)\n",
    "\n",
    "rf.fit(train_features, train_labels)\n",
    "\n",
    "test_model(rf, test_features, test_labels)\n",
    "draw_tree(rf, test_features, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.02\n",
      "Accuracy: 98.46 %.\n",
      "Total Samples: 812\n",
      "Total Trues: 29\n",
      "Total Predictions: 25\n",
      "Total Errors: 18\n",
      "false_positive: 7\n",
      "false_negative: 11\n",
      "true_positive: 18\n",
      ">>>>>>>>>>>>>>>>>>>>\n",
      "PX303Fg006_6X3_0X2_1_PX303Fg006_6X3_1X2_0\n",
      "PX303Fg006_4X3_0X0_1_PX303Fg006_4X3_1X0_0\n",
      "PX303Fg006_6X3_0X1_1_PX303Fg006_6X3_1X1_0\n",
      "PX303Fg006_6X3_2X2_1_PX303Fg006_6X3_3X2_0\n",
      "PX303Fg006_4X3_0X1_1_PX303Fg006_4X3_1X1_0\n",
      "PX303Fg006_6X3_0X0_1_PX303Fg006_6X3_1X0_0\n",
      "PX303Fg006_7X3_2X1_1_PX303Fg006_7X3_3X1_0\n",
      "PX303Fg006_6X2_3X0_1_PX303Fg006_6X2_4X0_0\n",
      "PX303Fg006_5X3_1X1_1_PX303Fg006_5X3_2X1_0\n",
      "PX303Fg006_7X3_1X2_1_PX303Fg006_7X3_2X2_0\n",
      "PX303Fg006_7X3_5X0_1_PX303Fg006_7X3_6X0_0\n",
      ">>>>>>>>>>>>>>>>>>>>\n",
      "precision: 0.72\n",
      "recall: 0.620689655172\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.71999999999999997, 0.62068965517241381)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# AdaBoostClassifier model \n",
    "ab = AdaBoostClassifier(n_estimators= 1000, learning_rate=0.8)\n",
    "\n",
    "ab.fit(train_features, train_labels)\n",
    "\n",
    "test_model(ab, test_features, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.02\n",
      "Accuracy: 98.95 %.\n",
      "Total Samples: 812\n",
      "Total Trues: 29\n",
      "Total Predictions: 24\n",
      "Total Errors: 13\n",
      "false_positive: 4\n",
      "false_negative: 9\n",
      "true_positive: 20\n",
      ">>>>>>>>>>>>>>>>>>>>\n",
      "PX303Fg006_6X3_0X2_1_PX303Fg006_6X3_1X2_0\n",
      "PX303Fg006_4X3_0X0_1_PX303Fg006_4X3_1X0_0\n",
      "PX303Fg006_6X3_0X1_1_PX303Fg006_6X3_1X1_0\n",
      "PX303Fg006_7X3_3X2_1_PX303Fg006_7X3_4X2_0\n",
      "PX303Fg006_4X3_0X1_1_PX303Fg006_4X3_1X1_0\n",
      "PX303Fg006_6X3_0X0_1_PX303Fg006_6X3_1X0_0\n",
      "PX303Fg006_7X3_2X1_1_PX303Fg006_7X3_3X1_0\n",
      "PX303Fg006_5X3_1X1_1_PX303Fg006_5X3_2X1_0\n",
      "PX303Fg006_4X2_1X0_1_PX303Fg006_4X2_2X0_0\n",
      ">>>>>>>>>>>>>>>>>>>>\n",
      "precision: 0.833333333333\n",
      "recall: 0.689655172414\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.83333333333333337, 0.68965517241379315)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BaggingClassifier model \n",
    "bc = BaggingClassifier(n_estimators= 1000)\n",
    "\n",
    "bc.fit(train_features, train_labels)\n",
    "\n",
    "test_model(bc, test_features, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.02\n",
      "Accuracy: 99.14 %.\n",
      "Total Samples: 812\n",
      "Total Trues: 29\n",
      "Total Predictions: 18\n",
      "Total Errors: 13\n",
      "false_positive: 1\n",
      "false_negative: 12\n",
      "true_positive: 17\n",
      ">>>>>>>>>>>>>>>>>>>>\n",
      "PX303Fg006_6X3_0X2_1_PX303Fg006_6X3_1X2_0\n",
      "PX303Fg006_4X3_0X0_1_PX303Fg006_4X3_1X0_0\n",
      "PX303Fg006_6X3_0X1_1_PX303Fg006_6X3_1X1_0\n",
      "PX303Fg006_7X3_3X2_1_PX303Fg006_7X3_4X2_0\n",
      "PX303Fg006_6X3_2X0_1_PX303Fg006_6X3_3X0_0\n",
      "PX303Fg006_6X3_2X2_1_PX303Fg006_6X3_3X2_0\n",
      "PX303Fg006_4X3_0X1_1_PX303Fg006_4X3_1X1_0\n",
      "PX303Fg006_6X3_0X0_1_PX303Fg006_6X3_1X0_0\n",
      "PX303Fg006_7X3_2X2_1_PX303Fg006_7X3_3X2_0\n",
      "PX303Fg006_7X3_2X1_1_PX303Fg006_7X3_3X1_0\n",
      "PX303Fg006_5X3_1X1_1_PX303Fg006_5X3_2X1_0\n",
      "PX303Fg006_4X2_1X0_1_PX303Fg006_4X2_2X0_0\n",
      ">>>>>>>>>>>>>>>>>>>>\n",
      "precision: 0.944444444444\n",
      "recall: 0.586206896552\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.94444444444444442, 0.58620689655172409)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ExtraTreesClassifier model \n",
    "et = ExtraTreesClassifier(n_estimators= 1000)\n",
    "\n",
    "et.fit(train_features, train_labels)\n",
    "\n",
    "test_model(et, test_features, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.01\n",
      "Accuracy: 99.26 %.\n",
      "Total Samples: 812\n",
      "Total Trues: 29\n",
      "Total Predictions: 20\n",
      "Total Errors: 11\n",
      "false_positive: 1\n",
      "false_negative: 10\n",
      "true_positive: 19\n",
      ">>>>>>>>>>>>>>>>>>>>\n",
      "PX303Fg006_6X3_0X2_1_PX303Fg006_6X3_1X2_0\n",
      "PX303Fg006_4X3_0X0_1_PX303Fg006_4X3_1X0_0\n",
      "PX303Fg006_6X3_0X1_1_PX303Fg006_6X3_1X1_0\n",
      "PX303Fg006_4X3_0X1_1_PX303Fg006_4X3_1X1_0\n",
      "PX303Fg006_6X3_0X0_1_PX303Fg006_6X3_1X0_0\n",
      "PX303Fg006_7X3_2X1_1_PX303Fg006_7X3_3X1_0\n",
      "PX303Fg006_3X3_0X0_1_PX303Fg006_3X3_1X0_0\n",
      "PX303Fg006_5X3_1X1_1_PX303Fg006_5X3_2X1_0\n",
      "PX303Fg006_7X3_1X2_1_PX303Fg006_7X3_2X2_0\n",
      "PX303Fg006_7X3_5X0_1_PX303Fg006_7X3_6X0_0\n",
      ">>>>>>>>>>>>>>>>>>>>\n",
      "precision: 0.95\n",
      "recall: 0.655172413793\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.94999999999999996, 0.65517241379310343)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GradientBoostingClassifier model \n",
    "gb = GradientBoostingClassifier(n_estimators= 1000)\n",
    "\n",
    "gb.fit(train_features, train_labels)\n",
    "\n",
    "test_model(gb, test_features, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.01\n",
      "Accuracy: 99.26 %.\n",
      "Total Samples: 812\n",
      "Total Trues: 29\n",
      "Total Predictions: 20\n",
      "Total Errors: 11\n",
      "false_positive: 1\n",
      "false_negative: 10\n",
      "true_positive: 19\n",
      ">>>>>>>>>>>>>>>>>>>>\n",
      "PX303Fg006_6X3_0X2_1_PX303Fg006_6X3_1X2_0\n",
      "PX303Fg006_4X3_0X0_1_PX303Fg006_4X3_1X0_0\n",
      "PX303Fg006_6X3_0X1_1_PX303Fg006_6X3_1X1_0\n",
      "PX303Fg006_7X3_3X2_1_PX303Fg006_7X3_4X2_0\n",
      "PX303Fg006_4X3_0X1_1_PX303Fg006_4X3_1X1_0\n",
      "PX303Fg006_6X3_0X0_1_PX303Fg006_6X3_1X0_0\n",
      "PX303Fg006_7X3_2X1_1_PX303Fg006_7X3_3X1_0\n",
      "PX303Fg006_5X3_1X1_1_PX303Fg006_5X3_2X1_0\n",
      "PX303Fg006_7X3_1X2_1_PX303Fg006_7X3_2X2_0\n",
      "PX303Fg006_7X3_5X0_1_PX303Fg006_7X3_6X0_0\n",
      ">>>>>>>>>>>>>>>>>>>>\n",
      "precision: 0.95\n",
      "recall: 0.655172413793\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.94999999999999996, 0.65517241379310343)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# VotingClassifier model \n",
    "vt = VotingClassifier(estimators=[('ab', ab), ('rf', rf), ('bc', bc), ('et', et), ('gb', gb)], voting='soft', n_jobs=-1)\n",
    "\n",
    "vt.fit(train_features, train_labels)\n",
    "\n",
    "test_model(vt, test_features, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import cross_val_predict\n",
    "# from sklearn import metrics\n",
    "# predicted = cross_val_predict(rf, test_features, test_labels, cv=5)\n",
    "# metrics.accuracy_score(test_labels, np.round(predicted)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Random Forest 2nd variation of model - just for reference - not used\n",
    "rf_new = RandomForestRegressor(n_estimators = 1000, criterion = 'mse', max_depth = None, \n",
    "                               min_samples_split = 2, min_samples_leaf = 1)\n",
    "rf_new.fit(train_features, train_labels)\n",
    "\n",
    "test_model(rf_new, test_features, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Random Forest 3rd model - Limit depth of tree to 2 levels - not used\n",
    "rf_small = RandomForestRegressor(n_estimators=10, max_depth = 3, random_state=42)\n",
    "rf_small.fit(train_features, train_labels)\n",
    "\n",
    "test_model(rf_small, test_features, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "code_folding": [],
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rndFstBasic.pkl']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finally - use the 1st model and this time train on the entire set \n",
    "fit_features = features[:,1:] # remove the fragmentAndSide column which is the label\n",
    "\n",
    "rf.fit(fit_features, labels);\n",
    "\n",
    "joblib.dump(rf, 'rndFstBasic.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "code_folding": [],
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Run on the output of the voting and classify them\n",
    "# Read in data as pandas dataframe\n",
    "orig_features = pd.read_csv('20181020_212330_pairs_votes.csv') #('real_cubes_all_vote.csv')\n",
    "\n",
    "# Remove the irrelevant texts from the features\n",
    "# axis 1 refers to the columns\n",
    "features = orig_features.drop('fragmanetAndSide', axis = 1)\n",
    "features = features.drop('fragment', axis = 1)\n",
    "features = features.drop('fragmentAndSideTotal', axis = 1)\n",
    "features = features.drop('fragmentAndSideTrend', axis = 1)\n",
    "features = features.drop('fragmentAndSideCubes', axis = 1)\n",
    "features = features.drop('fragmentAndSideDrawRect', axis = 1)\n",
    "features = features.drop('fragmentAndSideMatchPoint', axis = 1)\n",
    "features = features.drop('origCoordinates', axis = 1)\n",
    "features = features.drop(\"firstFileName\", axis = 1)\n",
    "features = features.drop(\"firstCroppedWidth\", axis = 1)\n",
    "features = features.drop(\"firstOffsetX\", axis = 1)\n",
    "features = features.drop(\"firstOffsetY\", axis = 1)\n",
    "features = features.drop(\"firstHorizontalFlip\", axis = 1)\n",
    "features = features.drop(\"secondFileName\", axis = 1)\n",
    "features = features.drop(\"secondCroppedWidth\", axis = 1)\n",
    "features = features.drop(\"secondOffsetX\", axis = 1)\n",
    "features = features.drop(\"secondOffsetY\", axis = 1)\n",
    "features = features.drop(\"secondHorizontalFlip\", axis = 1)\n",
    "features = features.drop(\"class\", axis = 1)\n",
    "\n",
    "forest_model = joblib.load('rndFstBasic.pkl') \n",
    "\n",
    "predictions = np.round(forest_model.predict(features))-1\n",
    "orig_features[\"class\"] = predictions\n",
    "filtered = orig_features[orig_features[\"class\"] == 1]\n",
    "filtered.to_csv('20181020_212330_pairs_final.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_code_all_hidden": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
