{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-23T09:33:07.884646Z",
     "start_time": "2019-04-23T09:33:07.368936Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# IMPORTS\n",
    "# Pandas is used for data manipulation\n",
    "import pandas as pd\n",
    "# Use numpy to convert to arrays\n",
    "import numpy as np\n",
    "# Using Skicit-learn to split data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Import tools needed for visualization\n",
    "from sklearn.tree import export_graphviz\n",
    "# import pydot\n",
    "# Import the model we are using\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "# Utility to store and load model from disk\n",
    "from sklearn.externals import joblib\n",
    "# write csv files\n",
    "import csv\n",
    "# Import charting lib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-23T09:33:08.880477Z",
     "start_time": "2019-04-23T09:33:08.811154Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# UTIL\n",
    "def test_model(forest_model, test_features, test_labels):\n",
    "    # Use the forest's predict method on the test data\n",
    "    predictions = np.round(forest_model.predict(test_features))\n",
    "\n",
    "    # Calculate the absolute errors\n",
    "    errors = abs(predictions - test_labels)\n",
    "\n",
    "    # Print out the mean absolute error (mae)\n",
    "    print('Mean Absolute Error:', round(np.mean(errors), 2))\n",
    "\n",
    "    # Calculate mean absolute percentage error (MAPE)\n",
    "    mape = 100 * (errors / test_labels)\n",
    "\n",
    "    # Calculate and display accuracy\n",
    "    accuracy = 100 - np.mean(mape)\n",
    "    print('Accuracy:', round(accuracy, 2), '%.')\n",
    "\n",
    "    # Pull out one tree from the forest\n",
    "    #tree = forest_model.estimators_[5]\n",
    "    # print('The depth of this tree is:', tree.tree_.max_depth)\n",
    "\n",
    "    total_trues = sum(x == 2 for x in test_labels)\n",
    "    total_predictions = sum(x == 2 for x in predictions)\n",
    "    total_errors = sum(x == 1 for x in errors)\n",
    "    print('Total Samples:', len(test_labels))\n",
    "    print('Total Trues:', total_trues)\n",
    "    print('Total Predictions:', total_predictions)\n",
    "    print('Total Errors:', total_errors)\n",
    "\n",
    "    false_positive = sum(predict > label for predict, label in zip(predictions, test_labels))\n",
    "    false_negative = sum(predict < label for predict, label in zip(predictions, test_labels))\n",
    "    true_positive = total_predictions - false_positive\n",
    "    print('false_positive:', false_positive)\n",
    "    print('false_negative:', false_negative)\n",
    "    print('true_positive:', true_positive)\n",
    "    \n",
    "    print('>>>>>>>>>>>>>>>>>>>>')\n",
    "    for index, value in enumerate(zip(predictions, test_labels)):\n",
    "        if value[0] < value[1]:\n",
    "            print(test_features_[index,0])\n",
    "    print('>>>>>>>>>>>>>>>>>>>>')\n",
    "    \n",
    "    \n",
    "    precision = true_positive / total_predictions\n",
    "    recall = true_positive / (true_positive + false_negative)\n",
    "    print('precision:', precision)\n",
    "    print('recall:', recall)\n",
    "    return precision, recall\n",
    "\n",
    "def draw_tree(forest_model, test_features, test_labels): \n",
    "    importances = forest_model.feature_importances_\n",
    "    std = np.std([tree.feature_importances_ for tree in forest_model.estimators_],\n",
    "                 axis=0)\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "\n",
    "    # Print the feature ranking\n",
    "    print(\"Feature ranking:\")\n",
    "\n",
    "    for f in range(test_features.shape[1]):\n",
    "        print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))\n",
    "\n",
    "    # Plot the feature importances of the forest\n",
    "    plt.figure()\n",
    "    plt.title(\"Feature importances\")\n",
    "    plt.bar(range(test_features.shape[1]), importances[indices],\n",
    "           color=\"r\", yerr=std[indices], align=\"center\")\n",
    "    plt.xticks(range(test_features.shape[1]), indices)\n",
    "    plt.xlim([-1, test_features.shape[1]])\n",
    "    plt.show()    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Prepare the source data\n",
    "features = pd.read_csv('20181216_034921_pairs_final_enhanced_synt.csv') #20181020_212330_pairs_votes_enhanced\n",
    "\n",
    "# Remove the irrelevant texts from the features\n",
    "# axis 1 refers to the columns\n",
    "# features = features.drop('fragmanetAndSide', axis = 1)\n",
    "features = features.drop('fragment', axis = 1)\n",
    "features = features.drop('fragmentAndSideTotal', axis = 1)\n",
    "features = features.drop('fragmentAndSideTrend', axis = 1)\n",
    "features = features.drop('fragmentAndSideCubes', axis = 1)\n",
    "features = features.drop('fragmentAndSideDrawRect', axis = 1)\n",
    "features = features.drop('fragmentAndSideMatchPoint', axis = 1)\n",
    "features = features.drop('rotateFragmentAndSideCubes', axis = 1)\n",
    "features = features.drop('rotateFragmentAndSideDrawRect', axis = 1)\n",
    "features = features.drop('rotateFragmentAndSideMatchPoint', axis = 1)\n",
    "features = features.drop('origCoordinates', axis = 1)\n",
    "features = features.drop(\"firstFileName\", axis = 1)\n",
    "features = features.drop(\"firstCroppedWidth\", axis = 1)\n",
    "features = features.drop(\"firstOffsetX\", axis = 1)\n",
    "features = features.drop(\"firstOffsetY\", axis = 1)\n",
    "features = features.drop(\"firstHorizontalFlip\", axis = 1)\n",
    "features = features.drop(\"secondFileName\", axis = 1)\n",
    "features = features.drop(\"secondCroppedWidth\", axis = 1)\n",
    "features = features.drop(\"secondOffsetX\", axis = 1)\n",
    "features = features.drop(\"secondOffsetY\", axis = 1)\n",
    "features = features.drop(\"secondHorizontalFlip\", axis = 1)\n",
    "features = features.drop(\"prediction\", axis = 1)\n",
    "\n",
    "# features = features.drop('fragmentTotal', axis = 1)\n",
    "# features = features.drop('fragmentAndSideVote', axis = 1)\n",
    "# features = features.drop('fragmentAndSideTrendVote', axis = 1)\n",
    "\n",
    "# One-hot encode categorical features\n",
    "#features = pd.get_dummies(features)\n",
    "\n",
    "# Labels are the values we want to predict\n",
    "labels = np.array(features['class'])\n",
    "labels = labels + 1\n",
    "\n",
    "# Remove the labels from the features\n",
    "# axis 1 refers to the columns\n",
    "features= features.drop('class', axis = 1)\n",
    "\n",
    "# Saving feature names for later use\n",
    "feature_list = list(features.columns)\n",
    "\n",
    "# Convert to numpy array\n",
    "features = np.array(features)\n",
    "\n",
    "feature_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Random Forest 1st model\n",
    "# Split the data into training and testing sets\n",
    "train_features_, test_features_, train_labels, test_labels = train_test_split(features, labels, test_size = 0.3)\n",
    "\n",
    "train_features = train_features_[:,1:] # remove the fragmentAndSide column which is the label\n",
    "test_features = test_features_[:,1:] # remove the fragmentAndSide column which is the label\n",
    "\n",
    "# Instantiate model \n",
    "rf = RandomForestClassifier(n_estimators= 1000, random_state=42, n_jobs=-1)\n",
    "\n",
    "rf.fit(train_features, train_labels)\n",
    "\n",
    "test_model(rf, test_features, test_labels)\n",
    "draw_tree(rf, test_features, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# AdaBoostClassifier model \n",
    "ab = AdaBoostClassifier(n_estimators= 1000, learning_rate=0.8)\n",
    "\n",
    "ab.fit(train_features, train_labels)\n",
    "\n",
    "test_model(ab, test_features, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# BaggingClassifier model \n",
    "bc = BaggingClassifier(n_estimators= 1000)\n",
    "\n",
    "bc.fit(train_features, train_labels)\n",
    "\n",
    "test_model(bc, test_features, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ExtraTreesClassifier model \n",
    "et = ExtraTreesClassifier(n_estimators= 1000)\n",
    "\n",
    "et.fit(train_features, train_labels)\n",
    "\n",
    "test_model(et, test_features, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# GradientBoostingClassifier model \n",
    "gb = GradientBoostingClassifier(n_estimators= 1000)\n",
    "\n",
    "gb.fit(train_features, train_labels)\n",
    "\n",
    "test_model(gb, test_features, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# VotingClassifier model \n",
    "vt = VotingClassifier(estimators=[('ab', ab), ('rf', rf), ('bc', bc), ('et', et), ('gb', gb)], voting='soft', n_jobs=-1)\n",
    "\n",
    "vt.fit(train_features, train_labels)\n",
    "\n",
    "test_model(vt, test_features, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import cross_val_predict\n",
    "# from sklearn import metrics\n",
    "# predicted = cross_val_predict(rf, test_features, test_labels, cv=5)\n",
    "# metrics.accuracy_score(test_labels, np.round(predicted)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Random Forest 2nd variation of model - just for reference - not used\n",
    "rf_new = RandomForestRegressor(n_estimators = 1000, criterion = 'mse', max_depth = None, \n",
    "                               min_samples_split = 2, min_samples_leaf = 1)\n",
    "rf_new.fit(train_features, train_labels)\n",
    "\n",
    "test_model(rf_new, test_features, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Random Forest 3rd model - Limit depth of tree to 2 levels - not used\n",
    "rf_small = RandomForestRegressor(n_estimators=10, max_depth = 3, random_state=42)\n",
    "rf_small.fit(train_features, train_labels)\n",
    "\n",
    "test_model(rf_small, test_features, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Finally - use the 1st model and this time train on the entire set \n",
    "fit_features = features[:,1:] # remove the fragmentAndSide column which is the label\n",
    "\n",
    "rf.fit(fit_features, labels);\n",
    "\n",
    "joblib.dump(rf, 'rndFstBasic.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-23T09:33:22.828290Z",
     "start_time": "2019-04-23T09:33:19.107781Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ilan/venv35/lib/python3.5/site-packages/sklearn/base.py:253: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 0.18.1 when using version 0.20.3. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/home/ilan/venv35/lib/python3.5/site-packages/sklearn/base.py:253: UserWarning: Trying to unpickle estimator RandomForestClassifier from version 0.18.1 when using version 0.20.3. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# Run on the output of the voting and classify them\n",
    "# Read in data as pandas dataframe\n",
    "orig_features = pd.read_csv('20190407_pairs_votes_enhanced.csv') # 20181216_034921_pairs_final_enhanced_synt #('20181213_031300_pairs_final_flipped_enhanced.csv')\n",
    "\n",
    "# Remove the irrelevant texts from the features\n",
    "# axis 1 refers to the columns\n",
    "features = orig_features.drop('fragmentAndSide', axis = 1)\n",
    "features = features.drop('fragment', axis = 1)\n",
    "features = features.drop('fragmentAndSideTotal', axis = 1)\n",
    "features = features.drop('fragmentAndSideTrend', axis = 1)\n",
    "features = features.drop('fragmentAndSideCubes', axis = 1)\n",
    "features = features.drop('fragmentAndSideDrawRect', axis = 1)\n",
    "features = features.drop('fragmentAndSideMatchPoint', axis = 1)\n",
    "features = features.drop('rotateFragmentAndSideCubes', axis = 1)\n",
    "features = features.drop('rotateFragmentAndSideDrawRect', axis = 1)\n",
    "features = features.drop('rotateFragmentAndSideMatchPoint', axis = 1)\n",
    "features = features.drop('origCoordinates', axis = 1)\n",
    "features = features.drop(\"firstFileName\", axis = 1)\n",
    "features = features.drop(\"firstCroppedWidth\", axis = 1)\n",
    "features = features.drop(\"firstOffsetX\", axis = 1)\n",
    "features = features.drop(\"firstOffsetY\", axis = 1)\n",
    "features = features.drop(\"firstHorizontalFlip\", axis = 1)\n",
    "features = features.drop(\"secondFileName\", axis = 1)\n",
    "features = features.drop(\"secondCroppedWidth\", axis = 1)\n",
    "features = features.drop(\"secondOffsetX\", axis = 1)\n",
    "features = features.drop(\"secondOffsetY\", axis = 1)\n",
    "features = features.drop(\"secondHorizontalFlip\", axis = 1)\n",
    "features = features.drop(\"class\", axis = 1)\n",
    "if 'prediction' in features:\n",
    "    features = features.drop(\"prediction\", axis = 1)\n",
    "if 'prediction_score' in features:\n",
    "    features = features.drop(\"prediction_score\", axis = 1)\n",
    "\n",
    "forest_model = joblib.load('rndFstBasic.pkl') \n",
    "\n",
    "ttemp = forest_model.predict_proba(features)\n",
    "orig_features[\"prediction_score\"] = [item[1] for item in ttemp]\n",
    "\n",
    "predictions = np.round(forest_model.predict(features))-1\n",
    "orig_features[\"prediction\"] = predictions\n",
    "filtered = orig_features[orig_features[\"prediction\"] == 1]\n",
    "filtered.to_csv('20190407_votes_enhanced_final.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_code_all_hidden": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
