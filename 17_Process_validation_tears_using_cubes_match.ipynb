{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/il239838/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "# RUN Main import block and TODO list\n",
    "\n",
    "# TODO: see how uri calculated the ridges\n",
    "\n",
    "# TODO: Perform Histogram equalization - start with it\n",
    "# TODO: \n",
    "# take integral from the Highest peak+-0.005 divide by integral of the entire graph \n",
    "# This will be the peakness measure for the PSD ==> The desired ridge index\n",
    "# TODO:\n",
    "# take integral from the Highest peak+-0.005 divide by integral of the entire graph - it's the peakness measure for the PSD\n",
    "# must select a peak above a min threshold in order to ignore noisy frequency\n",
    "# must ignore peaks above a certain threshold in order to detect meaningful frequency\n",
    "# run the PSD in moving windows every 200 px (deduced from the below PSD pointing to a freq of 1/0.02=50-> times 4= 200px)\n",
    "# and medianf the result of the windows\n",
    "# TODO:\n",
    "# Another alternative: (with Yariv)\n",
    "# Run PSD column by column - get the phase, freq, peakness and reconstruct an artificial ridge slice\n",
    "# from this - reconstruct a \"clean\" artificial ridge image\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.image as img\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import urllib.request\n",
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "from scipy import ndimage\n",
    "from scipy import signal\n",
    "#import cv2\n",
    "\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "import mahotas as mh\n",
    "from mahotas import polygon\n",
    "# import pymorph as pm\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "from scipy import ndimage as nd\n",
    "import skimage.transform as transform\n",
    "import skimage.morphology as mp\n",
    "import skimage.io as sio\n",
    "import scipy.misc as sm\n",
    "from skimage.filters import threshold_otsu, threshold_adaptive\n",
    "from skimage.feature import hessian_matrix, hessian_matrix_eigvals\n",
    "from skimage import exposure\n",
    "from skimage import data, img_as_float\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "from bisect import bisect_left\n",
    "import math\n",
    "import warnings\n",
    "import csv\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [
     0,
     58,
     72,
     78,
     84,
     98,
     107,
     122,
     140,
     175,
     315,
     325,
     336,
     346,
     358,
     363,
     368,
     375,
     397,
     404,
     413,
     450
    ],
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found a ZERO index cube with the name:ZERO\n"
     ]
    }
   ],
   "source": [
    "# RUN Utility functions\n",
    "\n",
    "# One time init\n",
    "# with open('results.csv', 'w') as csvfile:\n",
    "#     csvout = csv.writer(csvfile)\n",
    "#     csvout.writerow([\"File\", \"Model\", \"Gap\", \"Slice_size\", \"Count\", \"Precision\", \"Recall\", \"F-score\", \"True Count\", \"Error Rate\"])\n",
    "\n",
    "#BASIC CROP FRAME\n",
    "X_START = 1000\n",
    "X_END = 6000\n",
    "Y_START = 800\n",
    "Y_END = 4300\n",
    "BG_2_OBJ_RATIO = 0.91\n",
    "CUBE_SIZE = 250\n",
    "EDGE_GAP = 50\n",
    "ROOT_FOLDER = \"/home/il239838/files/\"\n",
    "#ROOT_FOLDER = \"/Users/il239838/Downloads/private/Thesis/Papyrus/PX303/files/\"\n",
    "VOL_FOLDER = \"/home/il239838/files/\"\n",
    "#VOL_FOLDER = \"/Volumes/250GB/\"\n",
    "LEARNING_RATE = 0.001\n",
    "BATCHES = 800\n",
    "BATCH_SIZE = 50\n",
    "BREAK_VAL = 1000\n",
    "\n",
    "# Simple crop by x/y ranges\n",
    "def crop(image, ymin, ymax, xmin, xmax):\n",
    "    return image[ymin:ymax, xmin:xmax]\n",
    "\n",
    "# returns a logical matrix of values beyond a threshld\n",
    "def thresholded(image, val): \n",
    "    return np.logical_and(*[image[...] > val  for t in enumerate([0, 0])])\n",
    "\n",
    "def find_min_max_without_orphand_pixels(nonzero_dimension, crop_filter=20):\n",
    "    sorted = np.sort(nonzero_dimension)\n",
    "    prev=-1\n",
    "    min_val = sorted[0]\n",
    "    for i, x in enumerate(sorted[:100]):\n",
    "        if prev >= 0 and x - prev > crop_filter:\n",
    "            min_val = x\n",
    "        prev = x\n",
    "    prev=-1\n",
    "    max_val = sorted[-1]\n",
    "    for i, x in enumerate(sorted[-100:]):\n",
    "        if prev >= 0 and x - prev > crop_filter:\n",
    "            max_val = prev\n",
    "            break\n",
    "        prev = x\n",
    "    \n",
    "    return min_val, max_val\n",
    "\n",
    "def calc_min_max_coordinates(image, crop_val=50):\n",
    "    temp = thresholded(image, crop_val)\n",
    "    temp = temp * 1\n",
    "    temp = np.nonzero(temp)\n",
    "    ymin, ymax = find_min_max_without_orphand_pixels(temp[0])\n",
    "    xmin,xmax = find_min_max_without_orphand_pixels(temp[1])\n",
    "    return ymin, ymax, xmin, xmax\n",
    "\n",
    "def calc_min_max_coordinates_dynamic(image, cutoff=1):\n",
    "    temp = exposure.equalize_adapthist(image, clip_limit=0.03)\n",
    "    flat = np.sort(np.matrix.getA1(temp))\n",
    "    sum_all = np.sum(flat)\n",
    "    index = np.argmin(flat.cumsum() < (sum_all * cutoff))\n",
    "\n",
    "    temp = thresholded(temp, flat[index])\n",
    "    temp = temp * 1\n",
    "    temp = np.nonzero(temp)\n",
    "    ymin, ymax = find_min_max_without_orphand_pixels(temp[0])\n",
    "    xmin,xmax = find_min_max_without_orphand_pixels(temp[1])\n",
    "    return ymin, ymax, xmin, xmax\n",
    "\n",
    "# initial static crop and a seondary dynamic crop based on signal2noise ratio\n",
    "def crop_full_scan(image, x_start, x_end, y_start, y_end):\n",
    "    temp = crop(image, y_start, y_end, x_start, x_end)\n",
    "    ymin, ymax, xmin, xmax = calc_min_max_coordinates_dynamic(temp, cutoff=BG_2_OBJ_RATIO)\n",
    "    temp = crop(image, y_start+ymin, y_start+ymax, x_start+xmin, x_start+xmax)\n",
    "    return temp\n",
    "\n",
    "def crop_thresholded(image):\n",
    "    temp = crop(image, 0, image.shape[0]-1, 0, image.shape[1]-1)\n",
    "    ymin, ymax, xmin, xmax = calc_min_max_coordinates(temp)\n",
    "    temp = crop(image, ymin, ymax, xmin, xmax)\n",
    "    return temp\n",
    "\n",
    "def read_and_crop(image_name, x_start=X_START, x_end=X_END, y_start=Y_START, y_end=Y_END):\n",
    "    if \"il239838\" in os.getcwd():\n",
    "        image = img.imread(ROOT_FOLDER + image_name)\n",
    "    else:\n",
    "        f = urllib.request.urlopen(\"https://dl.dropboxusercontent.com/s/31b96942qdcn73k/\" + image_name)\n",
    "        image = img.imread(f, format='jpeg')\n",
    "\n",
    "    # Smart-crop the image to get rid of all the noise and redundant area\n",
    "    # return crop_full_scan(image)\n",
    "    cropped = crop_full_scan(image, x_start, x_end, y_start, y_end)\n",
    "    return exposure.equalize_adapthist(cropped, clip_limit=0.03)\n",
    "\n",
    "\n",
    "# TODO: fix performance!!! http://scikit-image.org/docs/dev/user_guide/tutorial_parallelization.html\n",
    "def combine_3_images_to_RGB(red, green, blue):\n",
    "    new_image = np.empty((blue.shape[0],blue.shape[1],3))\n",
    "    for x in range(0, blue.shape[0]):\n",
    "        for y in range(0, blue.shape[1]):\n",
    "            new_image[x,y,0] = red[x,y]\n",
    "            new_image[x,y,1] = green[x,y]\n",
    "            new_image[x,y,2] = blue[x,y]\n",
    "    return new_image\n",
    "\n",
    "def slice_image_left_edge(original, width=200, rotate=0):\n",
    "    rot = ndimage.rotate(original, rotate)\n",
    "    # Slice the left slice of the so-called \"blue\" image\n",
    "    left_edge_orig = crop(rot, 1, 1400, 1, width)\n",
    "    left_edge_orig = crop_thresholded(left_edge_orig)\n",
    "\n",
    "    # Copy to a new array so we don't thrash the origin\n",
    "    left_edge = np.empty_like (left_edge_orig)\n",
    "    np.copyto(left_edge, left_edge_orig)\n",
    "\n",
    "    # Zero down low level \"noise\" values\n",
    "    low_values_indices = left_edge < 30  # Where values are low\n",
    "    left_edge[low_values_indices] = 0  # All low values set to 0\n",
    "    return left_edge\n",
    "\n",
    "def get_best_angle_rotation(original, crop=True, width=200):\n",
    "    min_var = 99999999999\n",
    "    best_angle = -10\n",
    "    for x in range(-5,5):\n",
    "        if crop:            \n",
    "            rot_edge = slice_image_left_edge(original, width, x)\n",
    "        else:\n",
    "            rot_edge = ndimage.rotate(original, x)\n",
    "        left_var = np.var(rot_edge, axis=1)\n",
    "        # left_var = np.apply_along_axis(lambda v: np.var(v[np.nonzero(v)]), 1, rot_edge)\n",
    "        var_sum = np.sum(left_var)\n",
    "        if (var_sum < min_var):\n",
    "            min_var = var_sum\n",
    "            best_angle = x\n",
    "    print (\"best_angle=\"+str(best_angle))\n",
    "    return best_angle\n",
    "\n",
    "#     import pdb; pdb.set_trace()\n",
    "def calc_neighbors(slice_map, col, row):\n",
    "    # import pdb; pdb.set_trace()\n",
    "    if ((col-1, row) in slice_map and slice_map[(col-1, row)] != None):\n",
    "        slice_map[(col, row)][\"left\"] = slice_map[(col-1, row)]\n",
    "        slice_map[(col-1, row)][\"right\"] = slice_map[(col, row)]\n",
    "    if ((col+1, row) in slice_map and slice_map[(col+1, row)] != None):\n",
    "        slice_map[(col, row)][\"right\"] = slice_map[(col+1, row)]\n",
    "        slice_map[(col+1, row)][\"left\"] = slice_map[(col, row)]\n",
    "    if ((col, row-1) in slice_map and slice_map[(col, row-1)] != None):\n",
    "        slice_map[(col, row)][\"top\"] = slice_map[(col, row-1)]\n",
    "        slice_map[(col, row-1)][\"bottom\"] = slice_map[(col, row)]\n",
    "    if ((col, row+1) in slice_map and slice_map[(col, row+1)] != None):\n",
    "        slice_map[(col, row)][\"bottom\"] = slice_map[(col, row+1)]\n",
    "        slice_map[(col, row+1)][\"top\"] = slice_map[(col, row)]\n",
    "    \n",
    "\n",
    "\n",
    "def VAL_create_cube(name, raw, x, y):\n",
    "    cube = {}\n",
    "    cube[\"cube\"] = raw\n",
    "    cube[\"file\"] = name\n",
    "    if name.find('P') == 0 and name.find('Fg') > 0:\n",
    "        cube[\"index\"] = int(name[name.find('P')+1:name.find('P')+4]) * 1000 + int(name[name.find('Fg')+2:name.find('Fg')+5])\n",
    "    else:\n",
    "        print(\"Found a ZERO index cube with the name:\"+name)\n",
    "        cube[\"index\"] = 0\n",
    "    cube[\"top_row\"] = x\n",
    "    cube[\"left_col\"] = y\n",
    "    cube[\"right_col\"] = y + CUBE_SIZE\n",
    "    return cube\n",
    "    \n",
    "\n",
    "ZERO_CUBE = VAL_create_cube(\"ZERO\", np.zeros((CUBE_SIZE, CUBE_SIZE), dtype=np.int), -1, -2)\n",
    "\n",
    "# slice an image to cubes with 250X250 pixel size\n",
    "def VAL_slice_TEAR_to_static_slices(name, cropped_original):\n",
    "    structure = {}\n",
    "    # cropped_original = cropped_original / 256 # divide by 256 to \"normalize\" between 0 and 1\n",
    "\n",
    "    # import pdb; pdb.set_trace()\n",
    "    x, y = cropped_original[\"cut\"].shape\n",
    "    # print (x,y)\n",
    "    n = 0\n",
    "    # see n offset to see offset in pixels on the x axis == rows. every n equals CUBE_SIZE\n",
    "    while ((n + 1) * CUBE_SIZE < x):\n",
    "        # mark the piece as narrow so the first would be counted as lastt too\n",
    "        narrow = True if ((CUBE_SIZE + (4 * EDGE_GAP)) > y) else False\n",
    "        # cut a cube of 250X250 at the FIRST column\n",
    "        start_row_px = int(np.round(n * CUBE_SIZE, -1))\n",
    "        end_row_px = int(np.round((n + 1) * CUBE_SIZE, -1))\n",
    "        cube = (crop(cropped_original[\"cut\"], start_row_px, end_row_px, EDGE_GAP, CUBE_SIZE + EDGE_GAP))\n",
    "        # keep only cubes for which half of the pixels have some \"color\"\n",
    "        if np.median(cube) > 0.2: # aligned with the normalization 0.2 correlates to 50\n",
    "            # keep the cube\n",
    "            new_cube = VAL_create_cube(name, cube, start_row_px, EDGE_GAP)\n",
    "            new_cube[\"col\"] = 0 # marks that the cube is on the first col of the piece\n",
    "            new_cube[\"row\"] = n\n",
    "            new_cube[\"last\"] = narrow # marks that the cube is on the last col of the piece\n",
    "            new_cube[\"orig\"] = cropped_original\n",
    "            new_cube[\"col_px_left\"] = cropped_original[\"col_px\"] + EDGE_GAP\n",
    "            new_cube[\"col_px_right\"] = cropped_original[\"col_px\"] + CUBE_SIZE + EDGE_GAP\n",
    "            new_cube[\"row_px_top\"] = cropped_original[\"row_px\"] + start_row_px\n",
    "            new_cube[\"row_px_bottom\"] = cropped_original[\"row_px\"] + end_row_px\n",
    "            structure[(0, n)] = new_cube\n",
    "\n",
    "        # cut a cube of 250X250 at the LAST column\n",
    "        cube = (crop(cropped_original[\"cut\"], start_row_px, end_row_px, y - CUBE_SIZE - EDGE_GAP, y - EDGE_GAP))\n",
    "        # keep only cubes for which half of the pixels have some \"color\"\n",
    "        # aligned with the normalization 0.2 correlates to 50\n",
    "        if np.median(cube) > 0.2:\n",
    "            # keep the cube\n",
    "            new_cube = VAL_create_cube(name, cube, start_row_px, y - CUBE_SIZE - EDGE_GAP)\n",
    "            new_cube[\"col\"] = 1 # marks that the cube is on the last col of the piece\n",
    "            new_cube[\"row\"] = n\n",
    "            new_cube[\"last\"] = not narrow # like col - marks that the cube is on the last col of the piece\n",
    "            new_cube[\"orig\"] = cropped_original\n",
    "            new_cube[\"col_px_left\"] = cropped_original[\"col_px\"] + y - CUBE_SIZE - EDGE_GAP\n",
    "            new_cube[\"col_px_right\"] = cropped_original[\"col_px\"] + y - EDGE_GAP\n",
    "            new_cube[\"row_px_top\"] = cropped_original[\"row_px\"] + start_row_px\n",
    "            new_cube[\"row_px_bottom\"] = cropped_original[\"row_px\"] + end_row_px\n",
    "            structure[(1, n)] = new_cube\n",
    "\n",
    "    #         m = 0\n",
    "    #         # every 250 pixels on the y axis == cols\n",
    "    #         while ((m + 1) * CUBE_SIZE < y):            \n",
    "    #             if ((m == 0) or ((m + 2) * CUBE_SIZE >= y)): # Only keep the left and right edges of the piece for matching!!\n",
    "    #                 # cut a cube of 250X250\n",
    "    #                 cube = crop(cropped_original[\"cut\"], n * CUBE_SIZE, (n + 1) * CUBE_SIZE, m * CUBE_SIZE, (m + 1) * CUBE_SIZE)\n",
    "    #                 # keep only cubes for which half of the pixels have some \"color\"\n",
    "    #                 # print(np.median(cube))\n",
    "    #                 if np.median(cube) > 0.2: # aligned with the normalization 0.2 correlates to 50\n",
    "    #                     # keep the cube\n",
    "    #                     new_cube = VAL_create_cube(name, cube, n * CUBE_SIZE, m * CUBE_SIZE)\n",
    "    #                     new_cube[\"col\"] = m\n",
    "    #                     new_cube[\"row\"] = n\n",
    "    #                     new_cube[\"orig\"] = cropped_original\n",
    "    #                     new_cube[\"col_px_left\"] = cropped_original[\"col_px\"] + m * CUBE_SIZE\n",
    "    #                     new_cube[\"col_px_right\"] = cropped_original[\"col_px\"] + (m + 1) * CUBE_SIZE\n",
    "    #                     new_cube[\"row_px_top\"] = cropped_original[\"row_px\"] + n * CUBE_SIZE\n",
    "    #                     new_cube[\"row_px_bottom\"] = cropped_original[\"row_px\"] + (n + 1) * CUBE_SIZE\n",
    "    #                     if ((m + 2) * CUBE_SIZE >= y):\n",
    "    #                         new_cube[\"last\"] = True\n",
    "    #                     else:\n",
    "    #                         new_cube[\"last\"] = False\n",
    "    #                     structure[(m, n)] = new_cube\n",
    "    #             m += 1\n",
    "        n += 0.2 # currently set to jump in 50 px offset\n",
    "            \n",
    "    # this loop has to be performed only after we've established all the None cubes\n",
    "    for cube in structure.values():\n",
    "        # set the reference to neighbor cubes\n",
    "        if cube != None:\n",
    "            calc_neighbors(structure, cube[\"col\"], cube[\"row\"])\n",
    "\n",
    "    # return the data structure with all the cubes and the counters of the rows and columns\n",
    "    return structure.values()\n",
    "\n",
    "def VAL_slice_to_static_slices(name, cropped_original, img_data):\n",
    "    structure = {}\n",
    "    # cropped_original = cropped_original / 256 # divide by 256 to \"normalize\" between 0 and 1\n",
    "\n",
    "    # import pdb; pdb.set_trace()\n",
    "    x, y = cropped_original.shape\n",
    "    # print (x,y)\n",
    "    n = 0\n",
    "    # see n offset to see offset in pixels on the x axis == rows. every n equals CUBE_SIZE\n",
    "    while ((n + 1) * CUBE_SIZE < x):\n",
    "        # mark the piece as narrow so the first would be counted as lastt too\n",
    "        narrow = True if ((CUBE_SIZE + (4 * EDGE_GAP)) > y) else False\n",
    "        # cut a cube of 250X250 at the FIRST column\n",
    "        start_row_px = int(np.round(n * CUBE_SIZE, -1))\n",
    "        end_row_px = int(np.round((n + 1) * CUBE_SIZE, -1))\n",
    "        cube = (crop(cropped_original, start_row_px, end_row_px, EDGE_GAP, CUBE_SIZE + EDGE_GAP))\n",
    "        # keep only cubes for which half of the pixels have some \"color\"\n",
    "        if np.median(cube) > 0.2: # aligned with the normalization 0.2 correlates to 50\n",
    "            # keep the cube\n",
    "            new_cube = VAL_create_cube(name, cube, start_row_px, EDGE_GAP)\n",
    "            new_cube[\"col\"] = 0 # marks that the cube is on the first col of the piece\n",
    "            new_cube[\"row\"] = n\n",
    "            new_cube[\"last\"] = narrow # marks that the cube is on the last col of the piece\n",
    "            new_cube[\"orig\"] = cropped_original\n",
    "            new_cube[\"col_px_left\"] = img_data[\"col_px\"] + EDGE_GAP\n",
    "            new_cube[\"col_px_right\"] = img_data[\"col_px\"] + CUBE_SIZE + EDGE_GAP\n",
    "            new_cube[\"row_px_top\"] = img_data[\"row_px\"] + start_row_px\n",
    "            new_cube[\"row_px_bottom\"] = img_data[\"row_px\"] + end_row_px\n",
    "            structure[(0, n)] = new_cube\n",
    "\n",
    "        # cut a cube of 250X250 at the LAST column\n",
    "        cube = (crop(cropped_original, start_row_px, end_row_px, y - CUBE_SIZE - EDGE_GAP, y - EDGE_GAP))\n",
    "        # keep only cubes for which half of the pixels have some \"color\"\n",
    "        # aligned with the normalization 0.2 correlates to 50\n",
    "        if np.median(cube) > 0.2:\n",
    "            # keep the cube\n",
    "            new_cube = VAL_create_cube(name, cube, start_row_px, y - CUBE_SIZE - EDGE_GAP)\n",
    "            new_cube[\"col\"] = 1 # marks that the cube is on the last col of the piece\n",
    "            new_cube[\"row\"] = n\n",
    "            new_cube[\"last\"] = not narrow # like col - marks that the cube is on the last col of the piece\n",
    "            new_cube[\"orig\"] = cropped_original\n",
    "            new_cube[\"col_px_left\"] = img_data[\"col_px\"] + y - CUBE_SIZE - EDGE_GAP\n",
    "            new_cube[\"col_px_right\"] = img_data[\"col_px\"] + y - EDGE_GAP\n",
    "            new_cube[\"row_px_top\"] = img_data[\"row_px\"] + start_row_px\n",
    "            new_cube[\"row_px_bottom\"] = img_data[\"row_px\"] + end_row_px\n",
    "            structure[(1, n)] = new_cube\n",
    "\n",
    "        n += 0.2 # currently set to jump in 50 px offset\n",
    "            \n",
    "    ## this loop has to be performed only after we've established all the None cubes\n",
    "    #for cube in structure.values():\n",
    "    #    # set the reference to neighbor cubes\n",
    "    #    if cube != None:\n",
    "    #        calc_neighbors(structure, cube[\"col\"], cube[\"row\"])\n",
    "\n",
    "    # return the data structure with all the cubes and the counters of the rows and columns\n",
    "    return structure.values()\n",
    "\n",
    "def pad_above(original, above, amount):\n",
    "    res = np.insert(original[\"cube\"], np.zeros(amount), above[\"cube\"][-amount:], axis=0)\n",
    "    res = np.delete(res, np.arange(CUBE_SIZE,CUBE_SIZE+amount), axis=0)\n",
    "    cube = VAL_create_cube(original[\"file\"], res, original[\"top_row\"] - amount, original[\"left_col\"])\n",
    "    cube[\"col_px_left\"] = original[\"col_px_left\"]\n",
    "    cube[\"col_px_right\"] = original[\"col_px_right\"]\n",
    "    cube[\"row_px_top\"] = original[\"row_px_top\"] - amount\n",
    "    cube[\"row_px_bottom\"] = original[\"row_px_bottom\"] - amount\n",
    "    return cube\n",
    "\n",
    "def pad_below(original, below, amount):\n",
    "    res = np.insert(original[\"cube\"], np.full(amount, CUBE_SIZE), below[\"cube\"][:amount], axis=0)\n",
    "    res = np.delete(res, np.arange(0, amount), axis=0)\n",
    "    cube =  VAL_create_cube(original[\"file\"], res, original[\"top_row\"] + amount, original[\"left_col\"])\n",
    "    cube[\"col_px_left\"] = original[\"col_px_left\"]\n",
    "    cube[\"col_px_right\"] = original[\"col_px_right\"]\n",
    "    cube[\"row_px_top\"] = original[\"row_px_top\"] + amount\n",
    "    cube[\"row_px_bottom\"] = original[\"row_px_bottom\"] + amount\n",
    "    return cube\n",
    "    \n",
    "    \n",
    "def pad_left(original, left, amount):\n",
    "    res = np.insert(original[\"cube\"], np.zeros(amount, dtype=int), left[\"cube\"][:,-amount:], axis=1)\n",
    "    res = np.delete(res, np.arange(CUBE_SIZE, CUBE_SIZE+amount), axis=1)\n",
    "    cube = VAL_create_cube(original[\"file\"], res, original[\"top_row\"], original[\"left_col\"] - amount)\n",
    "    cube[\"col_px_left\"] = original[\"col_px_left\"] - amount\n",
    "    cube[\"col_px_right\"] = original[\"col_px_right\"] - amount\n",
    "    cube[\"row_px_top\"] = original[\"row_px_top\"]\n",
    "    cube[\"row_px_bottom\"] = original[\"row_px_bottom\"]\n",
    "    return cube\n",
    "\n",
    "def pad_right(original, right, amount):\n",
    "    res = np.insert(original[\"cube\"], [CUBE_SIZE], right[\"cube\"][:,:amount], axis=1)\n",
    "    res = np.delete(res, np.arange(0, amount), axis=1)\n",
    "    cube = VAL_create_cube(original[\"file\"], res, original[\"top_row\"], original[\"left_col\"] + amount)\n",
    "    cube[\"col_px_left\"] = original[\"col_px_left\"] + amount\n",
    "    cube[\"col_px_right\"] = original[\"col_px_right\"] + amount\n",
    "    cube[\"row_px_top\"] = original[\"row_px_top\"]\n",
    "    cube[\"row_px_bottom\"] = original[\"row_px_bottom\"]\n",
    "    return cube\n",
    "    \n",
    "\n",
    "# \"Shave\" the right edge of the cube with <gap> pixels and pad with zeros on the left\n",
    "def shave_right(original, amount):\n",
    "    return pad_left(original, ZERO_CUBE, amount)\n",
    "    \n",
    "\n",
    "# \"Shave\" the left edge of the cube with <gap> pixels and pad with zeros on the right    \n",
    "def shave_left(original, amount):\n",
    "    return pad_right(original, ZERO_CUBE, amount)\n",
    "    \n",
    "\n",
    "# concatenate cubes \n",
    "def concatenate_cubes(left, right, slice_size):\n",
    "    con = np.concatenate((left[\"cube\"][:,-slice_size:], right[\"cube\"][:,:slice_size]), axis=1)\n",
    "    x_delta = right[\"top_row\"] - left[\"top_row\"]\n",
    "    y_delta = right[\"left_col\"] - left[\"right_col\"] \n",
    "    return con, x_delta, y_delta\n",
    "\n",
    "# concatenate cubes \n",
    "def VAL_concatenate_cubes(left, right, slice_size):\n",
    "    right_img = right[\"cube\"]\n",
    "    # next block is not relevant for training ...\n",
    "    #     # if the left cube is matched to another left cube (or right cube to another right cube) then rotate the right\n",
    "    #     # cube by 180 so we try to match it upside down, covering the option that the cube was pictured rotated\n",
    "    #     if ((left[\"col\"] == 0 and right[\"col\"] == 0) or (left[\"col\"] != 0 and right[\"col\"] != 0)):\n",
    "    #         right_img = np.rot90(right[\"cube\"], 2);\n",
    "\n",
    "    con = np.concatenate((left[\"cube\"][:,-slice_size:], right_img[:,:slice_size]), axis=1)\n",
    "\n",
    "    # next block calculates distance based on the distance between left's right-top corner and right's left-top corner    \n",
    "    #     x_delta = right[\"top_row\"] - left[\"top_row\"]\n",
    "    #     y_delta = right[\"left_col\"] - left[\"right_col\"] \n",
    "\n",
    "    # next block calculates the distance between the centers of cubes, accounting for test set's possibility of reverse slices (left instead of right and vice versa)\n",
    "    x_delta = right[\"row_px_top\"] - left[\"row_px_top\"] # equivalent to distance between vertical centers\n",
    "    y_delta = (right[\"col_px_left\"] + (slice_size / 2)) - (left[\"col_px_right\"] - (slice_size / 2)) # measuring the distance between horizontal centers of the slices\n",
    "\n",
    "    return con, x_delta, y_delta, left[\"file\"], right[\"file\"]\n",
    "    \n",
    "\n",
    "# concatenate cubes while artificially creating a gap between them. Pad the other end of the cube with zeros\n",
    "def concatenate_cubes_zero_pad_gaps(left_orig, right_orig, gap):\n",
    "    left = left_orig if gap == 0 else shave_right(left_orig, gap)\n",
    "    right = right_orig if gap == 0 else shave_left(right_orig, gap)\n",
    "    return concatenate_cubes(left, right)    \n",
    "\n",
    "# concatenate cubes while artificially creating a gap between them. Pad the other end of the cobe with the nearby\n",
    "# continuation of the cubes\n",
    "def concatenate_cubes_with_gap(left_orig, right_orig, gap, left_pad, right_pad, slice_size):\n",
    "    # import pdb; pdb.set_trace()\n",
    "    left = left_orig if gap == 0 else pad_left(left_orig, left_pad, gap)\n",
    "    right = right_orig if gap == 0 else pad_right(right_orig, right_pad, gap)\n",
    "    return concatenate_cubes(left, right, slice_size)        \n",
    "\n",
    "# convert the data structure of cubes into a train set of 2 arrays of images and labels\n",
    "# each image is a concatanation of 2 images from the original cubes set, covering all combinations of images\n",
    "# effectively creating Nx(N-1) images\n",
    "def VAL_build_train_set_for_euclidean_distance(cubes, slice_size, folder):\n",
    "    # clean folder before starting\n",
    "    for root, dirs, files in os.walk(folder):\n",
    "        for f in files:\n",
    "            os.unlink(os.path.join(root, f))\n",
    "\n",
    "    #import pdb; pdb.set_trace()\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "    train_imgs = []\n",
    "    train_x_delta = []\n",
    "    train_y_delta = []\n",
    "    train_left_obj = []\n",
    "    train_right_obj = []\n",
    "    # iterate over all cubes   \n",
    "    for curr in cubes:\n",
    "        # iterate over the others (effectively n^2)\n",
    "        for adj in cubes:\n",
    "            if (adj[\"file\"] != curr[\"file\"]): # no need to test against self CURRENTLY checking from directions!!!\n",
    "                #import pdb; pdb.set_trace()\n",
    "                # append the adjacent image to the current image\n",
    "                conc, x_delta, y_delta, x_file, y_file = VAL_concatenate_cubes(curr, adj, slice_size)\n",
    "                output = folder+x_file+\"_\"+str(curr[\"top_row\"])+\"_\"+str(curr[\"left_col\"])+\"---\"+y_file+\"_\"+str(adj[\"top_row\"])+\"_\"+str(adj[\"left_col\"])\n",
    "                np.save(output, conc)\n",
    "                train_imgs.append(output)\n",
    "                train_x_delta.append(x_delta)\n",
    "                train_y_delta.append(y_delta)\n",
    "                train_left_obj.append(curr)\n",
    "                train_right_obj.append(adj)\n",
    "\n",
    "    warnings.filterwarnings(\"default\")\n",
    "    return train_imgs, train_x_delta, train_y_delta, train_left_obj, train_right_obj\n",
    "\n",
    "\n",
    "# convert the data structure of cubes into a train set of 2 arrays of images and labels\n",
    "# each image is a concatanation of 2 images from the original cubes set, covering all combinations of images\n",
    "# effectively creating Nx(N-1) images\n",
    "def ORIG_build_train_set(cubes, gap):\n",
    "    # import pdb; pdb.set_trace()\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "    train_imgs = []\n",
    "    train_lbls = []\n",
    "    train_x_delta = []\n",
    "    train_y_delta = []\n",
    "    # iterate over the rows and cols, essentially going over the grid of sliced cubes\n",
    "    for row in range(0, rows):\n",
    "        for col in range(0, cols):\n",
    "            # if this cube exists (could have been removed previously due to lack of data)\n",
    "            if (cubes[(col, row)] != None):\n",
    "                # for each \"current\" image in the iteration\n",
    "                curr = cubes[(col, row)]\n",
    "                # iterate over all the cubes to find all the \"other\" (adjacent) cubes\n",
    "                for adj_row in range(0, rows):\n",
    "                    for adj_col in range(0, cols):\n",
    "                        if (adj_row != row or adj_col != col):\n",
    "                            if (cubes[(adj_col, adj_row)] != None):\n",
    "                                adj = cubes[(adj_col, adj_row)]\n",
    "                                # append the adjacent image to the current image\n",
    "                                # pass the filling cubes on the right and left to pad against the gap\n",
    "                                if (gap == 0 or (\"left\" in curr.keys() and \"right\" in adj.keys())):\n",
    "                                    if (gap == 0):\n",
    "                                        conc, x_delta, y_delta = concatenate_cubes(curr, adj, slice_size)\n",
    "                                    else:\n",
    "                                        conc, x_delta, y_delta = concatenate_cubes_with_gap(curr, adj, gap, curr[\"left\"], adj[\"right\"], slice_size)\n",
    "                                    train_imgs.append(conc)\n",
    "                                    train_x_delta.append(x_delta)\n",
    "                                    train_y_delta.append(y_delta)\n",
    "                                    # if the adj image is on the same row and on the right of the curr image - it will be marked as match    \n",
    "                                    if (adj_row == row and adj_col == (col + 1)):\n",
    "                                        # mark the image as matched\n",
    "                                        train_lbls.append([0,1])\n",
    "                                        # need to enrich the set with a few more tru positive samples - so we offset \n",
    "                                        # the matched images up ad down a few times and create more matches\n",
    "                                        if (\"top\" in curr.keys() and \"top\"in adj.keys()):\n",
    "                                            for i in range(5, 101, 5):\n",
    "                                                curr1 = pad_above(curr, curr[\"top\"],i)\n",
    "                                                adj1 = pad_above(adj, adj[\"top\"],i)\n",
    "                                                if (gap == 0 or (\"left\" in curr.keys() and \"right\" in adj.keys() and \"top\" in curr[\"left\"].keys() and \"top\"in curr[\"right\"].keys())):\n",
    "                                                    if (gap == 0):\n",
    "                                                        conc, x_delta, y_delta = concatenate_cubes(curr1, adj1, slice_size)\n",
    "                                                    else:\n",
    "                                                        curr1Left = pad_above(curr[\"left\"], curr[\"left\"][\"top\"], i) # FIXIT?\n",
    "                                                        adj1Right = pad_above(adj[\"right\"], curr[\"right\"][\"top\"], i) # FIXIT?\n",
    "                                                        conc, x_delta, y_delta = concatenate_cubes_with_gap(curr1, adj1, gap, curr1Left, adj1Right, slice_size)\n",
    "                                                    train_imgs.append(conc)\n",
    "                                                    train_x_delta.append(x_delta)\n",
    "                                                    train_y_delta.append(y_delta)\n",
    "                                                    # mark the image as matched\n",
    "                                                    train_lbls.append([0,1])\n",
    "                                        if (\"bottom\" in curr.keys() and \"bottom\"in adj.keys()):\n",
    "                                            for i in range(5, 101, 5):\n",
    "                                                curr1 = pad_below(curr, curr[\"bottom\"],i)\n",
    "                                                adj1 = pad_below(adj, adj[\"bottom\"],i)\n",
    "                                                if (gap == 0 or (\"left\" in curr.keys() and \"right\" in adj.keys() and \"bottom\" in curr[\"left\"].keys() and \"bottom\"in curr[\"right\"].keys())):\n",
    "                                                    if (gap == 0):\n",
    "                                                        conc, x_delta, y_delta = concatenate_cubes(curr1, adj1, slice_size)\n",
    "                                                    else:\n",
    "                                                        curr1Left = pad_below(curr[\"left\"], curr[\"left\"][\"bottom\"], i) # FIXIT?\n",
    "                                                        adj1Right = pad_below(adj[\"right\"], curr[\"right\"][\"bottom\"], i) # FIXIT?\n",
    "                                                        conc, x_delta, y_delta = concatenate_cubes_with_gap(curr1, adj1, gap, curr1Left, adj1Right, slice_size)\n",
    "                                                    train_imgs.append(conc)\n",
    "                                                    train_x_delta.append(x_delta)\n",
    "                                                    train_y_delta.append(y_delta)\n",
    "                                                    # mark the image as matched\n",
    "                                                    train_lbls.append([0,1])\n",
    "                                        if (\"left\" in curr.keys()): # enough to check only the curr as the left of the adj is the curr\n",
    "                                            for i in range(5, 101, 5):\n",
    "                                                curr1 = pad_left(curr, curr[\"left\"],i)\n",
    "                                                adj1 = pad_left(adj, adj[\"left\"],i) # essentially the curr\n",
    "                                                if (gap == 0 or (\"left\" in curr.keys() and \"right\" in adj.keys())):\n",
    "                                                    if (gap == 0):\n",
    "                                                        conc, x_delta, y_delta = concatenate_cubes(curr1, adj1, slice_size)\n",
    "                                                    else:\n",
    "                                                        curr1Left = pad_left(curr[\"left\"], ZERO_CUBE, i) # FIXIT? + assuming the gap will not be more than 150\n",
    "                                                        adj1Right = pad_left(adj[\"right\"], ZERO_CUBE, i) # FIXIT? + assuming the gap will not be more than 150\n",
    "                                                        conc, x_delta, y_delta = concatenate_cubes_with_gap(curr1, adj1, gap, curr1Left, adj1Right, slice_size)\n",
    "                                                    train_imgs.append(conc)\n",
    "                                                    train_x_delta.append(x_delta)\n",
    "                                                    train_y_delta.append(y_delta)\n",
    "                                                    # mark the image as matched\n",
    "                                                    train_lbls.append([0,1])\n",
    "                                        if (\"right\" in adj.keys()): # enough to check only the adj as the right of the curr is the adj\n",
    "                                            for i in range(5, 101, 5):\n",
    "                                                curr1 = pad_right(curr, curr[\"right\"],i) # essentially the adj\n",
    "                                                adj1 = pad_right(adj, adj[\"right\"],i)\n",
    "                                                if (gap == 0 or (\"left\" in curr.keys() and \"right\" in adj.keys())):\n",
    "                                                    if (gap == 0):\n",
    "                                                        conc, x_delta, y_delta = concatenate_cubes(curr1, adj1, slice_size)\n",
    "                                                    else:\n",
    "                                                        curr1Left = pad_right(curr[\"left\"], ZERO_CUBE, i) # FIXIT? + assuming the gap will not be more than 150\n",
    "                                                        adj1Right = pad_right(adj[\"right\"], ZERO_CUBE, i) # FIXIT? + assuming the gap will not be more than 150\n",
    "                                                        conc, x_delta, y_delta = concatenate_cubes_with_gap(curr1, adj1, gap, curr1Left, adj1Right, slice_size)\n",
    "                                                    train_imgs.append(conc)\n",
    "                                                    train_x_delta.append(x_delta)\n",
    "                                                    train_y_delta.append(y_delta)\n",
    "                                                    # mark the image as matched\n",
    "                                                    train_lbls.append([0,1])\n",
    "                                    else:\n",
    "                                        # mark the image as not matched\n",
    "                                        train_lbls.append([1,0])\n",
    "                                \n",
    "    warnings.filterwarnings(\"default\")\n",
    "    return train_imgs, train_lbls, train_x_delta, train_y_delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [
     0,
     248,
     271,
     286
    ],
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# RUN Utility functions 2\n",
    "SAVE_PNG=False\n",
    "def save_img(path, img):\n",
    "    np.save(path, img)  \n",
    "    if SAVE_PNG:\n",
    "        plt.imsave(path+\".png\", img, cmap=plt.cm.gray)\n",
    "                    \n",
    "def VAL_add_tolerance_matches(slice_size, folder, train_imgs, train_lbls, train_x_delta, \n",
    "                              train_y_delta, curr, adj, tolerance_factor=0):\n",
    "    # need to enhance the set with a few more true positive samples\n",
    "    # allowing some up and down tolerance\n",
    "    if (\"top\" in curr.keys()):\n",
    "        for i in range(0, tolerance_factor * 10, 10):\n",
    "            if i == 0:\n",
    "                continue\n",
    "            curr1 = pad_above(curr, curr[\"top\"],i)\n",
    "            adj1 = adj\n",
    "            conc, x_delta, y_delta, x_file, y_file = VAL_concatenate_cubes(curr1, adj1, slice_size)\n",
    "            output = folder+\"1=\"+x_file+\"_\"+str(curr1[\"top_row\"])+\"_\"+str(curr1[\"left_col\"])+\"---\"+y_file+\"_\"+str(adj1[\"top_row\"])+\"_\"+str(adj1[\"left_col\"])\n",
    "            # print(\">>> MATCH >>>\"+output)\n",
    "            save_img(output, conc)\n",
    "            # print(\">>> >>> >>> SAVED\")\n",
    "            train_imgs.append(output)\n",
    "            train_x_delta.append(x_delta)\n",
    "            train_y_delta.append(y_delta)\n",
    "            # mark the image as matched\n",
    "            train_lbls.append([0,1])\n",
    "    if (\"top\" in adj.keys()):\n",
    "        for i in range(0, tolerance_factor * 10, 10):\n",
    "            if i == 0:\n",
    "                continue\n",
    "            curr1 = curr\n",
    "            adj1 = pad_above(adj, adj[\"top\"],i)\n",
    "            conc, x_delta, y_delta, x_file, y_file = VAL_concatenate_cubes(curr1, adj1, slice_size)\n",
    "            output = folder+\"1=\"+x_file+\"_\"+str(curr1[\"top_row\"])+\"_\"+str(curr1[\"left_col\"])+\"---\"+y_file+\"_\"+str(adj1[\"top_row\"])+\"_\"+str(adj1[\"left_col\"])\n",
    "            # print(\">>> MATCH >>>\"+output)\n",
    "            save_img(output, conc)\n",
    "            # print(\">>> >>> >>> SAVED\")\n",
    "            train_imgs.append(output)\n",
    "            train_x_delta.append(x_delta)\n",
    "            train_y_delta.append(y_delta)\n",
    "            # mark the image as matched\n",
    "            train_lbls.append([0,1])\n",
    "    if (\"bottom\" in curr.keys()):\n",
    "        for i in range(0, tolerance_factor * 10, 10):\n",
    "            if i == 0:\n",
    "                continue\n",
    "            curr1 = pad_below(curr, curr[\"bottom\"],i)\n",
    "            adj1 = adj\n",
    "            conc, x_delta, y_delta, x_file, y_file = VAL_concatenate_cubes(curr1, adj1, slice_size)\n",
    "            output = folder+\"1=\"+x_file+\"_\"+str(curr1[\"top_row\"])+\"_\"+str(curr1[\"left_col\"])+\"---\"+y_file+\"_\"+str(adj1[\"top_row\"])+\"_\"+str(adj1[\"left_col\"])\n",
    "            # print(\">>> MATCH >>>\"+output)\n",
    "            save_img(output, conc)\n",
    "            # print(\">>> >>> >>> SAVED\")\n",
    "            train_imgs.append(output)\n",
    "            train_x_delta.append(x_delta)\n",
    "            train_y_delta.append(y_delta)\n",
    "            # mark the image as matched\n",
    "            train_lbls.append([0,1])\n",
    "    if (\"bottom\"in adj.keys()):\n",
    "        for i in range(0, tolerance_factor * 10, 10):\n",
    "            if i == 0:\n",
    "                continue\n",
    "            curr1 = curr\n",
    "            adj1 = pad_below(adj, adj[\"bottom\"],i)\n",
    "            conc, x_delta, y_delta, x_file, y_file = VAL_concatenate_cubes(curr1, adj1, slice_size)\n",
    "            output = folder+\"1=\"+x_file+\"_\"+str(curr1[\"top_row\"])+\"_\"+str(curr1[\"left_col\"])+\"---\"+y_file+\"_\"+str(adj1[\"top_row\"])+\"_\"+str(adj1[\"left_col\"])\n",
    "            # print(\">>> MATCH >>>\"+output)\n",
    "            save_img(output, conc)\n",
    "            # print(\">>> >>> >>> SAVED\")\n",
    "            train_imgs.append(output)\n",
    "            train_x_delta.append(x_delta)\n",
    "            train_y_delta.append(y_delta)\n",
    "            # mark the image as matched\n",
    "            train_lbls.append([0,1])\n",
    "\n",
    "                            \n",
    "                \n",
    "# IMPORTANT: enrich_factor determines how many \"duplications\" of TRUE values will we have in the train set\n",
    "# This allows for a more balanced train set however, it reduces the strictness of the matches \n",
    "# i.e. (not sure why) when we have multiple nearby \"duplicates\" matches we get much more matches in the validation\n",
    "# PARAMS: enrich_factor=1 means no enrich/duplicate, 20 means duplicate by 20, every 10 pixels\n",
    "# PARAMS: tolerance_factor=0 means only match against exact horizon, each notch equals additional 10 pixels tolerance\n",
    "def NEW_build_train_set_for_binary_labeling(cubes, slice_size, folder, enrich_factor=1, tolerance_factor=0): \n",
    "    # enrich_factor is split by 2 because it is dual-sided and 1 means actually no enrichment - i.e. 0.5\n",
    "    enrich_factor = enrich_factor / 2 \n",
    "    # clean folder before starting\n",
    "    for root, dirs, files in os.walk(folder):\n",
    "        for f in files:\n",
    "            os.unlink(os.path.join(root, f))\n",
    "\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "    train_imgs = []\n",
    "    train_lbls = []\n",
    "    train_x_delta = []\n",
    "    train_y_delta = []\n",
    "    discard_c = 0\n",
    "\n",
    "    # import pdb; pdb.set_trace()\n",
    "\n",
    "    # iterate over the cubes\n",
    "    for curr in cubes:\n",
    "        # iterate over the others (effectively n^2)\n",
    "        for adj in cubes:\n",
    "            # Initial filter: what CAN be matched against what?\n",
    "            # 1 - not of the same fragment (file==fragment)\n",
    "            # 2 - they ARE of the same tear - don't want to confuse the learning with false data coming from different tears\n",
    "            # 3 - no need to test against self and avoid checking from both directions\n",
    "            if  adj[\"file\"] != curr[\"file\"] and \\\n",
    "                adj[\"tear\"] == curr[\"tear\"] and \\\n",
    "                curr[\"piece_col\"] < adj[\"piece_col\"]: \n",
    "                # last condition above - actually ignores pieces of the same col but different rows\n",
    "                # the assumption is that they are either \"not-match\" and then will tilt the balance further to not-match\n",
    "                # or they are \"somewhat-matching\" but in a way that might confuse the algorithm\n",
    "                \n",
    "                # print(\">>> >>>\"+str(curr[\"cube\"].shape)+\" <<< <<<\"+str(adj[\"cube\"].shape))\n",
    "                # append the adjacent image to the current image\n",
    "                conc, x_delta, y_delta, x_file, y_file = VAL_concatenate_cubes(curr, adj, slice_size)\n",
    "\n",
    "                train_x_delta.append(x_delta)\n",
    "                train_y_delta.append(y_delta)\n",
    "                                \n",
    "                # Condition for marking as match:\n",
    "                # 1 - the adj piece is on the same row as the curr\n",
    "                # 2 - the adj piece is just to the right of the curr\n",
    "                # 3 - the curr cube is on the right edge of the piece\n",
    "                # 4 - the adj cube is on the left edge of the piece\n",
    "                # 5 - the cubes are in the same horizon\n",
    "                if  curr[\"piece_row\"] == adj[\"piece_row\"] and \\\n",
    "                    curr[\"piece_col\"] + 1 == adj[\"piece_col\"] and \\\n",
    "                    (curr[\"col\"] != 0 or curr[\"last\"]) and \\\n",
    "                    (adj[\"col\"] == 0 or not adj[\"last\"]) and \\\n",
    "                    np.abs(x_delta) < 50: \n",
    "\n",
    "                    # print(x_delta, y_delta)\n",
    "                    \n",
    "                    # mark the image as matched\n",
    "                    output = folder+\"1=\"+x_file+\"_\"+str(curr[\"top_row\"])+\"_\"+str(curr[\"left_col\"])+\"---\"+y_file+\"_\"+str(adj[\"top_row\"])+\"_\"+str(adj[\"left_col\"])\n",
    "                    # print(\">>> MATCH >>>\"+output)\n",
    "                    save_img(output, conc)\n",
    "                    # print(\">>> >>> >>> SAVED\")\n",
    "                    train_imgs.append(output)\n",
    "                    train_lbls.append([0,1])\n",
    "\n",
    "                    #import pdb; pdb.set_trace()\n",
    "                    # TOLERANCE\n",
    "                    VAL_add_tolerance_matches(slice_size, folder, train_imgs, train_lbls, train_x_delta, \n",
    "                                              train_y_delta, curr, adj, tolerance_factor)\n",
    "                    \n",
    "                    # ENRICH/DUPLICATE\n",
    "                    # need to enrich the set with a few more true positive samples - so we offset \n",
    "                    # the matched images up and down a few times and create more matches\n",
    "                    if (\"top\" in curr.keys() and \"top\" in adj.keys()):\n",
    "                        for i in range(0, 121, int(120/enrich_factor)):\n",
    "                            if i == 0:\n",
    "                                continue\n",
    "                            curr1 = pad_above(curr, curr[\"top\"],i)\n",
    "                            adj1 = pad_above(adj, adj[\"top\"],i)\n",
    "                            conc, x_delta, y_delta, x_file, y_file = VAL_concatenate_cubes(curr1, adj1, slice_size)\n",
    "                            output = folder+\"1=\"+x_file+\"_\"+str(curr1[\"top_row\"])+\"_\"+str(curr1[\"left_col\"])+\"---\"+y_file+\"_\"+str(adj1[\"top_row\"])+\"_\"+str(adj1[\"left_col\"])\n",
    "                            # print(\">>> MATCH >>>\"+output)\n",
    "                            save_img(output, conc)\n",
    "                            # print(\">>> >>> >>> SAVED\")\n",
    "                            train_imgs.append(output)\n",
    "                            train_x_delta.append(x_delta)\n",
    "                            train_y_delta.append(y_delta)\n",
    "                            # mark the image as matched\n",
    "                            train_lbls.append([0,1])\n",
    "\n",
    "                            # TOLERANCE\n",
    "                            VAL_add_tolerance_matches(slice_size, folder, train_imgs, train_lbls, train_x_delta, \n",
    "                                                      train_y_delta, curr1, adj1, tolerance_factor)\n",
    "                            \n",
    "                    if (\"bottom\" in curr.keys() and \"bottom\"in adj.keys()):\n",
    "                        for i in range(0, 121, int(120/enrich_factor)):\n",
    "                            if i == 0:\n",
    "                                continue\n",
    "                            curr1 = pad_below(curr, curr[\"bottom\"],i)\n",
    "                            adj1 = pad_below(adj, adj[\"bottom\"],i)\n",
    "                            conc, x_delta, y_delta, x_file, y_file = VAL_concatenate_cubes(curr1, adj1, slice_size)\n",
    "                            output = folder+\"1=\"+x_file+\"_\"+str(curr1[\"top_row\"])+\"_\"+str(curr1[\"left_col\"])+\"---\"+y_file+\"_\"+str(adj1[\"top_row\"])+\"_\"+str(adj1[\"left_col\"])\n",
    "                            # print(\">>> MATCH >>>\"+output)\n",
    "                            save_img(output, conc)\n",
    "                            # print(\">>> >>> >>> SAVED\")\n",
    "                            train_imgs.append(output)\n",
    "                            train_x_delta.append(x_delta)\n",
    "                            train_y_delta.append(y_delta)\n",
    "                            # mark the image as matched\n",
    "                            train_lbls.append([0,1])\n",
    "\n",
    "                            # TOLERANCE\n",
    "                            VAL_add_tolerance_matches(slice_size, folder, train_imgs, train_lbls, train_x_delta, \n",
    "                                                      train_y_delta, curr1, adj1, tolerance_factor)\n",
    " \n",
    "                # adding a condition for marking as not-matched - we mark only the \"key\" cubes which are every 250px\n",
    "                # and not overlap - hence we reduce the ratio in favour of not matched which is enormous\n",
    "                elif int(curr[\"row\"]) == curr[\"row\"] and int(adj[\"row\"]) == adj[\"row\"]: \n",
    "                    # mark the image as not matched\n",
    "                    output = folder+\"0=\"+x_file+\"_\"+str(curr[\"top_row\"])+\"_\"+str(curr[\"left_col\"])+\"---\"+y_file+\"_\"+str(adj[\"top_row\"])+\"_\"+str(adj[\"left_col\"])\n",
    "                    # print(\"<<< nonmatch <<<\"+output)\n",
    "                    save_img(output, conc)\n",
    "                    # print(\"<<< <<< <<< SAVED\")\n",
    "                    train_imgs.append(output)\n",
    "                    train_lbls.append([1,0]) # not matched\n",
    "                \n",
    "                # discard not matched which are \n",
    "                else:\n",
    "                    discard_c += 1\n",
    "                    \n",
    "    print(\"*** MATCHED=\"+str(sum(x[1] == 1 for x in train_lbls)))\n",
    "    print(\"*** NOT MATCHED=\"+str(sum(x[0] == 1 for x in train_lbls)))\n",
    "    print(\"*** DISCARDED=\"+str(discard_c))\n",
    "    warnings.filterwarnings(\"default\")\n",
    "    return train_imgs, train_lbls, train_x_delta, train_y_delta\n",
    "\n",
    "# convert the data structure of cubes into a test set of 2 arrays of images and labels\n",
    "# each image is a concatanation of 2 images from the original cubes set, covering all combinations of images\n",
    "# effectively creating Nx(N-1) images\n",
    "def VAL_build_test_set(cubes, slice_size, folder, curr):\n",
    "    for root, dirs, files in os.walk(folder):\n",
    "        for f in files:\n",
    "            os.unlink(os.path.join(root, f))\n",
    "    # import pdb; pdb.set_trace()\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "    train_imgs = []\n",
    "    train_x_delta = []\n",
    "    train_y_delta = []\n",
    "    train_x_file = []\n",
    "    train_y_file = []\n",
    "    # iterate over the others (effectively n^2)\n",
    "    for adj in cubes:\n",
    "        #import pdb; pdb.set_trace()\n",
    "        if (adj[\"file\"] != curr[\"file\"]) and curr[\"index\"] < adj[\"index\"]: # no need to test against self and avoid checking from both directions    \n",
    "            # append the adjacent image to the current image\n",
    "            conc, x_delta, y_delta, x_file, y_file = VAL_concatenate_cubes(curr, adj, slice_size)\n",
    "            output = folder+x_file[:x_file.rfind(' ')]+\"_\"+str(curr[\"top_row\"])+\"_\"+str(curr[\"left_col\"])+\"---\"+y_file[:y_file.rfind(' ')]+\"_\"+str(adj[\"top_row\"])+\"_\"+str(adj[\"left_col\"])\n",
    "            np.save(output, conc)\n",
    "            train_imgs.append(output)\n",
    "            train_x_delta.append(x_delta)\n",
    "            train_y_delta.append(y_delta)\n",
    "            train_x_file.append(x_file)\n",
    "            train_y_file.append(y_file)\n",
    "\n",
    "    warnings.filterwarnings(\"default\")\n",
    "    return train_imgs,train_x_delta, train_y_delta, train_x_file, train_y_file\n",
    "\n",
    "def frame_to_n_by_m(orig, start_vector, end_vector, is_col):\n",
    "    max_val = np.amax(end_vector)\n",
    "    min_val = np.amin(start_vector)\n",
    "    width = max_val - min_val\n",
    "    if (is_col):\n",
    "        result = np.zeros((start_vector.size, width))\n",
    "    else:\n",
    "        result = np.zeros((width, start_vector.size))\n",
    "    \n",
    "    for i in range(0, start_vector.size):\n",
    "        if (is_col):\n",
    "            row_vec = orig[i, start_vector[i]:end_vector[i]]\n",
    "        else:\n",
    "            row_vec = orig[start_vector[i]:end_vector[i],i]\n",
    "        temp = np.lib.pad(row_vec, (start_vector[i]-min_val, max_val-end_vector[i]), 'constant', constant_values=(0.09, 0.09))\n",
    "        if (is_col):\n",
    "            if (result[i].size != width):\n",
    "                import pdb; pdb.set_trace()\n",
    "            result[i] = temp[0:width]\n",
    "        else:\n",
    "            result[:,i] = temp[0:width]\n",
    "    return min_val, result\n",
    "\n",
    "def rough_tear_line(orig, start_vector, cut_mean, is_col, chew_factor):\n",
    "    end_vector = np.empty(start_vector.size).astype(int)\n",
    "    if (is_col and np.absolute(cut_mean-orig.shape[1]) < 10):\n",
    "        end_vector.fill(orig.shape[1])\n",
    "    elif (not is_col and np.absolute(cut_mean-orig.shape[0]) < 10):\n",
    "        end_vector.fill(orig.shape[0])\n",
    "    else:\n",
    "        deviation_vector = np.random.normal(0, chew_factor, start_vector.size).astype(int)\n",
    "        end_vector[0] = cut_mean + deviation_vector[0]\n",
    "        for i in range(1, end_vector.size):\n",
    "            end_vector[i] = end_vector[i - 1] + deviation_vector[i]\n",
    "    \n",
    "    start_px, cut_piece = frame_to_n_by_m(orig, start_vector, end_vector, is_col)    \n",
    "    return start_px, cut_piece, end_vector\n",
    "\n",
    "def rough_tear_image(image, cols, rows):\n",
    "    pieces = []\n",
    "    col_width = int(image.shape[1] / cols)\n",
    "    row_height = int(image.shape[0] / rows)\n",
    "    # print(col_width, row_height)\n",
    "    next_col_start_vec = np.zeros((image.shape[0],), dtype=int)\n",
    "    for col_idx in range(0, cols):\n",
    "    #         import pdb; pdb.set_trace()\n",
    "        start_col_px, cut_column, next_col_start_vec =  rough_tear_line(image, next_col_start_vec, col_width * (col_idx + 1), True, 5)\n",
    "        next_row_start_vec = np.zeros((cut_column.shape[1],), dtype=int)\n",
    "        for row_idx in range(0, rows):\n",
    "            start_row_px, cut_piece, next_row_start_vec = rough_tear_line(cut_column, next_row_start_vec, row_height * (row_idx + 1), False, 1)\n",
    "\n",
    "            ymin, ymax, xmin, xmax = calc_min_max_coordinates_dynamic(cut_piece, cutoff=BG_2_OBJ_RATIO)\n",
    "            temp = crop(cut_piece, ymin, ymax, xmin, xmax)\n",
    "            \n",
    "            #import pdb; pdb.set_trace()\n",
    "            piece = {}\n",
    "            piece[\"orig\"] = cut_piece\n",
    "            piece[\"cut\"] = temp\n",
    "            piece[\"col\"] = col_idx\n",
    "            piece[\"row\"] = row_idx\n",
    "            piece[\"col_px\"] = start_col_px + xmin\n",
    "            piece[\"row_px\"] = start_row_px + ymin\n",
    "            pieces.append(piece)\n",
    "            \n",
    "    return pieces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# RUN Define model util functions\n",
    "\n",
    "# initialize a shaped matrix of weights with random values\n",
    "def weight_variable(shape):\n",
    "  initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "  return tf.Variable(initial)\n",
    "\n",
    "# initialize a shaped matrix of bias with random values\n",
    "def bias_variable(shape):\n",
    "  initial = tf.constant(0.1, shape=shape)\n",
    "  return tf.Variable(initial)\n",
    "\n",
    "def conv2d(x, W):\n",
    "  return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "  return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                        strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "def max_pool_1x2(x):\n",
    "  return tf.nn.max_pool(x, ksize=[1, 1, 2, 1],\n",
    "                        strides=[1, 1, 2, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2x1(x):\n",
    "  return tf.nn.max_pool(x, ksize=[1, 2, 1, 1],\n",
    "                        strides=[1, 2, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_1x1(x):\n",
    "  return tf.nn.max_pool(x, ksize=[1, 1, 1, 1],\n",
    "                        strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_5x5(x):\n",
    "  return tf.nn.max_pool(x, ksize=[1, 5, 5, 1],\n",
    "                        strides=[1, 5, 5, 1], padding='SAME')\n",
    "\n",
    "def max_pool_5x2(x):\n",
    "  return tf.nn.max_pool(x, ksize=[1, 5, 2, 1],\n",
    "                        strides=[1, 5, 2, 1], padding='SAME')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# RUN Image utility functions (external source)\n",
    "def branchedPoints(skel):\n",
    "    branch1=np.array([[2, 1, 2], [1, 1, 1], [2, 2, 2]])\n",
    "    branch2=np.array([[1, 2, 1], [2, 1, 2], [1, 2, 1]])\n",
    "    branch3=np.array([[1, 2, 1], [2, 1, 2], [1, 2, 2]])\n",
    "    branch4=np.array([[2, 1, 2], [1, 1, 2], [2, 1, 2]])\n",
    "    branch5=np.array([[1, 2, 2], [2, 1, 2], [1, 2, 1]])\n",
    "    branch6=np.array([[2, 2, 2], [1, 1, 1], [2, 1, 2]])\n",
    "    branch7=np.array([[2, 2, 1], [2, 1, 2], [1, 2, 1]])\n",
    "    branch8=np.array([[2, 1, 2], [2, 1, 1], [2, 1, 2]])\n",
    "    branch9=np.array([[1, 2, 1], [2, 1, 2], [2, 2, 1]])\n",
    "    br1=mh.morph.hitmiss(skel,branch1)\n",
    "    br2=mh.morph.hitmiss(skel,branch2)\n",
    "    br3=mh.morph.hitmiss(skel,branch3)\n",
    "    br4=mh.morph.hitmiss(skel,branch4)\n",
    "    br5=mh.morph.hitmiss(skel,branch5)\n",
    "    br6=mh.morph.hitmiss(skel,branch6)\n",
    "    br7=mh.morph.hitmiss(skel,branch7)\n",
    "    br8=mh.morph.hitmiss(skel,branch8)\n",
    "    br9=mh.morph.hitmiss(skel,branch9)\n",
    "    return br1+br2+br3+br4+br5+br6+br7+br8+br9\n",
    "\n",
    "def endPoints(skel):\n",
    "    endpoint1=np.array([[0, 0, 0],\n",
    "                        [0, 1, 0],\n",
    "                        [2, 1, 2]])\n",
    "    \n",
    "    endpoint2=np.array([[0, 0, 0],\n",
    "                        [0, 1, 2],\n",
    "                        [0, 2, 1]])\n",
    "    \n",
    "    endpoint3=np.array([[0, 0, 2],\n",
    "                        [0, 1, 1],\n",
    "                        [0, 0, 2]])\n",
    "    \n",
    "    endpoint4=np.array([[0, 2, 1],\n",
    "                        [0, 1, 2],\n",
    "                        [0, 0, 0]])\n",
    "    \n",
    "    endpoint5=np.array([[2, 1, 2],\n",
    "                        [0, 1, 0],\n",
    "                        [0, 0, 0]])\n",
    "    \n",
    "    endpoint6=np.array([[1, 2, 0],\n",
    "                        [2, 1, 0],\n",
    "                        [0, 0, 0]])\n",
    "    \n",
    "    endpoint7=np.array([[2, 0, 0],\n",
    "                        [1, 1, 0],\n",
    "                        [2, 0, 0]])\n",
    "    \n",
    "    endpoint8=np.array([[0, 0, 0],\n",
    "                        [2, 1, 0],\n",
    "                        [1, 2, 0]])\n",
    "    \n",
    "    ep1=mh.morph.hitmiss(skel,endpoint1)\n",
    "    ep2=mh.morph.hitmiss(skel,endpoint2)\n",
    "    ep3=mh.morph.hitmiss(skel,endpoint3)\n",
    "    ep4=mh.morph.hitmiss(skel,endpoint4)\n",
    "    ep5=mh.morph.hitmiss(skel,endpoint5)\n",
    "    ep6=mh.morph.hitmiss(skel,endpoint6)\n",
    "    ep7=mh.morph.hitmiss(skel,endpoint7)\n",
    "    ep8=mh.morph.hitmiss(skel,endpoint8)\n",
    "    ep = ep1+ep2+ep3+ep4+ep5+ep6+ep7+ep8\n",
    "    return ep\n",
    "\n",
    "def pruning(skeleton, size):\n",
    "    '''remove iteratively end points \"size\" \n",
    "       times from the skeleton\n",
    "    '''\n",
    "    for i in range(0, size):\n",
    "        endpoints = endPoints(skeleton)\n",
    "        endpoints = np.logical_not(endpoints)\n",
    "        skeleton = np.logical_and(skeleton,endpoints)\n",
    "    return skeleton\n",
    "\n",
    "def plot_comparison(original, filtered, filter_name):\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(8, 4), sharex=True, sharey=True)\n",
    "    ax1.imshow(original, cmap=plt.cm.gray)\n",
    "    ax1.set_title('original')\n",
    "    ax1.axis('off')\n",
    "    ax1.set_adjustable('box-forced')\n",
    "    ax2.imshow(filtered, cmap=plt.cm.gray)\n",
    "    ax2.set_title(filter_name)\n",
    "    ax2.axis('off')\n",
    "    ax2.set_adjustable('box-forced')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# RUN model_tf_deep - Define the model - 250, 125, 62, 25\n",
    "def model_tf_deep(input_width, forced_bias=0): \n",
    "    global accuracy, correct_prediction, train_step, x, y_, y_conv, keep_prob, probability, probabilities #, W_fc, b_fc, cost, y_conv_temp\n",
    "    \n",
    "    # foundation of the model - the input layer of the image 250 x input_width*2\n",
    "    x = tf.placeholder(tf.float32, [None, 250, input_width*2], \"001\")\n",
    "    x_image = tf.reshape(x, [-1,250,input_width*2,1], \"0011\") # 1 is the number of color channels\n",
    "\n",
    "    # the target digits of the model\n",
    "    y_ = tf.placeholder(tf.float32, [None, 2], \"002\") # 1\n",
    "\n",
    "    # zero convolutional layer: one input image and 32 output filters of 5x5\n",
    "    W_conv0 = weight_variable([5, 5, 1, 32])\n",
    "    b_conv0 = bias_variable([32])\n",
    "    h_conv0 = tf.nn.relu(conv2d(x_image, W_conv0) + b_conv0, \"0020\")\n",
    "    h_pool0 = max_pool_1x1(h_conv0) # size is maintained\n",
    "\n",
    "    # first convolutional layer: one input image and 32 output filters of 5x5\n",
    "    W_conv1 = weight_variable([5, 5, 32, 32])\n",
    "#     W_conv1 = weight_variable([5, 5, 1, 32])\n",
    "    b_conv1 = bias_variable([32])\n",
    "    h_conv1 = tf.nn.relu(conv2d(h_pool0, W_conv1) + b_conv1, \"0021\")\n",
    "#     h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1, \"0021\")\n",
    "    if (input_width == 250):\n",
    "        h_pool1 = max_pool_2x2(h_conv1) # size is reduced to 125x250\n",
    "    elif (input_width == 125):\n",
    "        h_pool1 = max_pool_2x1(h_conv1) # size is reduced to 125x250\n",
    "    elif (input_width == 62):\n",
    "        h_pool1 = max_pool_2x1(h_conv1) # size is reduced to 125x125\n",
    "    elif (input_width == 25):\n",
    "        h_pool1 = max_pool_2x1(h_conv1) # size is reduced to 125x50\n",
    "    else:\n",
    "        print(\"ERROR - unsupported slice width\")\n",
    "        return\n",
    "\n",
    "    # second convolutional layer: 32 input (filtered) images and 32 output filters of 5x5\n",
    "    W_conv2 = weight_variable([5, 5, 32, 32])\n",
    "    b_conv2 = bias_variable([32])\n",
    "    h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2, \"0022\")\n",
    "    if (input_width == 62):\n",
    "        h_pool2 = max_pool_1x1(h_conv2) # size is reduced to 125x125\n",
    "    elif (input_width == 25):\n",
    "        h_pool2 = max_pool_1x1(h_conv2) # size is reduced to 125x50\n",
    "    else:\n",
    "        h_pool2 = max_pool_1x2(h_conv2) # size is reduced to 125x125\n",
    "\n",
    "\n",
    "    # third convolutional layer: 32 input (filtered) images and 32 output filters of 5x5\n",
    "    W_conv3 = weight_variable([5, 5, 32, 32])\n",
    "    b_conv3 = bias_variable([32])\n",
    "    h_conv3 = tf.nn.relu(conv2d(h_pool2, W_conv3) + b_conv3, \"0023\")\n",
    "    if (input_width == 25):\n",
    "        h_pool3 = max_pool_5x2(h_conv3) # size is reduced to 25x25\n",
    "    else:\n",
    "        h_pool3 = max_pool_5x5(h_conv3) # size is reduced to 25x25\n",
    "\n",
    "\n",
    "    h_pool3_flat = tf.reshape(h_pool3, [-1, 25*25*32]) # shape as an array \n",
    "\n",
    "    # fourth layer - fully connected with input 25*25*128 and output 1024\n",
    "    W_fc1 = weight_variable([25*25*32, 1024])\n",
    "    b_fc1 = bias_variable([1024])\n",
    "    h_fc1 = tf.nn.relu(tf.matmul(h_pool3_flat, W_fc1) + b_fc1, \"0024\")\n",
    "\n",
    "    # a drop layer with probability \n",
    "    keep_prob = tf.placeholder(tf.float32, name=\"003\")\n",
    "    h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob, name=\"0031\")\n",
    "\n",
    "    #     # final layer - reduce to one \"class\" for the linear regression\n",
    "    #     W_fc = weight_variable([1024, 1]) \n",
    "    #     b_fc = bias_variable([1])         \n",
    "    #     y_conv_temp = tf.matmul(h_fc1_drop, W_fc, name=\"0032\") + b_fc\n",
    "    #     y_conv = tf.minimum(y_conv_temp, tf.constant(BREAK_VAL, tf.float32))\n",
    "\n",
    "    #     #     # minimize loss function\n",
    "    #     #     cross_entropy = tf.reduce_mean(\n",
    "    #     #       tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y_conv))\n",
    "    #     # cost = tf.reduce_sum(tf.pow(y_conv - y_, 2))/(2*BATCHES*BATCH_SIZE) # Mean squared error\n",
    "    #     cost = tf.reduce_mean(tf.square(y_conv_temp - y_), name=\"0033\") # Mean squared error\n",
    "\n",
    "    #     #     # define train step and rate\n",
    "    #     #     train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "    #     train_step = tf.train.AdamOptimizer(LEARNING_RATE).minimize(cost) # Gradient descent\n",
    "\n",
    "    #     # evaluate the prediction and the accuracy on the train test - needed only for printing during the training\n",
    "    #     correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y_,1))\n",
    "    #     accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    \n",
    "    # final layer - softmax reduction 2 outputs\n",
    "    W_fc2 = weight_variable([1024, 2])\n",
    "    b_fc2 = bias_variable([2])\n",
    "    c_fc2 = tf.constant([0, forced_bias], dtype=tf.float32)\n",
    "    y_conv = tf.matmul(h_fc1_drop, W_fc2) + b_fc2 + c_fc2\n",
    "\n",
    "    # minimize loss function\n",
    "    cross_entropy = tf.reduce_mean(\n",
    "      tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y_conv))\n",
    "\n",
    "    probability = tf.nn.softmax(y_conv,1)\n",
    "    \n",
    "    probabilities=tf.reduce_sum(probability,1)\n",
    "    \n",
    "    # define train step and rate\n",
    "    train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "\n",
    "    # evaluate the prediction and the accuracy on the train test - needed only for printing during the training\n",
    "    correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y_,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# RUN model_tf_orig - Define the model - 250, 125, 62, 25\n",
    "def model_tf_orig(input_width): \n",
    "    global accuracy, correct_prediction, train_step, x, y_, y_conv, keep_prob #, W_fc, b_fc, cost, y_conv_temp\n",
    "    \n",
    "    # foundation of the model - the input layer of the image 250 x input_width*2\n",
    "    x = tf.placeholder(tf.float32, [None, 250, input_width*2], \"001\")\n",
    "    x_image = tf.reshape(x, [-1,250,input_width*2,1], \"0011\") # 1 is the number of color channels\n",
    "\n",
    "    # the target digits of the model\n",
    "    y_ = tf.placeholder(tf.float32, [None, 2], \"002\") # 1\n",
    "\n",
    "    # zero convolutional layer: one input image and 32 output filters of 5x5\n",
    "#     W_conv0 = weight_variable([5, 5, 1, 32])\n",
    "#     b_conv0 = bias_variable([32])\n",
    "#     h_conv0 = tf.nn.relu(conv2d(x_image, W_conv0) + b_conv0, \"0020\")\n",
    "#     h_pool0 = max_pool_1x1(h_conv0) # size is maintained\n",
    "\n",
    "    # first convolutional layer: one input image and 32 output filters of 5x5\n",
    "#     W_conv1 = weight_variable([5, 5, 32, 32])\n",
    "    W_conv1 = weight_variable([5, 5, 1, 32])\n",
    "    b_conv1 = bias_variable([32])\n",
    "#     h_conv1 = tf.nn.relu(conv2d(h_pool0, W_conv1) + b_conv1, \"0021\")\n",
    "    h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1, \"0021\")\n",
    "    if (input_width == 250):\n",
    "        h_pool1 = max_pool_2x2(h_conv1) # size is reduced to 125x250\n",
    "    elif (input_width == 125):\n",
    "        h_pool1 = max_pool_2x1(h_conv1) # size is reduced to 125x250\n",
    "    elif (input_width == 62):\n",
    "        h_pool1 = max_pool_2x1(h_conv1) # size is reduced to 125x125\n",
    "    elif (input_width == 25):\n",
    "        h_pool1 = max_pool_2x1(h_conv1) # size is reduced to 125x50\n",
    "    else:\n",
    "        print(\"ERROR - unsupported slice width\")\n",
    "        return\n",
    "\n",
    "    # second convolutional layer: 32 input (filtered) images and 32 output filters of 5x5\n",
    "    W_conv2 = weight_variable([5, 5, 32, 32])\n",
    "    b_conv2 = bias_variable([32])\n",
    "    h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2, \"0022\")\n",
    "    if (input_width == 62):\n",
    "        h_pool2 = max_pool_1x1(h_conv2) # size is reduced to 125x125\n",
    "    elif (input_width == 25):\n",
    "        h_pool2 = max_pool_1x1(h_conv2) # size is reduced to 125x50\n",
    "    else:\n",
    "        h_pool2 = max_pool_1x2(h_conv2) # size is reduced to 125x125\n",
    "\n",
    "\n",
    "    # third convolutional layer: 32 input (filtered) images and 32 output filters of 5x5\n",
    "    W_conv3 = weight_variable([5, 5, 32, 32])\n",
    "    b_conv3 = bias_variable([32])\n",
    "    h_conv3 = tf.nn.relu(conv2d(h_pool2, W_conv3) + b_conv3, \"0023\")\n",
    "    if (input_width == 25):\n",
    "        h_pool3 = max_pool_5x2(h_conv3) # size is reduced to 25x25\n",
    "    else:\n",
    "        h_pool3 = max_pool_5x5(h_conv3) # size is reduced to 25x25\n",
    "\n",
    "\n",
    "    h_pool3_flat = tf.reshape(h_pool3, [-1, 25*25*32]) # shape as an array \n",
    "\n",
    "    # fourth layer - fully connected with input 25*25*128 and output 1024\n",
    "    W_fc1 = weight_variable([25*25*32, 1024])\n",
    "    b_fc1 = bias_variable([1024])\n",
    "    h_fc1 = tf.nn.relu(tf.matmul(h_pool3_flat, W_fc1) + b_fc1, \"0024\")\n",
    "\n",
    "    # a drop layer with probability \n",
    "    keep_prob = tf.placeholder(tf.float32, name=\"003\")\n",
    "    h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob, name=\"0031\")\n",
    "\n",
    "    #     # final layer - reduce to one \"class\" for the linear regression\n",
    "    #     W_fc = weight_variable([1024, 1]) \n",
    "    #     b_fc = bias_variable([1])         \n",
    "    #     y_conv_temp = tf.matmul(h_fc1_drop, W_fc, name=\"0032\") + b_fc\n",
    "    #     y_conv = tf.minimum(y_conv_temp, tf.constant(BREAK_VAL, tf.float32))\n",
    "\n",
    "    #     #     # minimize loss function\n",
    "    #     #     cross_entropy = tf.reduce_mean(\n",
    "    #     #       tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y_conv))\n",
    "    #     # cost = tf.reduce_sum(tf.pow(y_conv - y_, 2))/(2*BATCHES*BATCH_SIZE) # Mean squared error\n",
    "    #     cost = tf.reduce_mean(tf.square(y_conv_temp - y_), name=\"0033\") # Mean squared error\n",
    "\n",
    "    #     #     # define train step and rate\n",
    "    #     #     train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "    #     train_step = tf.train.AdamOptimizer(LEARNING_RATE).minimize(cost) # Gradient descent\n",
    "\n",
    "    #     # evaluate the prediction and the accuracy on the train test - needed only for printing during the training\n",
    "    #     correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y_,1))\n",
    "    #     accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    \n",
    "    # final layer - softmax reduction 2 outputs\n",
    "    W_fc2 = weight_variable([1024, 2])\n",
    "    b_fc2 = bias_variable([2])\n",
    "    y_conv = tf.matmul(h_fc1_drop, W_fc2) + b_fc2\n",
    "\n",
    "    # minimize loss function\n",
    "    cross_entropy = tf.reduce_mean(\n",
    "      tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y_conv))\n",
    "\n",
    "    # define train step and rate\n",
    "    train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "\n",
    "    # evaluate the prediction and the accuracy on the train test - needed only for printing during the training\n",
    "    correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y_,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# RUN model_tf_wide - Define the model - 250, 125, 62, 25\n",
    "def model_tf_wide(input_width): \n",
    "    global accuracy, correct_prediction, train_step, x, y_, y_conv, keep_prob #, W_fc, b_fc, cost, y_conv_temp\n",
    "    \n",
    "    # foundation of the model - the input layer of the image 250 x input_width*2\n",
    "    x = tf.placeholder(tf.float32, [None, 250, input_width*2], \"001\")\n",
    "    x_image = tf.reshape(x, [-1,250,input_width*2,1], \"0011\") # 1 is the number of color channels\n",
    "\n",
    "    # the target digits of the model\n",
    "    y_ = tf.placeholder(tf.float32, [None, 2], \"002\") # 1\n",
    "\n",
    "    # first convolutional layer: one input image and 32 output filters of 5x5\n",
    "    W_conv1 = weight_variable([5, 5, 1, 64])\n",
    "    b_conv1 = bias_variable([64])\n",
    "    h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1, \"0021\")\n",
    "    if (input_width == 250):\n",
    "        h_pool1 = max_pool_2x2(h_conv1) # size is reduced to 125x250\n",
    "    elif (input_width == 125):\n",
    "        h_pool1 = max_pool_2x1(h_conv1) # size is reduced to 125x250\n",
    "    elif (input_width == 62):\n",
    "        h_pool1 = max_pool_2x1(h_conv1) # size is reduced to 125x125\n",
    "    elif (input_width == 25):\n",
    "        h_pool1 = max_pool_2x1(h_conv1) # size is reduced to 125x50\n",
    "    else:\n",
    "        print(\"ERROR - unsupported slice width\")\n",
    "        return\n",
    "\n",
    "    # second convolutional layer: 32 input (filtered) images and 32 output filters of 5x5\n",
    "    W_conv2 = weight_variable([5, 5, 64, 64])\n",
    "    b_conv2 = bias_variable([64])\n",
    "    h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2, \"0022\")\n",
    "    if (input_width == 62):\n",
    "        h_pool2 = max_pool_1x1(h_conv2) # size is reduced to 125x125\n",
    "    elif (input_width == 25):\n",
    "        h_pool2 = max_pool_1x1(h_conv2) # size is reduced to 125x50\n",
    "    else:\n",
    "        h_pool2 = max_pool_1x2(h_conv2) # size is reduced to 125x125\n",
    "\n",
    "\n",
    "    # third convolutional layer: 32 input (filtered) images and 32 output filters of 5x5\n",
    "    W_conv3 = weight_variable([5, 5, 64, 64])\n",
    "    b_conv3 = bias_variable([64])\n",
    "    h_conv3 = tf.nn.relu(conv2d(h_pool2, W_conv3) + b_conv3, \"0023\")\n",
    "    if (input_width == 25):\n",
    "        h_pool3 = max_pool_5x2(h_conv3) # size is reduced to 25x25\n",
    "    else:\n",
    "        h_pool3 = max_pool_5x5(h_conv3) # size is reduced to 25x25\n",
    "\n",
    "\n",
    "    h_pool3_flat = tf.reshape(h_pool3, [-1, 25*25*64]) # shape as an array \n",
    "\n",
    "    # fourth layer - fully connected with input 25*25*128 and output 1024\n",
    "    W_fc1 = weight_variable([25*25*64, 2048])\n",
    "    b_fc1 = bias_variable([2048])\n",
    "    h_fc1 = tf.nn.relu(tf.matmul(h_pool3_flat, W_fc1) + b_fc1, \"0024\")\n",
    "\n",
    "    # a drop layer with probability \n",
    "    keep_prob = tf.placeholder(tf.float32, name=\"003\")\n",
    "    h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob, name=\"0031\")\n",
    "\n",
    "    #     # final layer - reduce to one \"class\" for the linear regression\n",
    "    #     W_fc = weight_variable([1024, 1]) \n",
    "    #     b_fc = bias_variable([1])         \n",
    "    #     y_conv_temp = tf.matmul(h_fc1_drop, W_fc, name=\"0032\") + b_fc\n",
    "    #     y_conv = tf.minimum(y_conv_temp, tf.constant(BREAK_VAL, tf.float32))\n",
    "\n",
    "    #     #     # minimize loss function\n",
    "    #     #     cross_entropy = tf.reduce_mean(\n",
    "    #     #       tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y_conv))\n",
    "    #     # cost = tf.reduce_sum(tf.pow(y_conv - y_, 2))/(2*BATCHES*BATCH_SIZE) # Mean squared error\n",
    "    #     cost = tf.reduce_mean(tf.square(y_conv_temp - y_), name=\"0033\") # Mean squared error\n",
    "\n",
    "    #     #     # define train step and rate\n",
    "    #     #     train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "    #     train_step = tf.train.AdamOptimizer(LEARNING_RATE).minimize(cost) # Gradient descent\n",
    "\n",
    "    #     # evaluate the prediction and the accuracy on the train test - needed only for printing during the training\n",
    "    #     correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y_,1))\n",
    "    #     accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    \n",
    "    # final layer - softmax reduction 2 outputs\n",
    "    W_fc2 = weight_variable([2048, 2])\n",
    "    b_fc2 = bias_variable([2])\n",
    "    y_conv = tf.matmul(h_fc1_drop, W_fc2) + b_fc2\n",
    "\n",
    "    # minimize loss function\n",
    "    cross_entropy = tf.reduce_mean(\n",
    "      tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y_conv))\n",
    "\n",
    "    # define train step and rate\n",
    "    train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "\n",
    "    # evaluate the prediction and the accuracy on the train test - needed only for printing during the training\n",
    "    correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y_,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# RUN train\n",
    "def train(train_imgs, train_lbls, output_model, input_model=\"\"):\n",
    "    print(\"#####################################################################\")\n",
    "    print(\"TRAINING:\")\n",
    "    print(\"MODEL:\"+output_model)\n",
    "    print(\"#####################################################################\")\n",
    "\n",
    "    from random import randrange\n",
    "    \n",
    "    # TRAIN Prepare the session\n",
    "\n",
    "    # create a saver object\n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "    # start session and initialize variables\n",
    "    sess = tf.InteractiveSession()\n",
    "    if input_model != \"\":\n",
    "        # Restore variables from disk.\n",
    "        saver.restore(sess, input_model)\n",
    "        print(\"Model restored.\")\n",
    "    else:\n",
    "        sess.run(tf.initialize_all_variables())\n",
    "\n",
    "    # TRAIN Train the model\n",
    "    x_batch = []\n",
    "    y_batch = []\n",
    "    # run the train batches\n",
    "    for i in range(BATCHES):\n",
    "        x_batch = []\n",
    "        y_batch = []\n",
    "        for _ in range(BATCH_SIZE):\n",
    "            random_index = randrange(0,len(train_imgs))\n",
    "            image = np.load(train_imgs[random_index]+\".npy\")\n",
    "            x_batch.append(image)\n",
    "            y_batch.append(train_lbls[random_index])\n",
    "\n",
    "        # train\n",
    "        # print(\"step %d\"%(i))\n",
    "        train_step.run(feed_dict={x: x_batch, y_: y_batch, keep_prob: 0.5})\n",
    "\n",
    "        # print the accuracy thus far\n",
    "        if (i+1)%50 == 0:\n",
    "            train_accuracy = accuracy.eval(feed_dict={\n",
    "                x:x_batch, y_: y_batch, keep_prob: 1.0})\n",
    "            print(\"step %d, training accuracy %g\"%(i, train_accuracy))\n",
    "\n",
    "\n",
    "    print(\"Optimization Finished!\")\n",
    "    train_accuracy = accuracy.eval(feed_dict={\n",
    "        x:x_batch, y_: y_batch, keep_prob: 1.0})\n",
    "    print(\"step %d, training accuracy %g\"%(i, train_accuracy))\n",
    "\n",
    "    # Save the variables to disk.\n",
    "    save_path = saver.save(sess, output_model)\n",
    "    print(\"Model saved in file: %s\" % save_path)\n",
    "\n",
    "    # Close the Session when we're done. If un-commented - need to run next bock of restore...\n",
    "    sess.close()   \n",
    "    print(\"#####################################################################\")\n",
    "    print(\"TRAINING ENDED\")\n",
    "    print(\"#####################################################################\")\n",
    "    print(\" \")\n",
    "    print(\" \")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# RUN pre_process test\n",
    "def pre_process(folder, crops_data):\n",
    "    print(\"#####################################################################\")\n",
    "    print(\"PRE_PROCESS:\"+folder)\n",
    "    print(\"#####################################################################\")\n",
    "\n",
    "    # READ crops\n",
    "    crops = {}\n",
    "    with open(crops_data) as csvfile:\n",
    "        reader = csv.DictReader(csvfile, fieldnames=(\"file\",\"x_start\",\"y_start\",\"x_end\",\"y_end\",\"rotate\",\"horiz\",\"upside\"))\n",
    "        next(reader)\n",
    "        for row in reader:\n",
    "            row['name'] = row['file'][row['file'].rfind('/')+1:]\n",
    "            row['short_name'] = row['file'].split(\"/\")[5] # stay with the folder name\n",
    "            row['short_name'] = row['short_name'].split(\"-\")\n",
    "            row['short_name'] = row['short_name'][0] + row['short_name'][1] # set the short name...\n",
    "            row['x_start'] = int(row['x_start'])\n",
    "            row['col_px'] = int(row['x_start'])\n",
    "            row['y_start'] = int(row['y_start'])\n",
    "            row['row_px'] = int(row['y_start'])\n",
    "            row['x_end'] = int(row['x_end'])\n",
    "            row['y_end'] = int(row['y_end'])\n",
    "            row['rotate'] = True if row['rotate'] == 'True' else False\n",
    "            # import pdb; pdb.set_trace()\n",
    "            crops[row['name']] = row\n",
    "\n",
    "    result = []\n",
    "    \n",
    "    for root, dirs, files in os.walk(folder):\n",
    "        for file_ in files:\n",
    "            # Read the image\n",
    "            # image = img.imread(os.path.join(root, file_))\n",
    "            img_name = file_[:file_.rfind('.')]\n",
    "            image = np.load(os.path.join(root, file_))\n",
    "            # import pdb; pdb.set_trace()\n",
    "            cubes = VAL_slice_to_static_slices(file_, image, crops[img_name])\n",
    "            print(\"File: %s >>> cubes: %d\"%(file_, len(cubes)))\n",
    "            result.extend(cubes)\n",
    "    \n",
    "    return result\n",
    "    print(\"#####################################################################\")\n",
    "    print(\"PRE_PROCESS ENDED\")\n",
    "    print(\"#####################################################################\")\n",
    "    print(\" \")\n",
    "    print(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# RUN pre_process_training - crop image, then tear it randomly to various tears, then per tear create cubes out of the edges, return cube set\n",
    "def pre_process_training(img_name, x_start=X_START, x_end=X_END, y_start=Y_START, y_end=Y_END):\n",
    "    print(\"#####################################################################\")\n",
    "    print(\"PRE_PROCESS:\"+img_name)\n",
    "    print(\"#####################################################################\")\n",
    "    short_name = img_name[:img_name.rfind('-D')]\n",
    "    image = read_and_crop(img_name, x_start, x_end, y_start, y_end)\n",
    "    result = []\n",
    "    \n",
    "    # clean the output fragments folder before writing a new set of artificial fragments into it\n",
    "    for root, dirs, files in os.walk(ROOT_FOLDER+\"fragments/\"):\n",
    "        for f in files:\n",
    "            os.unlink(os.path.join(root, f))\n",
    "\n",
    "    \n",
    "    for col_cut in range(3, 9): # 3...10\n",
    "        for row_cut in range(2, 6): # 2...5\n",
    "            print(\"PRE_PROCESS:::\"+\"TEAR_\"+str(col_cut)+\"X\"+str(row_cut))\n",
    "            pieces = rough_tear_image(image, col_cut, row_cut)\n",
    "            \n",
    "            for piece in pieces:\n",
    "                # print(\"PRE_PROCESS:::\"+\"PIECE_\"+str(piece[\"col\"])+\"X\"+str(piece[\"row\"]))\n",
    "                fragment_name = short_name + \"_TEAR_\"+str(col_cut)+\"X\"+str(row_cut)+\"_PIECE_\"+str(piece[\"col\"])+\"X\"+str(piece[\"row\"])\n",
    "                fragment_file_name = short_name + \"_\"+str(col_cut)+\"X\"+str(row_cut)+\"_\"+str(piece[\"col\"])+\"X\"+str(piece[\"row\"])\n",
    "                # import pdb; pdb.set_trace()\n",
    "                plt.imsave(os.path.join(ROOT_FOLDER+\"fragments/\",fragment_file_name+\".jpg\"), piece[\"cut\"], cmap=plt.cm.gray)\n",
    "                cubes = VAL_slice_TEAR_to_static_slices(fragment_name, piece)\n",
    "                for cube in cubes:\n",
    "                    cube[\"tear\"] = str(col_cut)+\"X\"+str(row_cut)\n",
    "                    cube[\"piece_col\"] = piece[\"col\"]\n",
    "                    cube[\"piece_row\"] = piece[\"row\"]\n",
    "                # print(\"File: %s >>> cubes: %d\"%(file_, len(cubes)))\n",
    "                result.extend(cubes)\n",
    "    \n",
    "    return result\n",
    "    print(\"#####################################################################\")\n",
    "    print(\"PRE_PROCESS ENDED\")\n",
    "    print(\"#####################################################################\")\n",
    "    print(\" \")\n",
    "    print(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def validate1(cubes, model, slice_size, folder, curr_cube):    \n",
    "    # VALIDATE prepare the data sets\n",
    "    test_imgs, test_x_delta, test_y_delta, test_x_file, test_y_file = VAL_build_test_set(cubes, slice_size, folder, curr_cube)\n",
    "    print(\"loaded %d images\"%(len(test_imgs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "code_folding": [
     0,
     26
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def helper_name_extractor(first, second):\n",
    "    second = second.split(\".\")[0] # get rid of the suffix\n",
    "\n",
    "    # split the first file name and calc the row and col\n",
    "    split = first.split(\"_\")\n",
    "    firstNameOrig = split[0]\n",
    "    firstX = int(split[2])\n",
    "    firstCol = 0 if firstX < 100 else 1\n",
    "    split = firstNameOrig.split(\"-\")\n",
    "    first = split[0] + split[1]\n",
    "\n",
    "    # split the second file name and calc the row and col\n",
    "    split = second.split(\"_\")\n",
    "    secondNameOrig = split[0]\n",
    "    secondX = int(split[2])\n",
    "    secondCol = 0 if secondX < 100 else 1\n",
    "    split = secondNameOrig.split(\"-\")\n",
    "    second = split[0] + split[1]\n",
    "\n",
    "    fragmentKey = first + \"_\" + second\n",
    "\n",
    "    fragmentAndSideKey = first + \"_\" + str(firstCol) \\\n",
    "        + \"_\" + second + \"_\" + str(secondCol)\n",
    "        \n",
    "    return fragmentKey, fragmentAndSideKey\n",
    "    \n",
    "def helper_split_name(concatName):\n",
    "    # /home/il239838/files/train_concats3/PX303-Fg006-V-C02-R02_TEAR_5X3_PIECE_3X2_870_1745---PX303-Fg006-V-C02-R02_TEAR_5X3_PIECE_4X2_620_50\n",
    "    concatName = concatName[concatName.rfind('/')+1:]\n",
    "\n",
    "    # PX303-Fg006-V-C02-R02_TEAR_5X3_PIECE_3X2_870_1745---PX303-Fg006-V-C02-R02_TEAR_5X3_PIECE_4X2_620_50\n",
    "    firstName = concatName[0:concatName.find('---')]\n",
    "    secondName = concatName[concatName.find('---')+3:]\n",
    "\n",
    "    return firstName, secondName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def validate2(folder, model, slice_size):\n",
    "    test_imgs = []\n",
    "    test_x_file = []\n",
    "    test_y_file = []\n",
    "    the_root = \"\"\n",
    "    for root, dirs, files in os.walk(folder):\n",
    "        the_root = root\n",
    "        for file_ in files:\n",
    "            test_imgs.append( os.path.join(root, file_) )\n",
    "            test_x_file.append(file_[:file_.rfind('---P')])\n",
    "            test_y_file.append(file_[file_.rfind('---P')+3:])\n",
    "            \n",
    "    print(len(test_imgs))\n",
    "    \n",
    "    # VALIDATE Prepare a test session \n",
    "\n",
    "    # Add ops to save and restore all the variables.\n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "    # start session and initialize variables\n",
    "    sess = tf.InteractiveSession()\n",
    "\n",
    "    # Restore variables from disk.\n",
    "    saver.restore(sess, model)\n",
    "    print(\"Model restored.\")\n",
    "\n",
    "    # VALIDATE Validate the model\n",
    "\n",
    "    # import pdb; pdb.set_trace()\n",
    "    v1t = []\n",
    "    count = 0\n",
    "    length = len(test_imgs)\n",
    "    batch = 50\n",
    "    x_batch = []\n",
    "    # change the ranges in the loop below - first number is the start point (multiplied by batch size)\n",
    "    # second number is the end point (multiplied by batch size)\n",
    "    # third number is the jump from batch to batch\n",
    "    # use the length about to set the batch length\n",
    "    for start in range(0, length, batch):\n",
    "        for i in range(start, start+batch):\n",
    "            if (i < length):\n",
    "                image = np.load(test_imgs[i])\n",
    "                x_batch.append(image)\n",
    "                count += 1\n",
    "\n",
    "        # print(\"Validating start at #%d end at %d\"%(start*batch,(start+length)*batch))\n",
    "        my_prediction=tf.argmax(y_conv,1)\n",
    "        v1 = my_prediction.eval(feed_dict={x:x_batch, keep_prob: 1.0})\n",
    "        v1t = np.concatenate((v1t, v1), axis=0)\n",
    "        x_batch = []\n",
    "        if (start+batch) % 500 == 0:\n",
    "            print(\">>> step %d\"%(start+batch))\n",
    "\n",
    "\n",
    "    match_indexes = np.nonzero(v1t)[0]\n",
    "    A = np.array(test_x_file)\n",
    "    B = np.array(test_y_file)\n",
    "    C = np.array(test_imgs)\n",
    "    match_x_files = A[match_indexes]\n",
    "    match_y_files = B[match_indexes]\n",
    "    match_images = C[match_indexes]\n",
    "    \n",
    "    # CURRENTLY no need in saving the matched cubes since we can settle for the stats of the matched cubes    \n",
    "    #     for matched_img in match_images:\n",
    "    #         load_img = np.load(matched_img)\n",
    "    #         plt.imsave(os.path.join(VOL_FOLDER+ \"matched/\",matched_img[matched_img.rfind('/')+1:]+\".png\"), load_img, cmap=plt.cm.gray)\n",
    "    \n",
    "    for root, dirs, files in os.walk(folder):\n",
    "        for file_ in files:\n",
    "            os.remove( os.path.join(root, file_) ) # delete it from the FS\n",
    "         \n",
    "    print(\"FOUND Matches #: \" + str(len(match_indexes)))    \n",
    "    \n",
    "    #     with open('pairs_all.csv', 'a') as csvfile:\n",
    "    #         csvout = csv.writer(csvfile)\n",
    "    #         for idx, test_img in enumerate(test_imgs):\n",
    "    #             # print(\"MATCH %s === %s\"%(test_imgs[match_index], train_lbls[match_index]))\n",
    "    #             match_class = 0\n",
    "    #             if idx in match_indexes:\n",
    "    #                 match_class = 1\n",
    "    #             csvout.writerow([test_img, match_class])\n",
    "    #             # plt.imsave(\"match_\"+match_index+\".jpg\", C[match_index])\n",
    "\n",
    "    for idx, test_img in enumerate(test_imgs):\n",
    "        first_name, second_name = helper_split_name(test_img)\n",
    "        fragmentKey, framentAndSideKey = helper_name_extractor(first_name, second_name)\n",
    "        if fragmentKey not in fragment_counters:\n",
    "            fragment_counters[fragmentKey] = 0\n",
    "        if framentAndSideKey not in fragment_and_side_counters:\n",
    "            fragment_and_side_counters[framentAndSideKey] = 0\n",
    "        fragment_counters[fragmentKey] += 1\n",
    "        fragment_and_side_counters[framentAndSideKey] += 1\n",
    "        \n",
    "    with open('pairs_matches.csv', 'a') as csvfile:\n",
    "        csvout = csv.writer(csvfile)\n",
    "        for match_index in match_indexes:\n",
    "            fragmentKey, framentAndSideKey = helper_name_extractor(test_x_file[match_index], test_y_file[match_index])\n",
    "            csvout.writerow([test_x_file[match_index], test_y_file[match_index], fragment_counters[fragmentKey], fragment_and_side_counters[framentAndSideKey]])\n",
    "\n",
    "    # Close the Session when we're done.\n",
    "    sess.close()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def validate2_for_cross_validation(test_imgs, test_lbls, model, max_samples=0):\n",
    "    print(len(test_imgs))\n",
    "    \n",
    "    # VALIDATE Prepare a test session \n",
    "\n",
    "    # Add ops to save and restore all the variables.\n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "    # start session and initialize variables\n",
    "    sess = tf.InteractiveSession()\n",
    "\n",
    "    # Restore variables from disk.\n",
    "    saver.restore(sess, model)\n",
    "    print(\"Model restored.\")\n",
    "\n",
    "    # VALIDATE Validate the model\n",
    "\n",
    "    count = 0\n",
    "    se = 0\n",
    "    st = 0\n",
    "    v1t = []\n",
    "    v2t = []\n",
    "    v1tt = []\n",
    "    v2tt = []\n",
    "    length = len(test_imgs)\n",
    "    if max_samples != 0:\n",
    "        length = max_samples\n",
    "    batch = 100\n",
    "    x_batch = []\n",
    "    y_batch = []\n",
    "    # change the ranges in the loop below - first number is the start point (multiplied by batch size)\n",
    "    # second number is the end point (multiplied by batch size)\n",
    "    # third number is the jump from batch to batch\n",
    "    # use the length about to set the batch length\n",
    "    for start in range(0, length, batch):\n",
    "        for i in range(start, start+batch):\n",
    "            if (i < length):\n",
    "                image = np.load(test_imgs[i]+\".npy\")\n",
    "                x_batch.append(image)\n",
    "                y_batch.append(train_lbls[i])                \n",
    "                \n",
    "        # print the accuracy thus far\n",
    "    #         train_accuracy = accuracy.eval(feed_dict={\n",
    "    #             x:x_batch, y_: y_batch, keep_prob: 1.0})\n",
    "    #         print(\"step %d, training accuracy %g\"%(i, train_accuracy))\n",
    "\n",
    "        # print(\"Validating start at #%d end at %d\"%(start*batch,(start+length)*batch))\n",
    "    #         my_prediction=tf.argmax(y_conv,1)\n",
    "    #         v1 = my_prediction.eval(feed_dict={x:x_batch, keep_prob: 1.0})\n",
    "    #         v1t = np.concatenate((v1t, v1), axis=0)\n",
    "\n",
    "        ######## printing the predictions and their normalized values\n",
    "        # print(\"y_conv=\"+str(y_conv.eval(feed_dict={x:x_batch, y_: y_batch, keep_prob: 1.0})))\n",
    "        # print(\"probability=\"+str(probability.eval(feed_dict={x:x_batch, y_: y_batch, keep_prob: 1.0})))\n",
    "        # print(\"probabilities=\"+str(probabilities.eval(feed_dict={x:x_batch, y_: y_batch, keep_prob: 1.0})))\n",
    "        \n",
    "        my_prediction=tf.argmax(y_conv,1)\n",
    "        my_target=tf.argmax(y_,1)\n",
    "        v1 = my_prediction.eval(feed_dict={x:x_batch, y_: y_batch, keep_prob: 1.0})\n",
    "        v2 = my_target.eval(feed_dict={x:x_batch, y_: y_batch, keep_prob: 1.0})\n",
    "        v1t = np.concatenate((v1t, v1), axis=0)\n",
    "        v2t = np.concatenate((v2t, v2), axis=0)\n",
    "\n",
    "        c1 = np.sum(np.absolute(np.subtract(v2, v1)))\n",
    "        c2 = np.sum(np.absolute(v2))\n",
    "        se += c1\n",
    "        st += c2\n",
    "\n",
    "        x_batch = []\n",
    "        y_batch = []\n",
    "        print(\">>> step %d\"%(start+batch))\n",
    "        \n",
    "        count += ((i+1) - start)\n",
    "        precision, recall, f_score, support = precision_recall_fscore_support(v2t, v1t, average='binary')\n",
    "        print(\"step %d-%d, precision %f, recall %f, f_score %f\"%(start, i, precision, recall, f_score))\n",
    "        # print(\"Accumulated total true = %d\"%(st));\n",
    "        # print(\"Accumulated total error rate = %f\"%(se/count));\n",
    "        # v1tt = np.concatenate((v1tt, v1t), axis=0)\n",
    "        # v2tt = np.concatenate((v2tt, v2t), axis=0)\n",
    "        print(\"=== total %d match %d\"%(count, len(np.nonzero(v1t)[0])))\n",
    "\n",
    "    precision, recall, f_score, support = precision_recall_fscore_support(v2t, v1t, average='binary')\n",
    "    print(\"TOTAL %d, precision %f, recall %f, f_score %f\"%(count, precision, recall, f_score))\n",
    "    print(\"TOTAL true = %d\"%(st));\n",
    "    print(\"TOTAL error rate = %f\"%(se/count));\n",
    "    \n",
    "    match_indexes = np.nonzero(v1t)[0]\n",
    "    C = np.array(test_imgs)\n",
    "    match_images = C[match_indexes]\n",
    "    \n",
    "    # for matched_img in match_images:\n",
    "    #    load_img = np.load(matched_img+\".npy\")\n",
    "    #    plt.imsave(os.path.join(ROOT_FOLDER+\"synt_matched/\",matched_img[matched_img.rfind('/')+1:]+\".png\"), load_img, cmap=plt.cm.gray)\n",
    "\n",
    "    with open('synt_all.csv', 'a') as csvfile:\n",
    "        csvout = csv.writer(csvfile)\n",
    "        for idx, test_img in enumerate(test_imgs):\n",
    "            # print(\"MATCH %s === %s\"%(test_imgs[match_index], train_lbls[match_index]))\n",
    "            match_class = 0\n",
    "            if idx in match_indexes:\n",
    "                match_class = 1\n",
    "            csvout.writerow([test_img, train_lbls[idx], match_class])\n",
    "            # plt.imsave(\"match_\"+match_index+\".jpg\", C[match_index])\n",
    "\n",
    "    with open('synt_matches.csv', 'a') as csvfile:\n",
    "        csvout = csv.writer(csvfile)\n",
    "        for match_index in match_indexes:\n",
    "            # print(\"MATCH %s === %s\"%(test_imgs[match_index], train_lbls[match_index]))\n",
    "            csvout.writerow([test_imgs[match_index], train_lbls[match_index]])\n",
    "            # plt.imsave(\"match_\"+match_index+\".jpg\", C[match_index])\n",
    "\n",
    "    # Close the Session when we're done.\n",
    "    sess.close()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def iter_validate(cubes, model, slice_size, folder):\n",
    "    print(\"#####################################################################\")\n",
    "    print(\"VALIDATING\")\n",
    "    print(\"#####################################################################\")\n",
    "    cubes_len = len(cubes)\n",
    "    count = 0\n",
    "    # iterate over the cubes\n",
    "    for curr in cubes:\n",
    "        if count > 199 and count < 300: ### TEMP LIMITATION\n",
    "            print(\"### %s ### CUBE:%s\"%(count, curr[\"file\"]+\"_\"+str(curr[\"top_row\"])+\"_\"+str(curr[\"left_col\"])))\n",
    "            validate1(cubes, model, slice_size, folder, curr)\n",
    "            validate2(folder, model, slice_size)\n",
    "        count += 1\n",
    "        \n",
    "    print(\"#####################################################################\")\n",
    "    print(\"VALIDATION ENDED\")\n",
    "    print(\"#####################################################################\")\n",
    "    print(\" \")\n",
    "    print(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def run_all(folder, model, slice_size):\n",
    "    model_tf(slice_size)\n",
    "    cubes_set = pre_process(folder)\n",
    "    validate(cubes_set, model, slice_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# HELPER block\n",
    "# image = read_and_crop(\"PX303/FG001/PX303-Fg001-V-C01-R01-D05032015-T112602-ML924__012.jpg\")\n",
    "## image = read_and_crop(\"PX303/FG004/PX303-Fg004-V-C01-R01-D08032015-T110900-ML924__012.jpg\", 100, -1, 400, -1)\n",
    "# image = read_and_crop(\"PX303/FG004/PX303-Fg004-V-C01-R02-D08032015-T105147-ML924__012.jpg\")\n",
    "# image = read_and_crop(\"PX303/FG004/PX303-Fg004-V-C02-R01-D08032015-T110025-ML924__012.jpg\")\n",
    "# image = read_and_crop(\"PX303/FG004/PX303-Fg004-V-C02-R02-D08032015-T105553-ML924__012.jpg\")\n",
    "# image = read_and_crop(\"PX303/FG006/PX303-Fg006-V-C01-R01-D08032015-T120605-ML924__012.jpg\")\n",
    "# image = read_and_crop(\"PX303/FG006/PX303-Fg006-V-C01-R02-D08032015-T115230-ML924__012.jpg\")\n",
    "# image = read_and_crop(\"PX303/FG006/PX303-Fg006-V-C02-R01-D08032015-T120158-ML924__012.jpg\")\n",
    "##image = read_and_crop(\"PX303/FG006/PX303-Fg006-V-C02-R02-D08032015-T115704-ML924__012.jpg\", 0, 6200, 0, 4400)\n",
    "##plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_train_from_disk(path):\n",
    "    train_imgs = []\n",
    "    train_lbls = []\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for file_ in files:\n",
    "            file_name = os.path.join(root, file_)\n",
    "            file_name = file_name[:file_name.rfind(\".\")]\n",
    "            train_imgs.append(file_name)\n",
    "            train_lbls.append([1,0] if file_.startswith(\"0=\") else [0,1])\n",
    "    return train_imgs, train_lbls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#####################################################################\n",
      "PRE_PROCESS:/home/il239838/files/cropped2/\n",
      "#####################################################################\n",
      "File: P597-Fg006-V-C01-R01-D30112014-T111958-ML638 _018.jpg.npy >>> cubes: 27\n",
      "File: P597-Fg056-V-C01-R01-D01122014-T134220-ML638 _018.jpg.npy >>> cubes: 4\n",
      "File: P597-Fg052-V-C01-R01-D01122014-T130337-ML638 _018.jpg.npy >>> cubes: 2\n",
      "File: P593-Fg018-V-C01-R01-D31122013-T095423-ML638 _018.jpg.npy >>> cubes: 25\n",
      "File: P596-Fg003-V-C01-R01-D19012014-T121734-ML638 _018.jpg.npy >>> cubes: 4\n",
      "File: P598-Fg032-V-C01-R01-D08012014-T094343-ML638 _018.jpg.npy >>> cubes: 10\n",
      "File: P597-Fg017-V-C01-R01-D30112014-T135628-ML638 _018.jpg.npy >>> cubes: 2\n",
      "File: P597-Fg034-V-C01-R01-D01122014-T093849-ML638 _018.jpg.npy >>> cubes: 3\n",
      "File: P596-Fg049-V-C01-R01-D20012014-T150129-ML638 _018.jpg.npy >>> cubes: 2\n",
      "File: P596-Fg071-V-C01-R01-D22012014-T124942-ML638 _018.jpg.npy >>> cubes: 2\n",
      "File: P589-Fg010-V-C01-R01-D12022013-T124806-ML638 _018.jpg.npy >>> cubes: 26\n",
      "File: P598-Fg026-V-C01-R01-D07012014-T150637-ML638 _018.jpg.npy >>> cubes: 4\n",
      "File: P593-Fg020-V-C01-R01-D31122013-T101137-ML638 _018.jpg.npy >>> cubes: 2\n",
      "File: P597-Fg069-V-C01-R01-D02122014-T092736-ML638 _018.jpg.npy >>> cubes: 8\n",
      "File: P589-Fg011-V-C01-R01-D12022013-T125637-ML638 _018.jpg.npy >>> cubes: 41\n",
      "File: P597-Fg013-V-C01-R01-D30112014-T131041-ML638 _018.jpg.npy >>> cubes: 32\n",
      "File: P597-Fg036-V-C01-R01-D01122014-T095519-ML638 _018.jpg.npy >>> cubes: 5\n",
      "File: P598-Fg031-V-C01-R01-D08012014-T093535-ML638 _018.jpg.npy >>> cubes: 10\n",
      "File: P597-Fg037-V-C01-R01-D01122014-T100405-ML638 _018.jpg.npy >>> cubes: 12\n",
      "File: P596-Fg043-V-C01-R01-D20012014-T140533-ML638 _018.jpg.npy >>> cubes: 4\n",
      "File: P596-Fg044-V-C01-R01-D20012014-T141552-ML638 _018.jpg.npy >>> cubes: 11\n",
      "File: P589-Fg012-V-C01-R01-D12022013-T130509-ML638 _018.jpg.npy >>> cubes: 34\n",
      "File: P596-Fg010-V-C01-R01-D19012014-T140114-ML638 _018.jpg.npy >>> cubes: 6\n",
      "File: P596-Fg004-V-C01-R01-D19012014-T122811-ML638 _018.jpg.npy >>> cubes: 3\n",
      "File: P590-Fg033-V-C01-R01-D14022013-T152702-ML638 _018.jpg.npy >>> cubes: 15\n",
      "File: P597-Fg033-V-C01-R01-D01122014-T093105-ML638 _018.jpg.npy >>> cubes: 8\n",
      "File: P597-Fg029-V-C01-R01-D30112014-T154333-ML638 _018.jpg.npy >>> cubes: 10\n",
      "File: P590-Fg023-V-C01-R01-D14022013-T123034-ML638 _018.jpg.npy >>> cubes: 17\n",
      "File: P597-Fg072-V-C01-R01-D02122014-T100826-ML638 _018.jpg.npy >>> cubes: 6\n",
      "File: P596-Fg059-V-C01-R01-D22012014-T104211-ML638 _018.jpg.npy >>> cubes: 0\n",
      "File: P597-Fg044-V-C01-R01-D01122014-T110411-ML638 _018.jpg.npy >>> cubes: 8\n",
      "File: P589-Fg008-V-C01-R01-D12022013-T123020-ML638 _018.jpg.npy >>> cubes: 18\n",
      "File: P593-Fg003-V-C01-R01-D30122013-T145210-ML638 _018.jpg.npy >>> cubes: 40\n",
      "File: P596-Fg027-V-C01-R01-D20012014-T103313-ML638 _018.jpg.npy >>> cubes: 9\n",
      "File: P596-Fg006-V-C01-R01-D19012014-T132029-ML638 _018.jpg.npy >>> cubes: 9\n",
      "File: P590-Fg022-V-C01-R01-D14022013-T122020-ML638 _018.jpg.npy >>> cubes: 6\n",
      "File: P590-Fg025-V-C01-R01-D14022013-T125734-ML638 _018.jpg.npy >>> cubes: 12\n",
      "File: P596-Fg075-V-C01-R01-D22012014-T132331-ML638 _018.jpg.npy >>> cubes: 10\n",
      "File: P596-Fg005-V-C01-R01-D19012014-T131036-ML638 _018.jpg.npy >>> cubes: 17\n",
      "File: P596-Fg016-V-C01-R01-D10122014-T093231-ML638 _018.jpg.npy >>> cubes: 4\n",
      "File: P596-Fg077-V-C01-R01-D22012014-T134039-ML638 _018.jpg.npy >>> cubes: 12\n",
      "File: P598-Fg006-V-C01-R01-D07012014-T114255-ML638 _018.jpg.npy >>> cubes: 35\n",
      "File: P596-Fg019-V-C01-R01-D19012014-T152047-ML638 _018.jpg.npy >>> cubes: 4\n",
      "File: P593-Fg011-V-C01-R01-D31122013-T085542-ML638 _018.jpg.npy >>> cubes: 16\n",
      "File: P598-Fg008-V-C01-R01-D07012014-T123911-ML638 _018.jpg.npy >>> cubes: 39\n",
      "File: P597-Fg001-V-C01-R01-D30112014-T101313-ML638 _018.jpg.npy >>> cubes: 21\n",
      "File: P597-Fg020-V-C01-R01-D30112014-T142106-ML638 _018.jpg.npy >>> cubes: 10\n",
      "File: P590-Fg030-V-C01-R01-D14022013-T145646-ML638 _018.jpg.npy >>> cubes: 46\n",
      "File: P597-Fg043-V-C01-R01-D01122014-T105546-ML638 _018.jpg.npy >>> cubes: 7\n",
      "File: P590-Fg028-V-C01-R01-D14022013-T143331-ML638 _018.jpg.npy >>> cubes: 40\n",
      "File: P597-Fg042-V-C01-R01-D01122014-T104633-ML638 _018.jpg.npy >>> cubes: 17\n",
      "File: P597-Fg040-V-C01-R01-D01122014-T103014-ML638 _018.jpg.npy >>> cubes: 7\n",
      "File: P590-Fg004-V-C01-R01-D13022013-T142314-ML638 _018.jpg.npy >>> cubes: 16\n",
      "File: P589-Fg007-V-C01-R01-D12022013-T122152-ML638 _018.jpg.npy >>> cubes: 14\n",
      "File: P598-Fg033-V-C01-R01-D08012014-T095124-ML638 _018.jpg.npy >>> cubes: 16\n",
      "File: P596-Fg009-V-C01-R01-D19012014-T134823-ML638 _018.jpg.npy >>> cubes: 9\n",
      "File: P596-Fg063-V-C01-R01-D22012014-T111621-ML638 _018.jpg.npy >>> cubes: 4\n",
      "File: P597-Fg019-V-C01-R01-D30112014-T141320-ML638 _018.jpg.npy >>> cubes: 2\n",
      "File: P597-Fg023-V-C01-R01-D30112014-T144639-ML638 _018.jpg.npy >>> cubes: 16\n",
      "File: P593-Fg014-V-C01-R01-D31122013-T092131-ML638 _018.jpg.npy >>> cubes: 16\n",
      "File: P597-Fg060-V-C01-R01-D01122014-T141941-ML638 _018.jpg.npy >>> cubes: 22\n",
      "File: P597-Fg021-V-C01-R01-D30112014-T142912-ML638 _018.jpg.npy >>> cubes: 4\n",
      "File: P596-Fg023-V-C01-R01-D20012014-T095634-ML638 _018.jpg.npy >>> cubes: 6\n",
      "File: P590-Fg029-V-C01-R01-D14022013-T144300-ML638 _018.jpg.npy >>> cubes: 17\n",
      "File: P596-Fg078-V-C01-R01-D22012014-T134935-ML638 _018.jpg.npy >>> cubes: 4\n",
      "File: P597-Fg012-V-C01-R01-D30112014-T125059-ML638 _018.jpg.npy >>> cubes: 11\n",
      "File: P596-Fg050-V-C01-R01-D20012014-T151021-ML638 _018.jpg.npy >>> cubes: 5\n",
      "File: P597-Fg062-V-C01-R01-D01122014-T143757-ML638 _018.jpg.npy >>> cubes: 12\n",
      "File: P590-Fg014-V-C01-R01-D14022013-T110256-ML638 _018.jpg.npy >>> cubes: 4\n",
      "File: P593-Fg016-V-C01-R01-D31122013-T093806-ML638 _018.jpg.npy >>> cubes: 32\n",
      "File: P598-Fg022-V-C01-R01-D07012014-T143617-ML638 _018.jpg.npy >>> cubes: 10\n",
      "File: P596-Fg032-V-C01-R01-D20012014-T113938-ML638 _018.jpg.npy >>> cubes: 9\n",
      "File: P597-Fg005-V-C01-R01-D30112014-T111131-ML638 _018.jpg.npy >>> cubes: 26\n",
      "File: P597-Fg067-V-C01-R01-D02122014-T091144-ML638 _018.jpg.npy >>> cubes: 14\n",
      "File: P596-Fg061-V-C01-R01-D22012014-T105919-ML638 _018.jpg.npy >>> cubes: 9\n",
      "File: P589-Fg003-V-C01-R01-D12022013-T114238-ML638 _018.jpg.npy >>> cubes: 34\n",
      "File: P596-Fg011-V-C01-R01-D19012014-T140951-ML638 _018.jpg.npy >>> cubes: 12\n",
      "File: P597-Fg047-V-C01-R01-D01122014-T113803-ML638 _018.jpg.npy >>> cubes: 4\n",
      "File: P596-Fg082-V-C01-R01-D22012014-T142235-ML638 _018.jpg.npy >>> cubes: 9\n",
      "File: P593-Fg007-V-C01-R01-D30122013-T153034-ML638 _018.jpg.npy >>> cubes: 2\n",
      "File: P590-Fg015-V-C01-R01-D14022013-T111212-ML638 _018.jpg.npy >>> cubes: 14\n",
      "File: P596-Fg041-V-C01-R01-D20012014-T133814-ML638 _018.jpg.npy >>> cubes: 6\n",
      "File: P596-Fg084-V-C01-R01-D22012014-T143755-ML638 _018.jpg.npy >>> cubes: 4\n",
      "File: P597-Fg065-V-C01-R01-D01122014-T150736-ML638 _018.jpg.npy >>> cubes: 4\n",
      "File: P597-Fg070-V-C01-R01-D02122014-T094251-ML638 _018.jpg.npy >>> cubes: 3\n",
      "File: P597-Fg027-V-C01-R01-D30112014-T152802-ML638 _018.jpg.npy >>> cubes: 5\n",
      "File: P596-Fg056-V-C01-R01-D22012014-T101455-ML638 _018.jpg.npy >>> cubes: 9\n",
      "File: P590-Fg016-V-C01-R01-D14022013-T124908-ML638 _018.jpg.npy >>> cubes: 21\n",
      "File: P597-Fg064-V-C01-R01-D01122014-T145337-ML638 _018.jpg.npy >>> cubes: 15\n",
      "File: P598-Fg015-V-C01-R01-D07012014-T134050-ML638 _018.jpg.npy >>> cubes: 28\n",
      "File: P597-Fg016-V-C01-R01-D30112014-T133502-ML638 _018.jpg.npy >>> cubes: 6\n",
      "File: P596-Fg054-V-C01-R01-D22012014-T095736-ML638 _018.jpg.npy >>> cubes: 4\n",
      "File: P593-Fg004-V-C01-R01-D30122013-T150045-ML638 _018.jpg.npy >>> cubes: 25\n",
      "File: P593-Fg005-V-C01-R01-D30122013-T151255-ML638 _018.jpg.npy >>> cubes: 14\n",
      "File: P596-Fg015-V-C01-R01-D19012014-T144520-ML638 _018.jpg.npy >>> cubes: 0\n",
      "File: P596-Fg033-V-C01-R01-D20012014-T112940-ML638 _018.jpg.npy >>> cubes: 7\n",
      "File: P596-Fg064-V-C01-R01-D22012014-T112529-ML638 _018.jpg.npy >>> cubes: 6\n",
      "File: P597-Fg058-V-C01-R01-D01122014-T140215-ML638 _018.jpg.npy >>> cubes: 4\n",
      "File: P597-Fg068-V-C01-R01-D02122014-T091939-ML638 _018.jpg.npy >>> cubes: 4\n",
      "File: P589-Fg009-V-C01-R01-D12022013-T123842-ML638 _018.jpg.npy >>> cubes: 10\n",
      "File: P597-Fg002-V-C01-R01-D30112014-T102248-ML638 _018.jpg.npy >>> cubes: 12\n",
      "File: P590-Fg024-V-C01-R01-D14022013-T123931-ML638 _018.jpg.npy >>> cubes: 22\n",
      "File: P597-Fg007-V-C01-R01-D30112014-T112820-ML638 _018.jpg.npy >>> cubes: 11\n",
      "File: P598-Fg016-V-C01-R01-D07012014-T134836-ML638 _018.jpg.npy >>> cubes: 6\n",
      "File: P596-Fg066-V-C01-R01-D22012014-T115010-ML638 _018.jpg.npy >>> cubes: 2\n",
      "File: P597-Fg024-V-C01-R01-D30112014-T145447-ML638 _018.jpg.npy >>> cubes: 15\n",
      "File: P596-Fg080-V-C01-R01-D22012014-T140626-ML638 _018.jpg.npy >>> cubes: 4\n",
      "File: P593-Fg009-V-C01-R01-D30122013-T154732-ML638 _018.jpg.npy >>> cubes: 8\n",
      "File: P589-Fg001-V-C01-R01-D12022013-T111114-ML638 _018.jpg.npy >>> cubes: 25\n",
      "File: P596-Fg051-V-C01-R01-D20012014-T152838-ML638 _018.jpg.npy >>> cubes: 2\n",
      "File: P596-Fg058-V-C01-R01-D22012014-T103334-ML638 _018.jpg.npy >>> cubes: 0\n",
      "File: P596-Fg042-V-C01-R01-D20012014-T135659-ML638 _018.jpg.npy >>> cubes: 2\n",
      "File: P597-Fg048-V-C01-R01-D01122014-T122955-ML638 _018.jpg.npy >>> cubes: 2\n",
      "File: P598-Fg028-V-C01-R01-D08012014-T091113-ML638 _018.jpg.npy >>> cubes: 17\n",
      "File: P598-Fg005-V-C01-R01-D07012014-T113520-ML638 _018.jpg.npy >>> cubes: 27\n",
      "File: P596-Fg025-V-C01-R01-D20012014-T101436-ML638 _018.jpg.npy >>> cubes: 4\n",
      "File: P598-Fg001-V-C01-R01-D07012014-T105717-ML638 _018.jpg.npy >>> cubes: 37\n",
      "File: P598-Fg002-V-C01-R01-D07012014-T110515-ML638 _018.jpg.npy >>> cubes: 13\n",
      "File: P590-Fg002-V-C01-R01-D13022013-T140623-ML638 _018.jpg.npy >>> cubes: 21\n",
      "File: P598-Fg007-V-C01-R01-D07012014-T115107-ML638 _018.jpg.npy >>> cubes: 50\n",
      "File: P598-Fg035-V-C01-R01-D08012014-T114742-ML638 _018.jpg.npy >>> cubes: 20\n",
      "File: P598-Fg029-V-C01-R01-D08012014-T091929-ML638 _018.jpg.npy >>> cubes: 10\n",
      "File: P590-Fg018-V-C01-R01-D14022013-T113955-ML638 _018.jpg.npy >>> cubes: 12\n",
      "File: P596-Fg017-V-C01-R01-D19012014-T150317-ML638 _018.jpg.npy >>> cubes: 9\n",
      "File: P597-Fg035-V-C01-R01-D01122014-T094646-ML638 _018.jpg.npy >>> cubes: 13\n",
      "File: P596-Fg067-V-C01-R01-D22012014-T120037-ML638 _018.jpg.npy >>> cubes: 11\n",
      "File: P590-Fg035-V-C01-R01-D14022013-T154354-ML638 _018.jpg.npy >>> cubes: 32\n",
      "File: P596-Fg014-V-C01-R01-D19012014-T143732-ML638 _018.jpg.npy >>> cubes: 4\n",
      "File: P596-Fg053-V-C01-R01-D22012014-T094804-ML638 _018.jpg.npy >>> cubes: 5\n",
      "File: P596-Fg065-V-C01-R01-D22012014-T113545-ML638 _018.jpg.npy >>> cubes: 4\n",
      "File: P597-Fg008-V-C01-R01-D30112014-T113634-ML638 _018.jpg.npy >>> cubes: 7\n",
      "File: P593-Fg010-V-C01-R01-D31122013-T084652-ML638 _018.jpg.npy >>> cubes: 12\n",
      "File: P598-Fg020-V-C01-R01-D07012014-T142020-ML638 _018.jpg.npy >>> cubes: 25\n",
      "File: P596-Fg055-V-C01-R01-D22012014-T100617-ML638 _018.jpg.npy >>> cubes: 18\n",
      "File: P593-Fg019-V-C01-R01-D31122013-T100354-ML638 _018.jpg.npy >>> cubes: 10\n",
      "File: P596-Fg052-V-C01-R01-D22012014-T093945-ML638 _018.jpg.npy >>> cubes: 8\n",
      "File: P597-Fg004-V-C01-R01-D30112014-T110303-ML638 _018.jpg.npy >>> cubes: 17\n",
      "File: P596-Fg076-V-C01-R01-D22012014-T133230-ML638 _018.jpg.npy >>> cubes: 0\n",
      "File: P598-Fg025-V-C01-R01-D07012014-T145914-ML638 _018.jpg.npy >>> cubes: 10\n",
      "File: P597-Fg046-V-C01-R01-D01122014-T113002-ML638 _018.jpg.npy >>> cubes: 6\n",
      "File: P597-Fg051-V-C01-R01-D01122014-T125556-ML638 _018.jpg.npy >>> cubes: 12\n",
      "File: P596-Fg036-V-C01-R01-D20012014-T120635-ML638 _018.jpg.npy >>> cubes: 2\n",
      "File: P596-Fg020-V-C01-R01-D19012014-T152939-ML638 _018.jpg.npy >>> cubes: 9\n",
      "File: P598-Fg013-V-C01-R01-D07012014-T132450-ML638 _018.jpg.npy >>> cubes: 18\n",
      "File: P596-Fg060-V-C01-R01-D22012014-T105053-ML638 _018.jpg.npy >>> cubes: 4\n",
      "File: P597-Fg015-V-C01-R01-D30112014-T132658-ML638 _018.jpg.npy >>> cubes: 3\n",
      "File: P596-Fg024-V-C01-R01-D20012014-T100441-ML638 _018.jpg.npy >>> cubes: 6\n",
      "File: P590-Fg031-V-C01-R01-D14022013-T150510-ML638 _018.jpg.npy >>> cubes: 44\n",
      "File: P590-Fg021-V-C01-R01-D14022013-T121136-ML638 _018.jpg.npy >>> cubes: 8\n",
      "File: P598-Fg003-V-C01-R01-D07012014-T111412-ML638 _018.jpg.npy >>> cubes: 31\n",
      "File: P598-Fg027-V-C01-R01-D08012014-T090319-ML638 _018.jpg.npy >>> cubes: 2\n",
      "File: P593-Fg001-V-C01-R01-D30122013-T143528-ML638 _018.jpg.npy >>> cubes: 97\n",
      "File: P597-Fg009-V-C01-R01-D30112014-T115017-ML638 _018.jpg.npy >>> cubes: 2\n",
      "File: P596-Fg074-V-C01-R01-D22012014-T131454-ML638 _018.jpg.npy >>> cubes: 4\n",
      "File: P590-Fg017-V-C01-R01-D14022013-T112939-ML638 _018.jpg.npy >>> cubes: 12\n",
      "File: P597-Fg030-V-C01-R01-D30112014-T155128-ML638 _018.jpg.npy >>> cubes: 8\n",
      "File: P590-Fg009-V-C01-R01-D13022013-T150516-ML638 _018.jpg.npy >>> cubes: 19\n",
      "File: P590-Fg007-V-C01-R01-D13022013-T144900-ML638 _018.jpg.npy >>> cubes: 13\n",
      "File: P598-Fg011-V-C01-R01-D07012014-T130850-ML638 _018.jpg.npy >>> cubes: 5\n",
      "File: P596-Fg057-V-C01-R01-D22012014-T102326-ML638 _018.jpg.npy >>> cubes: 7\n",
      "File: P596-Fg083-V-C01-R01-D22012014-T143021-ML638 _018.jpg.npy >>> cubes: 0\n",
      "File: P596-Fg072-V-C01-R01-D22012014-T125806-ML638 _018.jpg.npy >>> cubes: 6\n",
      "File: P596-Fg068-V-C01-R01-D22012014-T121857-ML638 _018.jpg.npy >>> cubes: 2\n",
      "File: P597-Fg025-V-C01-R01-D30112014-T150611-ML638 _018.jpg.npy >>> cubes: 23\n",
      "File: P596-Fg045-V-C01-R01-D20012014-T142357-ML638 _018.jpg.npy >>> cubes: 6\n",
      "File: P597-Fg039-V-C01-R01-D01122014-T102051-ML638 _018.jpg.npy >>> cubes: 6\n",
      "File: P590-Fg027-V-C01-R01-D14022013-T142337-ML638 _018.jpg.npy >>> cubes: 11\n",
      "File: P593-Fg008-V-C01-R01-D30122013-T153909-ML638 _018.jpg.npy >>> cubes: 8\n",
      "File: P590-Fg012-V-C01-R01-D13022013-T152920-ML638 _018.jpg.npy >>> cubes: 12\n",
      "File: P597-Fg053-V-C01-R01-D01122014-T131604-ML638 _018.jpg.npy >>> cubes: 6\n",
      "File: P597-Fg054-V-C01-R01-D01122014-T132416-ML638 _018.jpg.npy >>> cubes: 6\n",
      "File: P596-Fg081-V-C01-R01-D22012014-T141443-ML638 _018.jpg.npy >>> cubes: 12\n",
      "File: P597-Fg028-V-C01-R01-D30112014-T153541-ML638 _018.jpg.npy >>> cubes: 1\n",
      "File: P598-Fg017-V-C01-R01-D07012014-T135638-ML638 _018.jpg.npy >>> cubes: 12\n",
      "File: P597-Fg014-V-C01-R01-D30112014-T131849-ML638 _018.jpg.npy >>> cubes: 5\n",
      "File: P590-Fg006-V-C01-R01-D13022013-T143816-ML638 _018.jpg.npy >>> cubes: 12\n",
      "File: P596-Fg046-V-C01-R01-D20012014-T143202-ML638 _018.jpg.npy >>> cubes: 10\n",
      "File: P596-Fg031-V-C01-R01-D20012014-T110945-ML638 _018.jpg.npy >>> cubes: 6\n",
      "File: P597-Fg045-V-C01-R01-D01122014-T112210-ML638 _018.jpg.npy >>> cubes: 8\n",
      "File: P596-Fg030-V-C01-R01-D20012014-T110102-ML638 _018.jpg.npy >>> cubes: 6\n",
      "File: P596-Fg007-V-C01-R01-D19012014-T133024-ML638 _018.jpg.npy >>> cubes: 6\n",
      "File: P596-Fg034-V-C01-R01-D20012014-T114914-ML638 _018.jpg.npy >>> cubes: 6\n",
      "File: P596-Fg022-V-C01-R01-D20012014-T094822-ML638 _018.jpg.npy >>> cubes: 9\n",
      "File: P589-Fg004-V-C01-R01-D12022013-T115122-ML638 _018.jpg.npy >>> cubes: 25\n",
      "File: P593-Fg015-V-C01-R01-D31122013-T092919-ML638 _018.jpg.npy >>> cubes: 32\n",
      "File: P597-Fg055-V-C01-R01-D01122014-T133333-ML638 _018.jpg.npy >>> cubes: 7\n",
      "File: P597-Fg011-V-C01-R01-D30112014-T124252-ML638 _018.jpg.npy >>> cubes: 9\n",
      "File: P596-Fg001-V-C01-R01-D19012014-T115843-ML638 _018.jpg.npy >>> cubes: 6\n",
      "File: P597-Fg022-V-C01-R01-D30112014-T143735-ML638 _018.jpg.npy >>> cubes: 4\n",
      "File: P596-Fg028-V-C01-R01-D20012014-T104311-ML638 _018.jpg.npy >>> cubes: 2\n",
      "File: P597-Fg061-V-C01-R01-D01122014-T142927-ML638 _018.jpg.npy >>> cubes: 6\n",
      "File: P589-Fg005-V-C01-R01-D12022013-T115957-ML638 _018.jpg.npy >>> cubes: 26\n",
      "File: P597-Fg018-V-C01-R01-D30112014-T140441-ML638 _018.jpg.npy >>> cubes: 12\n",
      "File: P597-Fg049-V-C01-R01-D01122014-T123857-ML638 _018.jpg.npy >>> cubes: 8\n",
      "File: P590-Fg026-V-C01-R01-D14022013-T141513-ML638 _018.jpg.npy >>> cubes: 36\n",
      "File: P597-Fg032-V-C01-R01-D01122014-T092254-ML638 _018.jpg.npy >>> cubes: 2\n",
      "File: P598-Fg024-V-C01-R01-D07012014-T145134-ML638 _018.jpg.npy >>> cubes: 15\n",
      "File: P596-Fg073-V-C01-R01-D22012014-T130619-ML638 _018.jpg.npy >>> cubes: 8\n",
      "File: P590-Fg003-V-C01-R01-D13022013-T141451-ML638 _018.jpg.npy >>> cubes: 35\n",
      "File: P596-Fg018-V-C01-R01-D19012014-T151220-ML638 _018.jpg.npy >>> cubes: 5\n",
      "File: P596-Fg012-V-C01-R01-D19012014-T142045-ML638 _018.jpg.npy >>> cubes: 11\n",
      "File: P598-Fg018-V-C01-R01-D07012014-T140420-ML638 _018.jpg.npy >>> cubes: 8\n",
      "File: P598-Fg030-V-C01-R01-D08012014-T092728-ML638 _018.jpg.npy >>> cubes: 16\n",
      "File: P590-Fg032-V-C01-R01-D14022013-T151728-ML638 _018.jpg.npy >>> cubes: 37\n",
      "File: P598-Fg023-V-C01-R01-D07012014-T144346-ML638 _018.jpg.npy >>> cubes: 7\n",
      "File: P596-Fg002-V-C01-R01-D19012014-T120813-ML638 _018.jpg.npy >>> cubes: 2\n",
      "File: P596-Fg039-V-C01-R01-D20012014-T131936-ML638 _018.jpg.npy >>> cubes: 4\n",
      "File: P598-Fg014-V-C01-R01-D07012014-T133248-ML638 _018.jpg.npy >>> cubes: 13\n",
      "File: P590-Fg005-V-C01-R01-D13022013-T143033-ML638 _018.jpg.npy >>> cubes: 24\n",
      "File: P589-Fg002-V-C01-R01-D12022013-T112400-ML638 _018.jpg.npy >>> cubes: 47\n",
      "File: P596-Fg021-V-C01-R01-D19012014-T153758-ML638 _018.jpg.npy >>> cubes: 12\n",
      "File: P596-Fg047-V-C01-R01-D20012014-T144042-ML638 _018.jpg.npy >>> cubes: 4\n",
      "File: P598-Fg004-V-C01-R01-D07012014-T112202-ML638 _018.jpg.npy >>> cubes: 20\n",
      "File: P589-Fg006-V-C01-R01-D12022013-T121224-ML638 _018.jpg.npy >>> cubes: 58\n",
      "File: P590-Fg001-V-C01-R01-D13022013-T135831-ML638 _018.jpg.npy >>> cubes: 19\n",
      "File: P598-Fg012-V-C01-R01-D07012014-T131627-ML638 _018.jpg.npy >>> cubes: 23\n",
      "File: P593-Fg006-V-C01-R01-D30122013-T152201-ML638 _018.jpg.npy >>> cubes: 6\n",
      "File: P598-Fg019-V-C01-R01-D07012014-T141237-ML638 _018.jpg.npy >>> cubes: 26\n",
      "File: P596-Fg037-V-C01-R01-D20012014-T121453-ML638 _018.jpg.npy >>> cubes: 12\n",
      "File: P597-Fg003-V-C01-R01-D30112014-T103141-ML638 _018.jpg.npy >>> cubes: 29\n",
      "File: P597-Fg041-V-C01-R01-D01122014-T103817-ML638 _018.jpg.npy >>> cubes: 3\n",
      "File: P596-Fg029-V-C01-R01-D20012014-T105249-ML638 _018.jpg.npy >>> cubes: 9\n",
      "File: P598-Fg010-V-C01-R01-D07012014-T130049-ML638 _018.jpg.npy >>> cubes: 24\n",
      "File: P596-Fg040-V-C01-R01-D20012014-T134235-ML638 _018.jpg.npy >>> cubes: 12\n",
      "File: P596-Fg085-V-C01-R01-D22012014-T144539-ML638 _018.jpg.npy >>> cubes: 9\n",
      "File: P596-Fg079-V-C01-R01-D22012014-T135758-ML638 _018.jpg.npy >>> cubes: 24\n",
      "File: P597-Fg063-V-C01-R01-D01122014-T144548-ML638 _018.jpg.npy >>> cubes: 3\n",
      "File: P590-Fg034-V-C01-R01-D14022013-T153515-ML638 _018.jpg.npy >>> cubes: 12\n",
      "File: P597-Fg050-V-C01-R01-D01122014-T124640-ML638 _018.jpg.npy >>> cubes: 4\n",
      "File: P598-Fg009-V-C01-R01-D07012014-T125232-ML638 _018.jpg.npy >>> cubes: 58\n",
      "File: P593-Fg002-V-C01-R01-D30122013-T144349-ML638 _018.jpg.npy >>> cubes: 31\n",
      "File: P598-Fg036-V-C01-R01-D08012014-T120043-ML638 _018.jpg.npy >>> cubes: 11\n",
      "File: P590-Fg011-V-C01-R01-D13022013-T152126-ML638 _018.jpg.npy >>> cubes: 8\n",
      "File: P596-Fg013-V-C01-R01-D19012014-T142905-ML638 _018.jpg.npy >>> cubes: 15\n",
      "File: P597-Fg057-V-C01-R01-D01122014-T135348-ML638 _018.jpg.npy >>> cubes: 0\n",
      "File: P593-Fg012-V-C01-R01-D31122013-T090434-ML638 _018.jpg.npy >>> cubes: 12\n",
      "File: P596-Fg026-V-C01-R01-D20012014-T102256-ML638 _018.jpg.npy >>> cubes: 5\n",
      "File: P590-Fg019-V-C01-R01-D14022013-T115307-ML638 _018.jpg.npy >>> cubes: 12\n",
      "File: P597-Fg026-V-C01-R01-D30112014-T151604-ML638 _018.jpg.npy >>> cubes: 16\n",
      "File: P590-Fg013-V-C01-R01-D13022013-T154000-ML638 _018.jpg.npy >>> cubes: 13\n",
      "File: P598-Fg021-V-C01-R01-D07012014-T142813-ML638 _018.jpg.npy >>> cubes: 17\n",
      "File: P597-Fg010-V-C01-R01-D30112014-T123526-ML638 _018.jpg.npy >>> cubes: 8\n",
      "File: P596-Fg048-V-C01-R01-D20012014-T144916-ML638 _018.jpg.npy >>> cubes: 0\n",
      "File: P596-Fg069-V-C01-R01-D22012014-T122730-ML638 _018.jpg.npy >>> cubes: 2\n",
      "File: P593-Fg013-V-C01-R01-D31122013-T091310-ML638 _018.jpg.npy >>> cubes: 31\n",
      "File: P593-Fg017-V-C01-R01-D31122013-T094553-ML638 _018.jpg.npy >>> cubes: 26\n",
      "File: P590-Fg008-V-C01-R01-D13022013-T145640-ML638 _018.jpg.npy >>> cubes: 48\n",
      "File: P597-Fg071-V-C01-R01-D02122014-T095737-ML638 _018.jpg.npy >>> cubes: 14\n",
      "File: P597-Fg066-V-C01-R01-D01122014-T151624-ML638 _018.jpg.npy >>> cubes: 4\n",
      "File: P598-Fg034-V-C01-R01-D08012014-T113919-ML638 _018.jpg.npy >>> cubes: 8\n",
      "File: P590-Fg010-V-C01-R01-D13022013-T151327-ML638 _018.jpg.npy >>> cubes: 14\n",
      "File: P596-Fg070-V-C01-R01-D22012014-T123605-ML638 _018.jpg.npy >>> cubes: 4\n",
      "File: P596-Fg035-V-C01-R01-D20012014-T115735-ML638 _018.jpg.npy >>> cubes: 10\n",
      "File: P597-Fg038-V-C01-R01-D01122014-T101213-ML638 _018.jpg.npy >>> cubes: 0\n",
      "File: P596-Fg062-V-C01-R01-D22012014-T110734-ML638 _018.jpg.npy >>> cubes: 6\n",
      "File: P597-Fg059-V-C01-R01-D01122014-T141104-ML638 _018.jpg.npy >>> cubes: 2\n",
      "File: P596-Fg038-V-C01-R01-D20012014-T122525-ML638 _018.jpg.npy >>> cubes: 4\n",
      "File: P597-Fg031-V-C01-R01-D01122014-T091456-ML638 _018.jpg.npy >>> cubes: 2\n",
      "File: P596-Fg008-V-C01-R01-D19012014-T133839-ML638 _018.jpg.npy >>> cubes: 9\n",
      "File: P590-Fg020-V-C01-R01-D14022013-T120138-ML638 _018.jpg.npy >>> cubes: 4\n",
      "WARNING:tensorflow:From <ipython-input-6-898022341402>:97: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See tf.nn.softmax_cross_entropy_with_logits_v2.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TEST - take test-set and cross-validate on it (uncomment all for full test run)\n",
    "# cubes_set = pre_process_training(\"PX303-Fg006-V-C02-R02-D08032015-T115622-ML638__006.jpg\", 0, 6200, 0, 4400)\n",
    "cubes_set = pre_process(VOL_FOLDER+ \"cropped2/\", \"crops.csv\")\n",
    "tf.reset_default_graph()\n",
    "model_tf_deep(250, 1)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#os.remove('pairs_matches.csv')\n",
    "fragment_counters = {}\n",
    "fragment_and_side_counters = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#####################################################################\n",
      "VALIDATING\n",
      "#####################################################################\n",
      "### 200 ### CUBE:P598-Fg031-V-C01-R01-D08012014-T093535-ML638 _018.jpg.npy_150_50\n",
      "loaded 65 images\n",
      "65\n",
      "INFO:tensorflow:Restoring parameters from /home/il239838/files/model_binary/tear_model2.ckpt\n",
      "Model restored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/il239838/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/util/tf_inspect.py:45: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  if d.decorator_argspec is not None), _inspect.getargspec(target))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOUND Matches #: 30\n",
      "### 201 ### CUBE:P598-Fg031-V-C01-R01-D08012014-T093535-ML638 _018.jpg.npy_300_847\n",
      "loaded 65 images\n",
      "65\n",
      "INFO:tensorflow:Restoring parameters from /home/il239838/files/model_binary/tear_model2.ckpt\n",
      "Model restored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/il239838/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/util/tf_inspect.py:45: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  if d.decorator_argspec is not None), _inspect.getargspec(target))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOUND Matches #: 47\n",
      "### 202 ### CUBE:P598-Fg031-V-C01-R01-D08012014-T093535-ML638 _018.jpg.npy_100_50\n",
      "loaded 65 images\n",
      "65\n",
      "INFO:tensorflow:Restoring parameters from /home/il239838/files/model_binary/tear_model2.ckpt\n",
      "Model restored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/il239838/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/util/tf_inspect.py:45: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  if d.decorator_argspec is not None), _inspect.getargspec(target))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOUND Matches #: 56\n",
      "### 203 ### CUBE:P598-Fg031-V-C01-R01-D08012014-T093535-ML638 _018.jpg.npy_200_50\n",
      "loaded 65 images\n",
      "65\n",
      "INFO:tensorflow:Restoring parameters from /home/il239838/files/model_binary/tear_model2.ckpt\n",
      "Model restored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/il239838/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/util/tf_inspect.py:45: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  if d.decorator_argspec is not None), _inspect.getargspec(target))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOUND Matches #: 4\n",
      "### 204 ### CUBE:P598-Fg031-V-C01-R01-D08012014-T093535-ML638 _018.jpg.npy_100_847\n",
      "loaded 65 images\n",
      "65\n",
      "INFO:tensorflow:Restoring parameters from /home/il239838/files/model_binary/tear_model2.ckpt\n",
      "Model restored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/il239838/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/util/tf_inspect.py:45: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  if d.decorator_argspec is not None), _inspect.getargspec(target))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOUND Matches #: 23\n",
      "### 205 ### CUBE:P598-Fg031-V-C01-R01-D08012014-T093535-ML638 _018.jpg.npy_200_847\n",
      "loaded 65 images\n",
      "65\n",
      "INFO:tensorflow:Restoring parameters from /home/il239838/files/model_binary/tear_model2.ckpt\n",
      "Model restored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/il239838/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/util/tf_inspect.py:45: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  if d.decorator_argspec is not None), _inspect.getargspec(target))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOUND Matches #: 58\n",
      "### 206 ### CUBE:P598-Fg031-V-C01-R01-D08012014-T093535-ML638 _018.jpg.npy_150_847\n",
      "loaded 65 images\n",
      "65\n",
      "INFO:tensorflow:Restoring parameters from /home/il239838/files/model_binary/tear_model2.ckpt\n",
      "Model restored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/il239838/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/util/tf_inspect.py:45: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  if d.decorator_argspec is not None), _inspect.getargspec(target))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOUND Matches #: 22\n",
      "### 207 ### CUBE:P598-Fg031-V-C01-R01-D08012014-T093535-ML638 _018.jpg.npy_0_50\n",
      "loaded 65 images\n",
      "65\n",
      "INFO:tensorflow:Restoring parameters from /home/il239838/files/model_binary/tear_model2.ckpt\n",
      "Model restored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/il239838/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/util/tf_inspect.py:45: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  if d.decorator_argspec is not None), _inspect.getargspec(target))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOUND Matches #: 21\n",
      "### 208 ### CUBE:P598-Fg031-V-C01-R01-D08012014-T093535-ML638 _018.jpg.npy_250_847\n",
      "loaded 65 images\n",
      "65\n",
      "INFO:tensorflow:Restoring parameters from /home/il239838/files/model_binary/tear_model2.ckpt\n",
      "Model restored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/il239838/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/util/tf_inspect.py:45: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  if d.decorator_argspec is not None), _inspect.getargspec(target))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOUND Matches #: 25\n",
      "### 209 ### CUBE:P597-Fg037-V-C01-R01-D01122014-T100405-ML638 _018.jpg.npy_250_50\n",
      "loaded 919 images\n",
      "919\n",
      "INFO:tensorflow:Restoring parameters from /home/il239838/files/model_binary/tear_model2.ckpt\n",
      "Model restored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/il239838/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/util/tf_inspect.py:45: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  if d.decorator_argspec is not None), _inspect.getargspec(target))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> step 500\n",
      "FOUND Matches #: 270\n",
      "### 210 ### CUBE:P597-Fg037-V-C01-R01-D01122014-T100405-ML638 _018.jpg.npy_50_50\n",
      "loaded 919 images\n",
      "919\n",
      "INFO:tensorflow:Restoring parameters from /home/il239838/files/model_binary/tear_model2.ckpt\n",
      "Model restored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/il239838/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/util/tf_inspect.py:45: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  if d.decorator_argspec is not None), _inspect.getargspec(target))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> step 500\n",
      "FOUND Matches #: 348\n",
      "### 211 ### CUBE:P597-Fg037-V-C01-R01-D01122014-T100405-ML638 _018.jpg.npy_100_50\n",
      "loaded 919 images\n",
      "919\n",
      "INFO:tensorflow:Restoring parameters from /home/il239838/files/model_binary/tear_model2.ckpt\n",
      "Model restored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/il239838/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/util/tf_inspect.py:45: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  if d.decorator_argspec is not None), _inspect.getargspec(target))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> step 500\n",
      "FOUND Matches #: 212\n",
      "### 212 ### CUBE:P597-Fg037-V-C01-R01-D01122014-T100405-ML638 _018.jpg.npy_200_74\n",
      "loaded 919 images\n",
      "919\n",
      "INFO:tensorflow:Restoring parameters from /home/il239838/files/model_binary/tear_model2.ckpt\n",
      "Model restored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/il239838/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/util/tf_inspect.py:45: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  if d.decorator_argspec is not None), _inspect.getargspec(target))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> step 500\n",
      "FOUND Matches #: 404\n",
      "### 213 ### CUBE:P597-Fg037-V-C01-R01-D01122014-T100405-ML638 _018.jpg.npy_150_50\n",
      "loaded 919 images\n",
      "919\n",
      "INFO:tensorflow:Restoring parameters from /home/il239838/files/model_binary/tear_model2.ckpt\n",
      "Model restored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/il239838/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/util/tf_inspect.py:45: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  if d.decorator_argspec is not None), _inspect.getargspec(target))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> step 500\n",
      "FOUND Matches #: 470\n",
      "### 214 ### CUBE:P597-Fg037-V-C01-R01-D01122014-T100405-ML638 _018.jpg.npy_250_74\n",
      "loaded 919 images\n",
      "919\n",
      "INFO:tensorflow:Restoring parameters from /home/il239838/files/model_binary/tear_model2.ckpt\n",
      "Model restored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/il239838/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/util/tf_inspect.py:45: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  if d.decorator_argspec is not None), _inspect.getargspec(target))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> step 500\n",
      "FOUND Matches #: 305\n",
      "### 215 ### CUBE:P597-Fg037-V-C01-R01-D01122014-T100405-ML638 _018.jpg.npy_0_50\n",
      "loaded 919 images\n",
      "919\n",
      "INFO:tensorflow:Restoring parameters from /home/il239838/files/model_binary/tear_model2.ckpt\n",
      "Model restored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/il239838/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/util/tf_inspect.py:45: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  if d.decorator_argspec is not None), _inspect.getargspec(target))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> step 500\n",
      "FOUND Matches #: 61\n",
      "### 216 ### CUBE:P597-Fg037-V-C01-R01-D01122014-T100405-ML638 _018.jpg.npy_50_74\n",
      "loaded 919 images\n",
      "919\n",
      "INFO:tensorflow:Restoring parameters from /home/il239838/files/model_binary/tear_model2.ckpt\n",
      "Model restored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/il239838/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/util/tf_inspect.py:45: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  if d.decorator_argspec is not None), _inspect.getargspec(target))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> step 500\n",
      "FOUND Matches #: 546\n",
      "### 217 ### CUBE:P597-Fg037-V-C01-R01-D01122014-T100405-ML638 _018.jpg.npy_0_74\n",
      "loaded 919 images\n",
      "919\n",
      "INFO:tensorflow:Restoring parameters from /home/il239838/files/model_binary/tear_model2.ckpt\n",
      "Model restored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/il239838/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/util/tf_inspect.py:45: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  if d.decorator_argspec is not None), _inspect.getargspec(target))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> step 500\n",
      "FOUND Matches #: 47\n",
      "### 218 ### CUBE:P597-Fg037-V-C01-R01-D01122014-T100405-ML638 _018.jpg.npy_100_74\n",
      "loaded 919 images\n",
      "919\n",
      "INFO:tensorflow:Restoring parameters from /home/il239838/files/model_binary/tear_model2.ckpt\n",
      "Model restored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/il239838/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/util/tf_inspect.py:45: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  if d.decorator_argspec is not None), _inspect.getargspec(target))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> step 500\n",
      "FOUND Matches #: 297\n",
      "### 219 ### CUBE:P597-Fg037-V-C01-R01-D01122014-T100405-ML638 _018.jpg.npy_150_74\n",
      "loaded 919 images\n",
      "919\n",
      "INFO:tensorflow:Restoring parameters from /home/il239838/files/model_binary/tear_model2.ckpt\n",
      "Model restored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/il239838/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/util/tf_inspect.py:45: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  if d.decorator_argspec is not None), _inspect.getargspec(target))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> step 500\n",
      "FOUND Matches #: 298\n",
      "### 220 ### CUBE:P597-Fg037-V-C01-R01-D01122014-T100405-ML638 _018.jpg.npy_200_50\n",
      "loaded 919 images\n",
      "919\n",
      "INFO:tensorflow:Restoring parameters from /home/il239838/files/model_binary/tear_model2.ckpt\n",
      "Model restored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/il239838/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/util/tf_inspect.py:45: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  if d.decorator_argspec is not None), _inspect.getargspec(target))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> step 500\n",
      "FOUND Matches #: 463\n",
      "### 221 ### CUBE:P596-Fg043-V-C01-R01-D20012014-T140533-ML638 _018.jpg.npy_0_483\n",
      "loaded 1571 images\n",
      "1571\n",
      "INFO:tensorflow:Restoring parameters from /home/il239838/files/model_binary/tear_model2.ckpt\n",
      "Model restored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/il239838/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/util/tf_inspect.py:45: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  if d.decorator_argspec is not None), _inspect.getargspec(target))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> step 500\n",
      ">>> step 1000\n",
      ">>> step 1500\n",
      "FOUND Matches #: 144\n",
      "### 222 ### CUBE:P596-Fg043-V-C01-R01-D20012014-T140533-ML638 _018.jpg.npy_0_50\n",
      "loaded 1571 images\n",
      "1571\n",
      "INFO:tensorflow:Restoring parameters from /home/il239838/files/model_binary/tear_model2.ckpt\n",
      "Model restored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/il239838/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/util/tf_inspect.py:45: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  if d.decorator_argspec is not None), _inspect.getargspec(target))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> step 500\n",
      ">>> step 1000\n",
      ">>> step 1500\n",
      "FOUND Matches #: 1281\n",
      "### 223 ### CUBE:P596-Fg043-V-C01-R01-D20012014-T140533-ML638 _018.jpg.npy_50_50\n",
      "loaded 1571 images\n",
      "1571\n",
      "INFO:tensorflow:Restoring parameters from /home/il239838/files/model_binary/tear_model2.ckpt\n",
      "Model restored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/il239838/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/util/tf_inspect.py:45: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  if d.decorator_argspec is not None), _inspect.getargspec(target))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> step 500\n",
      ">>> step 1000\n",
      ">>> step 1500\n",
      "FOUND Matches #: 956\n",
      "### 224 ### CUBE:P596-Fg043-V-C01-R01-D20012014-T140533-ML638 _018.jpg.npy_50_483\n",
      "loaded 1571 images\n",
      "1571\n",
      "INFO:tensorflow:Restoring parameters from /home/il239838/files/model_binary/tear_model2.ckpt\n",
      "Model restored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/il239838/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/util/tf_inspect.py:45: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  if d.decorator_argspec is not None), _inspect.getargspec(target))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> step 500\n",
      ">>> step 1000\n",
      ">>> step 1500\n",
      "FOUND Matches #: 574\n",
      "### 225 ### CUBE:P596-Fg044-V-C01-R01-D20012014-T141552-ML638 _018.jpg.npy_250_50\n",
      "loaded 1560 images\n",
      "1560\n",
      "INFO:tensorflow:Restoring parameters from /home/il239838/files/model_binary/tear_model2.ckpt\n",
      "Model restored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/il239838/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/util/tf_inspect.py:45: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  if d.decorator_argspec is not None), _inspect.getargspec(target))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> step 500\n",
      ">>> step 1000\n",
      ">>> step 1500\n",
      "FOUND Matches #: 149\n",
      "### 226 ### CUBE:P596-Fg044-V-C01-R01-D20012014-T141552-ML638 _018.jpg.npy_300_50\n",
      "loaded 1560 images\n",
      "1560\n",
      "INFO:tensorflow:Restoring parameters from /home/il239838/files/model_binary/tear_model2.ckpt\n",
      "Model restored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/il239838/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/util/tf_inspect.py:45: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  if d.decorator_argspec is not None), _inspect.getargspec(target))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> step 500\n",
      ">>> step 1000\n",
      ">>> step 1500\n",
      "FOUND Matches #: 511\n",
      "### 227 ### CUBE:P596-Fg044-V-C01-R01-D20012014-T141552-ML638 _018.jpg.npy_200_50\n",
      "loaded 1560 images\n",
      "1560\n",
      "INFO:tensorflow:Restoring parameters from /home/il239838/files/model_binary/tear_model2.ckpt\n",
      "Model restored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/il239838/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/util/tf_inspect.py:45: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  if d.decorator_argspec is not None), _inspect.getargspec(target))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> step 500\n",
      ">>> step 1000\n",
      ">>> step 1500\n",
      "FOUND Matches #: 313\n",
      "### 228 ### CUBE:P596-Fg044-V-C01-R01-D20012014-T141552-ML638 _018.jpg.npy_50_788\n",
      "loaded 1560 images\n",
      "1560\n",
      "INFO:tensorflow:Restoring parameters from /home/il239838/files/model_binary/tear_model2.ckpt\n",
      "Model restored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/il239838/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/util/tf_inspect.py:45: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  if d.decorator_argspec is not None), _inspect.getargspec(target))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> step 500\n",
      ">>> step 1000\n",
      ">>> step 1500\n",
      "FOUND Matches #: 1351\n",
      "### 229 ### CUBE:P596-Fg044-V-C01-R01-D20012014-T141552-ML638 _018.jpg.npy_300_788\n",
      "loaded 1560 images\n",
      "1560\n",
      "INFO:tensorflow:Restoring parameters from /home/il239838/files/model_binary/tear_model2.ckpt\n",
      "Model restored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/il239838/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/util/tf_inspect.py:45: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  if d.decorator_argspec is not None), _inspect.getargspec(target))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> step 500\n",
      ">>> step 1000\n",
      ">>> step 1500\n",
      "FOUND Matches #: 761\n",
      "### 230 ### CUBE:P596-Fg044-V-C01-R01-D20012014-T141552-ML638 _018.jpg.npy_350_788\n",
      "loaded 1560 images\n",
      "1560\n",
      "INFO:tensorflow:Restoring parameters from /home/il239838/files/model_binary/tear_model2.ckpt\n",
      "Model restored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/il239838/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/util/tf_inspect.py:45: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  if d.decorator_argspec is not None), _inspect.getargspec(target))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> step 500\n",
      ">>> step 1000\n",
      ">>> step 1500\n",
      "FOUND Matches #: 276\n",
      "### 231 ### CUBE:P596-Fg044-V-C01-R01-D20012014-T141552-ML638 _018.jpg.npy_150_788\n",
      "loaded 1560 images\n",
      "1560\n",
      "INFO:tensorflow:Restoring parameters from /home/il239838/files/model_binary/tear_model2.ckpt\n",
      "Model restored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/il239838/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/util/tf_inspect.py:45: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  if d.decorator_argspec is not None), _inspect.getargspec(target))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> step 500\n",
      ">>> step 1000\n",
      ">>> step 1500\n",
      "FOUND Matches #: 1224\n",
      "### 232 ### CUBE:P596-Fg044-V-C01-R01-D20012014-T141552-ML638 _018.jpg.npy_100_788\n",
      "loaded 1560 images\n",
      "1560\n",
      "INFO:tensorflow:Restoring parameters from /home/il239838/files/model_binary/tear_model2.ckpt\n",
      "Model restored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/il239838/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/util/tf_inspect.py:45: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  if d.decorator_argspec is not None), _inspect.getargspec(target))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> step 500\n",
      ">>> step 1000\n",
      ">>> step 1500\n",
      "FOUND Matches #: 1145\n",
      "### 233 ### CUBE:P596-Fg044-V-C01-R01-D20012014-T141552-ML638 _018.jpg.npy_0_788\n",
      "loaded 1560 images\n",
      "1560\n",
      "INFO:tensorflow:Restoring parameters from /home/il239838/files/model_binary/tear_model2.ckpt\n",
      "Model restored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/il239838/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/util/tf_inspect.py:45: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  if d.decorator_argspec is not None), _inspect.getargspec(target))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> step 500\n",
      ">>> step 1000\n",
      ">>> step 1500\n",
      "FOUND Matches #: 383\n",
      "### 234 ### CUBE:P596-Fg044-V-C01-R01-D20012014-T141552-ML638 _018.jpg.npy_200_788\n",
      "loaded 1560 images\n",
      "1560\n",
      "INFO:tensorflow:Restoring parameters from /home/il239838/files/model_binary/tear_model2.ckpt\n",
      "Model restored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/il239838/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/util/tf_inspect.py:45: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  if d.decorator_argspec is not None), _inspect.getargspec(target))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> step 500\n",
      ">>> step 1000\n",
      ">>> step 1500\n",
      "FOUND Matches #: 744\n",
      "### 235 ### CUBE:P596-Fg044-V-C01-R01-D20012014-T141552-ML638 _018.jpg.npy_250_788\n",
      "loaded 1560 images\n",
      "1560\n",
      "INFO:tensorflow:Restoring parameters from /home/il239838/files/model_binary/tear_model2.ckpt\n",
      "Model restored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/il239838/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/util/tf_inspect.py:45: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  if d.decorator_argspec is not None), _inspect.getargspec(target))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> step 500\n",
      ">>> step 1000\n",
      ">>> step 1500\n",
      "FOUND Matches #: 720\n",
      "### 236 ### CUBE:P589-Fg012-V-C01-R01-D12022013-T130509-ML638 _018.jpg.npy_300_50\n",
      "loaded 3000 images\n",
      "3000\n",
      "INFO:tensorflow:Restoring parameters from /home/il239838/files/model_binary/tear_model2.ckpt\n",
      "Model restored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/il239838/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/util/tf_inspect.py:45: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  if d.decorator_argspec is not None), _inspect.getargspec(target))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> step 500\n",
      ">>> step 1000\n",
      ">>> step 1500\n",
      ">>> step 2000\n",
      ">>> step 2500\n",
      ">>> step 3000\n",
      "FOUND Matches #: 234\n",
      "### 237 ### CUBE:P589-Fg012-V-C01-R01-D12022013-T130509-ML638 _018.jpg.npy_50_50\n",
      "loaded 3000 images\n",
      "3000\n",
      "INFO:tensorflow:Restoring parameters from /home/il239838/files/model_binary/tear_model2.ckpt\n",
      "Model restored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/il239838/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/util/tf_inspect.py:45: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  if d.decorator_argspec is not None), _inspect.getargspec(target))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> step 500\n",
      ">>> step 1000\n",
      ">>> step 1500\n",
      ">>> step 2000\n",
      ">>> step 2500\n",
      ">>> step 3000\n",
      "FOUND Matches #: 413\n",
      "### 238 ### CUBE:P589-Fg012-V-C01-R01-D12022013-T130509-ML638 _018.jpg.npy_700_50\n",
      "loaded 3000 images\n",
      "3000\n",
      "INFO:tensorflow:Restoring parameters from /home/il239838/files/model_binary/tear_model2.ckpt\n",
      "Model restored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/il239838/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/util/tf_inspect.py:45: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  if d.decorator_argspec is not None), _inspect.getargspec(target))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> step 500\n",
      ">>> step 1000\n",
      ">>> step 1500\n",
      ">>> step 2000\n",
      ">>> step 2500\n",
      ">>> step 3000\n",
      "FOUND Matches #: 726\n",
      "### 239 ### CUBE:P589-Fg012-V-C01-R01-D12022013-T130509-ML638 _018.jpg.npy_400_50\n",
      "loaded 3000 images\n",
      "3000\n",
      "INFO:tensorflow:Restoring parameters from /home/il239838/files/model_binary/tear_model2.ckpt\n",
      "Model restored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/il239838/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/util/tf_inspect.py:45: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  if d.decorator_argspec is not None), _inspect.getargspec(target))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> step 500\n",
      ">>> step 1000\n",
      ">>> step 1500\n",
      ">>> step 2000\n",
      ">>> step 2500\n",
      ">>> step 3000\n",
      "FOUND Matches #: 1088\n",
      "### 240 ### CUBE:P589-Fg012-V-C01-R01-D12022013-T130509-ML638 _018.jpg.npy_600_50\n",
      "loaded 3000 images\n",
      "3000\n",
      "INFO:tensorflow:Restoring parameters from /home/il239838/files/model_binary/tear_model2.ckpt\n",
      "Model restored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/il239838/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/util/tf_inspect.py:45: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  if d.decorator_argspec is not None), _inspect.getargspec(target))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> step 500\n",
      ">>> step 1000\n",
      ">>> step 1500\n",
      ">>> step 2000\n",
      ">>> step 2500\n",
      ">>> step 3000\n",
      "FOUND Matches #: 1909\n",
      "### 241 ### CUBE:P589-Fg012-V-C01-R01-D12022013-T130509-ML638 _018.jpg.npy_250_1379\n",
      "loaded 3000 images\n",
      "3000\n",
      "INFO:tensorflow:Restoring parameters from /home/il239838/files/model_binary/tear_model2.ckpt\n",
      "Model restored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/il239838/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/util/tf_inspect.py:45: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  if d.decorator_argspec is not None), _inspect.getargspec(target))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> step 500\n",
      ">>> step 1000\n",
      ">>> step 1500\n",
      ">>> step 2000\n",
      ">>> step 2500\n",
      ">>> step 3000\n",
      "FOUND Matches #: 2187\n",
      "### 242 ### CUBE:P589-Fg012-V-C01-R01-D12022013-T130509-ML638 _018.jpg.npy_750_1379\n",
      "loaded 3000 images\n",
      "3000\n",
      "INFO:tensorflow:Restoring parameters from /home/il239838/files/model_binary/tear_model2.ckpt\n",
      "Model restored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/il239838/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/util/tf_inspect.py:45: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  if d.decorator_argspec is not None), _inspect.getargspec(target))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> step 500\n",
      ">>> step 1000\n",
      ">>> step 1500\n",
      ">>> step 2000\n",
      ">>> step 2500\n",
      ">>> step 3000\n",
      "FOUND Matches #: 1974\n",
      "### 243 ### CUBE:P589-Fg012-V-C01-R01-D12022013-T130509-ML638 _018.jpg.npy_900_1379\n",
      "loaded 3000 images\n",
      "3000\n",
      "INFO:tensorflow:Restoring parameters from /home/il239838/files/model_binary/tear_model2.ckpt\n",
      "Model restored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/il239838/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/util/tf_inspect.py:45: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  if d.decorator_argspec is not None), _inspect.getargspec(target))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> step 500\n",
      ">>> step 1000\n",
      ">>> step 1500\n",
      ">>> step 2000\n",
      ">>> step 2500\n",
      ">>> step 3000\n",
      "FOUND Matches #: 641\n",
      "### 244 ### CUBE:P589-Fg012-V-C01-R01-D12022013-T130509-ML638 _018.jpg.npy_150_50\n",
      "loaded 3000 images\n",
      "3000\n",
      "INFO:tensorflow:Restoring parameters from /home/il239838/files/model_binary/tear_model2.ckpt\n",
      "Model restored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/il239838/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/util/tf_inspect.py:45: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  if d.decorator_argspec is not None), _inspect.getargspec(target))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> step 500\n",
      ">>> step 1000\n",
      ">>> step 1500\n",
      ">>> step 2000\n",
      ">>> step 2500\n",
      ">>> step 3000\n",
      "FOUND Matches #: 88\n",
      "### 245 ### CUBE:P589-Fg012-V-C01-R01-D12022013-T130509-ML638 _018.jpg.npy_400_1379\n",
      "loaded 3000 images\n",
      "3000\n",
      "INFO:tensorflow:Restoring parameters from /home/il239838/files/model_binary/tear_model2.ckpt\n",
      "Model restored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/il239838/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/util/tf_inspect.py:45: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  if d.decorator_argspec is not None), _inspect.getargspec(target))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> step 500\n",
      ">>> step 1000\n",
      ">>> step 1500\n",
      ">>> step 2000\n",
      ">>> step 2500\n",
      ">>> step 3000\n",
      "FOUND Matches #: 1953\n",
      "### 246 ### CUBE:P589-Fg012-V-C01-R01-D12022013-T130509-ML638 _018.jpg.npy_650_50\n",
      "loaded 3000 images\n",
      "3000\n",
      "INFO:tensorflow:Restoring parameters from /home/il239838/files/model_binary/tear_model2.ckpt\n",
      "Model restored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/il239838/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/util/tf_inspect.py:45: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  if d.decorator_argspec is not None), _inspect.getargspec(target))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> step 500\n",
      ">>> step 1000\n",
      ">>> step 1500\n",
      ">>> step 2000\n",
      ">>> step 2500\n",
      ">>> step 3000\n",
      "FOUND Matches #: 1658\n",
      "### 247 ### CUBE:P589-Fg012-V-C01-R01-D12022013-T130509-ML638 _018.jpg.npy_0_1379\n",
      "loaded 3000 images\n",
      "3000\n",
      "INFO:tensorflow:Restoring parameters from /home/il239838/files/model_binary/tear_model2.ckpt\n",
      "Model restored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/il239838/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/util/tf_inspect.py:45: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  if d.decorator_argspec is not None), _inspect.getargspec(target))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> step 500\n",
      ">>> step 1000\n",
      ">>> step 1500\n",
      ">>> step 2000\n",
      ">>> step 2500\n",
      ">>> step 3000\n",
      "FOUND Matches #: 1043\n",
      "### 248 ### CUBE:P589-Fg012-V-C01-R01-D12022013-T130509-ML638 _018.jpg.npy_350_50\n",
      "loaded 3000 images\n",
      "3000\n",
      "INFO:tensorflow:Restoring parameters from /home/il239838/files/model_binary/tear_model2.ckpt\n",
      "Model restored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/il239838/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/util/tf_inspect.py:45: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  if d.decorator_argspec is not None), _inspect.getargspec(target))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> step 500\n",
      ">>> step 1000\n",
      ">>> step 1500\n",
      ">>> step 2000\n",
      ">>> step 2500\n",
      ">>> step 3000\n",
      "FOUND Matches #: 2951\n",
      "### 249 ### CUBE:P589-Fg012-V-C01-R01-D12022013-T130509-ML638 _018.jpg.npy_200_1379\n",
      "loaded 3000 images\n",
      "3000\n",
      "INFO:tensorflow:Restoring parameters from /home/il239838/files/model_binary/tear_model2.ckpt\n",
      "Model restored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/il239838/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/util/tf_inspect.py:45: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  if d.decorator_argspec is not None), _inspect.getargspec(target))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> step 500\n",
      ">>> step 1000\n",
      ">>> step 1500\n",
      ">>> step 2000\n",
      ">>> step 2500\n",
      ">>> step 3000\n",
      "FOUND Matches #: 1138\n",
      "### 250 ### CUBE:P589-Fg012-V-C01-R01-D12022013-T130509-ML638 _018.jpg.npy_500_1379\n",
      "loaded 3000 images\n",
      "3000\n",
      "INFO:tensorflow:Restoring parameters from /home/il239838/files/model_binary/tear_model2.ckpt\n",
      "Model restored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/il239838/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/util/tf_inspect.py:45: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  if d.decorator_argspec is not None), _inspect.getargspec(target))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> step 500\n",
      ">>> step 1000\n",
      ">>> step 1500\n",
      ">>> step 2000\n",
      ">>> step 2500\n",
      ">>> step 3000\n",
      "FOUND Matches #: 1305\n",
      "### 251 ### CUBE:P589-Fg012-V-C01-R01-D12022013-T130509-ML638 _018.jpg.npy_100_1379\n",
      "loaded 3000 images\n",
      "3000\n",
      "INFO:tensorflow:Restoring parameters from /home/il239838/files/model_binary/tear_model2.ckpt\n",
      "Model restored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/il239838/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/util/tf_inspect.py:45: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  if d.decorator_argspec is not None), _inspect.getargspec(target))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> step 500\n",
      ">>> step 1000\n",
      ">>> step 1500\n",
      ">>> step 2000\n",
      ">>> step 2500\n",
      ">>> step 3000\n",
      "FOUND Matches #: 991\n",
      "### 252 ### CUBE:P589-Fg012-V-C01-R01-D12022013-T130509-ML638 _018.jpg.npy_250_50\n",
      "loaded 3000 images\n",
      "3000\n",
      "INFO:tensorflow:Restoring parameters from /home/il239838/files/model_binary/tear_model2.ckpt\n",
      "Model restored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/il239838/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/util/tf_inspect.py:45: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  if d.decorator_argspec is not None), _inspect.getargspec(target))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> step 500\n",
      ">>> step 1000\n",
      ">>> step 1500\n",
      ">>> step 2000\n",
      ">>> step 2500\n",
      ">>> step 3000\n",
      "FOUND Matches #: 2030\n",
      "### 253 ### CUBE:P589-Fg012-V-C01-R01-D12022013-T130509-ML638 _018.jpg.npy_850_50\n",
      "loaded 3000 images\n",
      "3000\n",
      "INFO:tensorflow:Restoring parameters from /home/il239838/files/model_binary/tear_model2.ckpt\n",
      "Model restored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/il239838/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/util/tf_inspect.py:45: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  if d.decorator_argspec is not None), _inspect.getargspec(target))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> step 500\n",
      ">>> step 1000\n",
      ">>> step 1500\n",
      ">>> step 2000\n",
      ">>> step 2500\n",
      ">>> step 3000\n",
      "FOUND Matches #: 10\n",
      "### 254 ### CUBE:P589-Fg012-V-C01-R01-D12022013-T130509-ML638 _018.jpg.npy_800_1379\n",
      "loaded 3000 images\n",
      "3000\n",
      "INFO:tensorflow:Restoring parameters from /home/il239838/files/model_binary/tear_model2.ckpt\n",
      "Model restored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/il239838/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/util/tf_inspect.py:45: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  if d.decorator_argspec is not None), _inspect.getargspec(target))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> step 500\n",
      ">>> step 1000\n",
      ">>> step 1500\n",
      ">>> step 2000\n",
      ">>> step 2500\n",
      ">>> step 3000\n",
      "FOUND Matches #: 1759\n",
      "### 255 ### CUBE:P589-Fg012-V-C01-R01-D12022013-T130509-ML638 _018.jpg.npy_550_50\n",
      "loaded 3000 images\n",
      "3000\n",
      "INFO:tensorflow:Restoring parameters from /home/il239838/files/model_binary/tear_model2.ckpt\n",
      "Model restored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/il239838/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/util/tf_inspect.py:45: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  if d.decorator_argspec is not None), _inspect.getargspec(target))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> step 500\n",
      ">>> step 1000\n",
      ">>> step 1500\n",
      ">>> step 2000\n",
      ">>> step 2500\n",
      ">>> step 3000\n",
      "FOUND Matches #: 1755\n",
      "### 256 ### CUBE:P589-Fg012-V-C01-R01-D12022013-T130509-ML638 _018.jpg.npy_950_1379\n",
      "loaded 3000 images\n",
      "3000\n",
      "INFO:tensorflow:Restoring parameters from /home/il239838/files/model_binary/tear_model2.ckpt\n",
      "Model restored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/il239838/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/util/tf_inspect.py:45: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  if d.decorator_argspec is not None), _inspect.getargspec(target))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> step 500\n",
      ">>> step 1000\n",
      ">>> step 1500\n",
      ">>> step 2000\n",
      ">>> step 2500\n",
      ">>> step 3000\n",
      "FOUND Matches #: 1295\n",
      "### 257 ### CUBE:P589-Fg012-V-C01-R01-D12022013-T130509-ML638 _018.jpg.npy_100_50\n",
      "loaded 3000 images\n",
      "3000\n",
      "INFO:tensorflow:Restoring parameters from /home/il239838/files/model_binary/tear_model2.ckpt\n",
      "Model restored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/il239838/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/util/tf_inspect.py:45: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  if d.decorator_argspec is not None), _inspect.getargspec(target))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> step 500\n",
      ">>> step 1000\n",
      ">>> step 1500\n",
      ">>> step 2000\n",
      ">>> step 2500\n",
      ">>> step 3000\n",
      "FOUND Matches #: 783\n",
      "### 258 ### CUBE:P589-Fg012-V-C01-R01-D12022013-T130509-ML638 _018.jpg.npy_900_50\n",
      "loaded 3000 images\n",
      "3000\n",
      "INFO:tensorflow:Restoring parameters from /home/il239838/files/model_binary/tear_model2.ckpt\n",
      "Model restored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/il239838/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/util/tf_inspect.py:45: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  if d.decorator_argspec is not None), _inspect.getargspec(target))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> step 500\n"
     ]
    }
   ],
   "source": [
    "iter_validate(cubes_set, ROOT_FOLDER + \"model_binary/tear_model2.ckpt\", CUBE_SIZE, VOL_FOLDER+ \"mixed/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### STOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# RE-TEST - take test-set and cross-validate on it (uncomment all for full test run)\n",
    "# train_imgs, train_lbls = \\\n",
    "#     load_train_from_disk(ROOT_FOLDER + \"train_concats3/\")\n",
    "# tf.reset_default_graph()\n",
    "# model_tf_deep(250, 1)    \n",
    "# validate2_for_cross_validation(train_imgs, train_lbls, ROOT_FOLDER + \"model_binary/tear_model2.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#len(cubes_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
