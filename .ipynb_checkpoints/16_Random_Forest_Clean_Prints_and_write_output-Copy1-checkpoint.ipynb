{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# IMPORTS\n",
    "# Pandas is used for data manipulation\n",
    "import pandas as pd\n",
    "# Use numpy to convert to arrays\n",
    "import numpy as np\n",
    "# Using Skicit-learn to split data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Import tools needed for visualization\n",
    "from sklearn.tree import export_graphviz\n",
    "import pydot\n",
    "# Import the model we are using\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "# Utility to store and load model from disk\n",
    "from sklearn.externals import joblib\n",
    "# write csv files\n",
    "import csv\n",
    "# Import charting lib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# UTIL\n",
    "def test_model(forest_model, test_features, test_labels):\n",
    "    # Use the forest's predict method on the test data\n",
    "    predictions = np.round(forest_model.predict(test_features))\n",
    "\n",
    "    # Calculate the absolute errors\n",
    "    errors = abs(predictions - test_labels)\n",
    "\n",
    "    # Print out the mean absolute error (mae)\n",
    "    print('Mean Absolute Error:', round(np.mean(errors), 2))\n",
    "\n",
    "    # Calculate mean absolute percentage error (MAPE)\n",
    "    mape = 100 * (errors / test_labels)\n",
    "\n",
    "    # Calculate and display accuracy\n",
    "    accuracy = 100 - np.mean(mape)\n",
    "    print('Accuracy:', round(accuracy, 2), '%.')\n",
    "\n",
    "    # Pull out one tree from the forest\n",
    "    #tree = forest_model.estimators_[5]\n",
    "    # print('The depth of this tree is:', tree.tree_.max_depth)\n",
    "\n",
    "    total_trues = sum(x == 2 for x in test_labels)\n",
    "    total_predictions = sum(x == 2 for x in predictions)\n",
    "    total_errors = sum(x == 1 for x in errors)\n",
    "    print('Total Samples:', len(test_labels))\n",
    "    print('Total Trues:', total_trues)\n",
    "    print('Total Predictions:', total_predictions)\n",
    "    print('Total Errors:', total_errors)\n",
    "\n",
    "    false_positive = sum(predict > label for predict, label in zip(predictions, test_labels))\n",
    "    false_negative = sum(predict < label for predict, label in zip(predictions, test_labels))\n",
    "    true_positive = total_predictions - false_positive\n",
    "    print('false_positive:', false_positive)\n",
    "    print('false_negative:', false_negative)\n",
    "    print('true_positive:', true_positive)\n",
    "    \n",
    "    print('>>>>>>>>>>>>>>>>>>>>')\n",
    "    for index, value in enumerate(zip(predictions, test_labels)):\n",
    "        if value[0] < value[1]:\n",
    "            print(test_features_[index,0])\n",
    "    print('>>>>>>>>>>>>>>>>>>>>')\n",
    "    \n",
    "    \n",
    "    precision = true_positive / total_predictions\n",
    "    recall = true_positive / (true_positive + false_negative)\n",
    "    print('precision:', precision)\n",
    "    print('recall:', recall)\n",
    "    return precision, recall\n",
    "\n",
    "def draw_tree(forest_model, test_features, test_labels): \n",
    "    importances = forest_model.feature_importances_\n",
    "    std = np.std([tree.feature_importances_ for tree in forest_model.estimators_],\n",
    "                 axis=0)\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "\n",
    "    # Print the feature ranking\n",
    "    print(\"Feature ranking:\")\n",
    "\n",
    "    for f in range(test_features.shape[1]):\n",
    "        print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))\n",
    "\n",
    "    # Plot the feature importances of the forest\n",
    "    plt.figure()\n",
    "    plt.title(\"Feature importances\")\n",
    "    plt.bar(range(test_features.shape[1]), importances[indices],\n",
    "           color=\"r\", yerr=std[indices], align=\"center\")\n",
    "    plt.xticks(range(test_features.shape[1]), indices)\n",
    "    plt.xlim([-1, test_features.shape[1]])\n",
    "    plt.show()    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fragmanetAndSide',\n",
       " 'fragmentTotal',\n",
       " 'fragmentVote',\n",
       " 'devideVoteByTotal',\n",
       " 'fragmentAndSideVote',\n",
       " 'devideSideVoteBySideTotal',\n",
       " 'fragmentAndSideTrendVote',\n",
       " 'devideSideTrendVoteBySideTotal',\n",
       " 'fragmentAndSideTrendVoteStrict',\n",
       " 'devideSideTrendVoteStrictBySideTotal',\n",
       " 'fragmentAndSideTrendVoteSync',\n",
       " 'devideSideTrendVoteSyncBySideTotal']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare the source data\n",
    "features = pd.read_csv('20181007_072858_votes_cubes_match_synt_75.csv')\n",
    "\n",
    "# Remove the irrelevant texts from the features\n",
    "# axis 1 refers to the columns\n",
    "# features = features.drop('fragmanetAndSide', axis = 1)\n",
    "features = features.drop('fragment', axis = 1)\n",
    "features = features.drop('fragmentAndSideTotal', axis = 1)\n",
    "features = features.drop('fragmentAndSideTrend', axis = 1)\n",
    "features = features.drop('fragmentAndSideCubes', axis = 1)\n",
    "features = features.drop('fragmentAndSideDrawRect', axis = 1)\n",
    "features = features.drop('fragmentAndSideMatchPoint', axis = 1)\n",
    "features = features.drop('origCoordinates', axis = 1)\n",
    "features = features.drop(\"firstFileName\", axis = 1)\n",
    "features = features.drop(\"firstCroppedWidth\", axis = 1)\n",
    "features = features.drop(\"firstOffsetX\", axis = 1)\n",
    "features = features.drop(\"firstOffsetY\", axis = 1)\n",
    "features = features.drop(\"firstHorizontalFlip\", axis = 1)\n",
    "features = features.drop(\"secondFileName\", axis = 1)\n",
    "features = features.drop(\"secondCroppedWidth\", axis = 1)\n",
    "features = features.drop(\"secondOffsetX\", axis = 1)\n",
    "features = features.drop(\"secondOffsetY\", axis = 1)\n",
    "features = features.drop(\"secondHorizontalFlip\", axis = 1)\n",
    "\n",
    "# features = features.drop('fragmentTotal', axis = 1)\n",
    "# features = features.drop('fragmentAndSideVote', axis = 1)\n",
    "# features = features.drop('fragmentAndSideTrendVote', axis = 1)\n",
    "\n",
    "# One-hot encode categorical features\n",
    "#features = pd.get_dummies(features)\n",
    "\n",
    "# Labels are the values we want to predict\n",
    "labels = np.array(features['class'])\n",
    "labels = labels + 1\n",
    "\n",
    "# Remove the labels from the features\n",
    "# axis 1 refers to the columns\n",
    "features= features.drop('class', axis = 1)\n",
    "\n",
    "# Saving feature names for later use\n",
    "feature_list = list(features.columns)\n",
    "\n",
    "# Convert to numpy array\n",
    "features = np.array(features)\n",
    "\n",
    "feature_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "code_folding": [],
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.02\n",
      "Accuracy: 98.89 %.\n",
      "Total Samples: 812\n",
      "Total Trues: 34\n",
      "Total Predictions: 19\n",
      "Total Errors: 17\n",
      "false_positive: 1\n",
      "false_negative: 16\n",
      "true_positive: 18\n",
      ">>>>>>>>>>>>>>>>>>>>\n",
      "PX303Fg006_7X3_0X2_1_PX303Fg006_7X3_1X2_0\n",
      "PX303Fg006_5X3_0X1_1_PX303Fg006_5X3_1X1_0\n",
      "PX303Fg006_7X3_3X2_1_PX303Fg006_7X3_4X2_0\n",
      "PX303Fg006_7X3_1X1_1_PX303Fg006_7X3_2X1_0\n",
      "PX303Fg006_3X3_0X1_1_PX303Fg006_3X3_1X1_0\n",
      "PX303Fg006_6X3_1X1_1_PX303Fg006_6X3_2X1_0\n",
      "PX303Fg006_6X2_3X0_1_PX303Fg006_6X2_4X0_0\n",
      "PX303Fg006_6X3_2X1_1_PX303Fg006_6X3_3X1_0\n",
      "PX303Fg006_7X2_0X1_1_PX303Fg006_7X2_1X1_0\n",
      "PX303Fg006_7X2_0X0_1_PX303Fg006_7X2_1X0_0\n",
      "PX303Fg006_7X2_2X1_1_PX303Fg006_7X2_3X1_0\n",
      "PX303Fg006_7X3_0X0_1_PX303Fg006_7X3_1X0_0\n",
      "PX303Fg006_3X2_1X1_1_PX303Fg006_3X2_2X1_0\n",
      "PX303Fg006_6X2_2X0_1_PX303Fg006_6X2_3X0_0\n",
      "PX303Fg006_5X3_0X0_1_PX303Fg006_5X3_1X0_0\n",
      "PX303Fg006_7X3_4X0_1_PX303Fg006_7X3_5X0_0\n",
      ">>>>>>>>>>>>>>>>>>>>\n",
      "precision: 0.947368421053\n",
      "recall: 0.529411764706\n",
      "Feature ranking:\n",
      "1. feature 3 (0.216050)\n",
      "2. feature 5 (0.172423)\n",
      "3. feature 7 (0.079215)\n",
      "4. feature 0 (0.078178)\n",
      "5. feature 9 (0.074316)\n",
      "6. feature 6 (0.069013)\n",
      "7. feature 8 (0.067858)\n",
      "8. feature 10 (0.066284)\n",
      "9. feature 1 (0.065034)\n",
      "10. feature 4 (0.063966)\n",
      "11. feature 2 (0.047662)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEKCAYAAADpfBXhAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQfBmxwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x115dc6cc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Random Forest 1st model\n",
    "# Split the data into training and testing sets\n",
    "train_features_, test_features_, train_labels, test_labels = train_test_split(features, labels, test_size = 0.3)\n",
    "\n",
    "train_features = train_features_[:,1:] # remove the fragmentAndSide column which is the label\n",
    "test_features = test_features_[:,1:] # remove the fragmentAndSide column which is the label\n",
    "\n",
    "# Instantiate model \n",
    "rf = RandomForestClassifier(n_estimators= 1000, random_state=42, n_jobs=-1)\n",
    "\n",
    "rf.fit(train_features, train_labels)\n",
    "\n",
    "test_model(rf, test_features, test_labels)\n",
    "draw_tree(rf, test_features, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.02\n",
      "Accuracy: 98.95 %.\n",
      "Total Samples: 812\n",
      "Total Trues: 34\n",
      "Total Predictions: 26\n",
      "Total Errors: 14\n",
      "false_positive: 3\n",
      "false_negative: 11\n",
      "true_positive: 23\n",
      ">>>>>>>>>>>>>>>>>>>>\n",
      "PX303Fg006_5X3_0X1_1_PX303Fg006_5X3_1X1_0\n",
      "PX303Fg006_7X3_3X2_1_PX303Fg006_7X3_4X2_0\n",
      "PX303Fg006_3X3_0X1_1_PX303Fg006_3X3_1X1_0\n",
      "PX303Fg006_6X3_1X1_1_PX303Fg006_6X3_2X1_0\n",
      "PX303Fg006_6X3_2X1_1_PX303Fg006_6X3_3X1_0\n",
      "PX303Fg006_7X2_0X1_1_PX303Fg006_7X2_1X1_0\n",
      "PX303Fg006_6X2_0X1_1_PX303Fg006_6X2_1X1_0\n",
      "PX303Fg006_7X2_0X0_1_PX303Fg006_7X2_1X0_0\n",
      "PX303Fg006_7X2_2X1_1_PX303Fg006_7X2_3X1_0\n",
      "PX303Fg006_3X2_1X1_1_PX303Fg006_3X2_2X1_0\n",
      "PX303Fg006_5X3_0X0_1_PX303Fg006_5X3_1X0_0\n",
      ">>>>>>>>>>>>>>>>>>>>\n",
      "precision: 0.884615384615\n",
      "recall: 0.676470588235\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.88461538461538458, 0.67647058823529416)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate model \n",
    "ab = AdaBoostClassifier(n_estimators= 1000, learning_rate=0.8)\n",
    "\n",
    "ab.fit(train_features, train_labels)\n",
    "\n",
    "test_model(ab, test_features, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.02\n",
      "Accuracy: 99.14 %.\n",
      "Total Samples: 812\n",
      "Total Trues: 34\n",
      "Total Predictions: 23\n",
      "Total Errors: 13\n",
      "false_positive: 1\n",
      "false_negative: 12\n",
      "true_positive: 22\n",
      ">>>>>>>>>>>>>>>>>>>>\n",
      "PX303Fg006_5X3_0X1_1_PX303Fg006_5X3_1X1_0\n",
      "PX303Fg006_7X3_3X2_1_PX303Fg006_7X3_4X2_0\n",
      "PX303Fg006_7X3_1X1_1_PX303Fg006_7X3_2X1_0\n",
      "PX303Fg006_3X3_0X1_1_PX303Fg006_3X3_1X1_0\n",
      "PX303Fg006_6X3_1X1_1_PX303Fg006_6X3_2X1_0\n",
      "PX303Fg006_6X3_2X1_1_PX303Fg006_6X3_3X1_0\n",
      "PX303Fg006_7X2_0X0_1_PX303Fg006_7X2_1X0_0\n",
      "PX303Fg006_7X3_0X0_1_PX303Fg006_7X3_1X0_0\n",
      "PX303Fg006_3X2_1X1_1_PX303Fg006_3X2_2X1_0\n",
      "PX303Fg006_6X2_2X0_1_PX303Fg006_6X2_3X0_0\n",
      "PX303Fg006_5X3_0X0_1_PX303Fg006_5X3_1X0_0\n",
      "PX303Fg006_7X3_4X0_1_PX303Fg006_7X3_5X0_0\n",
      ">>>>>>>>>>>>>>>>>>>>\n",
      "precision: 0.95652173913\n",
      "recall: 0.647058823529\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.95652173913043481, 0.6470588235294118)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate model \n",
    "bc = BaggingClassifier(n_estimators= 1000)\n",
    "\n",
    "bc.fit(train_features, train_labels)\n",
    "\n",
    "test_model(bc, test_features, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.02\n",
      "Accuracy: 98.77 %.\n",
      "Total Samples: 812\n",
      "Total Trues: 34\n",
      "Total Predictions: 20\n",
      "Total Errors: 18\n",
      "false_positive: 2\n",
      "false_negative: 16\n",
      "true_positive: 18\n",
      ">>>>>>>>>>>>>>>>>>>>\n",
      "PX303Fg006_7X3_0X2_1_PX303Fg006_7X3_1X2_0\n",
      "PX303Fg006_5X3_0X1_1_PX303Fg006_5X3_1X1_0\n",
      "PX303Fg006_7X3_3X2_1_PX303Fg006_7X3_4X2_0\n",
      "PX303Fg006_7X3_1X1_1_PX303Fg006_7X3_2X1_0\n",
      "PX303Fg006_3X3_0X1_1_PX303Fg006_3X3_1X1_0\n",
      "PX303Fg006_6X3_1X1_1_PX303Fg006_6X3_2X1_0\n",
      "PX303Fg006_6X2_3X0_1_PX303Fg006_6X2_4X0_0\n",
      "PX303Fg006_6X3_2X1_1_PX303Fg006_6X3_3X1_0\n",
      "PX303Fg006_7X2_0X1_1_PX303Fg006_7X2_1X1_0\n",
      "PX303Fg006_7X2_0X0_1_PX303Fg006_7X2_1X0_0\n",
      "PX303Fg006_7X2_2X1_1_PX303Fg006_7X2_3X1_0\n",
      "PX303Fg006_7X3_0X0_1_PX303Fg006_7X3_1X0_0\n",
      "PX303Fg006_3X2_1X1_1_PX303Fg006_3X2_2X1_0\n",
      "PX303Fg006_6X2_2X0_1_PX303Fg006_6X2_3X0_0\n",
      "PX303Fg006_5X3_0X0_1_PX303Fg006_5X3_1X0_0\n",
      "PX303Fg006_7X3_4X0_1_PX303Fg006_7X3_5X0_0\n",
      ">>>>>>>>>>>>>>>>>>>>\n",
      "precision: 0.9\n",
      "recall: 0.529411764706\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.90000000000000002, 0.52941176470588236)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate model \n",
    "et = ExtraTreesClassifier(n_estimators= 1000)\n",
    "\n",
    "et.fit(train_features, train_labels)\n",
    "\n",
    "test_model(et, test_features, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.01\n",
      "Accuracy: 99.26 %.\n",
      "Total Samples: 812\n",
      "Total Trues: 34\n",
      "Total Predictions: 25\n",
      "Total Errors: 11\n",
      "false_positive: 1\n",
      "false_negative: 10\n",
      "true_positive: 24\n",
      ">>>>>>>>>>>>>>>>>>>>\n",
      "PX303Fg006_5X3_0X1_1_PX303Fg006_5X3_1X1_0\n",
      "PX303Fg006_7X3_3X2_1_PX303Fg006_7X3_4X2_0\n",
      "PX303Fg006_7X3_1X1_1_PX303Fg006_7X3_2X1_0\n",
      "PX303Fg006_3X3_0X1_1_PX303Fg006_3X3_1X1_0\n",
      "PX303Fg006_6X3_1X1_1_PX303Fg006_6X3_2X1_0\n",
      "PX303Fg006_6X3_2X1_1_PX303Fg006_6X3_3X1_0\n",
      "PX303Fg006_7X2_0X0_1_PX303Fg006_7X2_1X0_0\n",
      "PX303Fg006_7X3_0X0_1_PX303Fg006_7X3_1X0_0\n",
      "PX303Fg006_3X2_1X1_1_PX303Fg006_3X2_2X1_0\n",
      "PX303Fg006_5X3_0X0_1_PX303Fg006_5X3_1X0_0\n",
      ">>>>>>>>>>>>>>>>>>>>\n",
      "precision: 0.96\n",
      "recall: 0.705882352941\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.95999999999999996, 0.70588235294117652)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate model \n",
    "gb = GradientBoostingClassifier(n_estimators= 1000)\n",
    "\n",
    "gb.fit(train_features, train_labels)\n",
    "\n",
    "test_model(gb, test_features, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.01\n",
      "Accuracy: 99.26 %.\n",
      "Total Samples: 812\n",
      "Total Trues: 34\n",
      "Total Predictions: 22\n",
      "Total Errors: 12\n",
      "false_positive: 0\n",
      "false_negative: 12\n",
      "true_positive: 22\n",
      ">>>>>>>>>>>>>>>>>>>>\n",
      "PX303Fg006_7X3_0X2_1_PX303Fg006_7X3_1X2_0\n",
      "PX303Fg006_5X3_0X1_1_PX303Fg006_5X3_1X1_0\n",
      "PX303Fg006_7X3_3X2_1_PX303Fg006_7X3_4X2_0\n",
      "PX303Fg006_7X3_1X1_1_PX303Fg006_7X3_2X1_0\n",
      "PX303Fg006_3X3_0X1_1_PX303Fg006_3X3_1X1_0\n",
      "PX303Fg006_6X3_1X1_1_PX303Fg006_6X3_2X1_0\n",
      "PX303Fg006_6X3_2X1_1_PX303Fg006_6X3_3X1_0\n",
      "PX303Fg006_7X2_0X0_1_PX303Fg006_7X2_1X0_0\n",
      "PX303Fg006_7X3_0X0_1_PX303Fg006_7X3_1X0_0\n",
      "PX303Fg006_3X2_1X1_1_PX303Fg006_3X2_2X1_0\n",
      "PX303Fg006_5X3_0X0_1_PX303Fg006_5X3_1X0_0\n",
      "PX303Fg006_7X3_4X0_1_PX303Fg006_7X3_5X0_0\n",
      ">>>>>>>>>>>>>>>>>>>>\n",
      "precision: 1.0\n",
      "recall: 0.647058823529\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1.0, 0.6470588235294118)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate model \n",
    "vt = VotingClassifier(estimators=[('ab', ab), ('rf', rf), ('bc', bc), ('et', et), ('gb', gb)], voting='soft', n_jobs=-1)\n",
    "\n",
    "vt.fit(train_features, train_labels)\n",
    "\n",
    "test_model(vt, test_features, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import cross_val_predict\n",
    "# from sklearn import metrics\n",
    "# predicted = cross_val_predict(rf, test_features, test_labels, cv=5)\n",
    "# metrics.accuracy_score(test_labels, np.round(predicted)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Random Forest 2nd variation of model - just for reference - not used\n",
    "rf_new = RandomForestRegressor(n_estimators = 1000, criterion = 'mse', max_depth = None, \n",
    "                               min_samples_split = 2, min_samples_leaf = 1)\n",
    "rf_new.fit(train_features, train_labels)\n",
    "\n",
    "test_model(rf_new, test_features, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Random Forest 3rd model - Limit depth of tree to 2 levels - not used\n",
    "rf_small = RandomForestRegressor(n_estimators=10, max_depth = 3, random_state=42)\n",
    "rf_small.fit(train_features, train_labels)\n",
    "\n",
    "test_model(rf_small, test_features, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Finally - use the 1st model and this time train on the entire set \n",
    "rf.fit(features, labels);\n",
    "\n",
    "joblib.dump(rf, 'rndFstBasic.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Run on the output of the voting and classify them\n",
    "# Read in data as pandas dataframe\n",
    "orig_features = pd.read_csv('pairs_votes.csv') #('real_cubes_all_vote.csv')\n",
    "\n",
    "# Remove the irrelevant texts from the features\n",
    "# axis 1 refers to the columns\n",
    "features = orig_features.drop('fragmanetAndSide', axis = 1)\n",
    "features = features.drop('fragment', axis = 1)\n",
    "features = features.drop('fragmentAndSideTotal', axis = 1)\n",
    "features = features.drop('fragmentAndSideTrend', axis = 1)\n",
    "features = features.drop('fragmentAndSideCubes', axis = 1)\n",
    "features = features.drop('fragmentAndSideDrawRect', axis = 1)\n",
    "features = features.drop('fragmentAndSideMatchPoint', axis = 1)\n",
    "features = features.drop('origCoordinates', axis = 1)\n",
    "features = features.drop(\"firstFileName\", axis = 1)\n",
    "features = features.drop(\"firstCroppedWidth\", axis = 1)\n",
    "features = features.drop(\"firstOffsetX\", axis = 1)\n",
    "features = features.drop(\"firstOffsetY\", axis = 1)\n",
    "features = features.drop(\"firstHorizontalFlip\", axis = 1)\n",
    "features = features.drop(\"secondFileName\", axis = 1)\n",
    "features = features.drop(\"secondCroppedWidth\", axis = 1)\n",
    "features = features.drop(\"secondOffsetX\", axis = 1)\n",
    "features = features.drop(\"secondOffsetY\", axis = 1)\n",
    "features = features.drop(\"secondHorizontalFlip\", axis = 1)\n",
    "features = features.drop(\"class\", axis = 1)\n",
    "\n",
    "forest_model = joblib.load('rndFstBasic.pkl') \n",
    "\n",
    "predictions = np.round(forest_model.predict(features))-1\n",
    "orig_features[\"class\"] = predictions\n",
    "filtered = orig_features[orig_features[\"class\"] == 1]\n",
    "filtered.to_csv('pairs_final.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "hide_code_all_hidden": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
