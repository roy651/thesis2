{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# IMPORTS\n",
    "# Pandas is used for data manipulation\n",
    "import pandas as pd\n",
    "# Use numpy to convert to arrays\n",
    "import numpy as np\n",
    "# Using Skicit-learn to split data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Import tools needed for visualization\n",
    "from sklearn.tree import export_graphviz\n",
    "import pydot\n",
    "# Import the model we are using\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# Utility to store and load model from disk\n",
    "from sklearn.externals import joblib\n",
    "# write csv files\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# UTIL\n",
    "def test_model(forest_model, test_features, test_labels):\n",
    "    # Use the forest's predict method on the test data\n",
    "    predictions = np.round(forest_model.predict(test_features))\n",
    "\n",
    "    # Calculate the absolute errors\n",
    "    errors = abs(predictions - test_labels)\n",
    "\n",
    "    # Print out the mean absolute error (mae)\n",
    "    print('Mean Absolute Error:', round(np.mean(errors), 2))\n",
    "\n",
    "    # Calculate mean absolute percentage error (MAPE)\n",
    "    mape = 100 * (errors / test_labels)\n",
    "\n",
    "    # Calculate and display accuracy\n",
    "    accuracy = 100 - np.mean(mape)\n",
    "    print('Accuracy:', round(accuracy, 2), '%.')\n",
    "\n",
    "    # Pull out one tree from the forest\n",
    "    tree = rf.estimators_[5]\n",
    "\n",
    "    print('The depth of this tree is:', tree.tree_.max_depth)\n",
    "\n",
    "    total_trues = sum(x == 2 for x in test_labels)\n",
    "    total_predictions = sum(x == 2 for x in predictions)\n",
    "    total_errors = sum(x == 1 for x in errors)\n",
    "\n",
    "    false_positive = sum(predict > label for predict, label in zip(predictions, test_labels))\n",
    "    false_negative = sum(predict < label for predict, label in zip(predictions, test_labels))\n",
    "    true_positive = total_predictions - false_positive\n",
    "    precision = true_positive / total_predictions\n",
    "    recall = true_positive / (true_positive + false_negative)\n",
    "    print('precision:', precision)\n",
    "    print('recall:', recall)\n",
    "\n",
    "    return precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.01\n",
      "Accuracy: 99.66 %.\n",
      "The depth of this tree is: 12\n",
      "precision: 0.947368421053\n",
      "recall: 0.885245901639\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.94736842105263153, 0.88524590163934425)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Forest 1st model\n",
    "# Read in data as pandas dataframe and display first 5 rows\n",
    "features = pd.read_csv('synt_cubes_all_vote.csv')\n",
    "\n",
    "# Remove the irrelevant texts from the features\n",
    "# axis 1 refers to the columns\n",
    "features = features.drop('fragmanetAndSide', axis = 1)\n",
    "features = features.drop('fragment', axis = 1)\n",
    "features = features.drop('fragmentAndSideTrend', axis = 1)\n",
    "features = features.drop('fragmentAndSideCubes', axis = 1)\n",
    "features = features.drop('origCoordinates', axis = 1)\n",
    "\n",
    "# One-hot encode categorical features\n",
    "features = pd.get_dummies(features)\n",
    "\n",
    "# Labels are the values we want to predict\n",
    "labels = np.array(features['class'])\n",
    "labels = labels + 1\n",
    "\n",
    "# Remove the labels from the features\n",
    "# axis 1 refers to the columns\n",
    "features= features.drop('class', axis = 1)\n",
    "\n",
    "# Saving feature names for later use\n",
    "feature_list = list(features.columns)\n",
    "\n",
    "# Convert to numpy array\n",
    "features = np.array(features)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size = 0.25)\n",
    "\n",
    "# Instantiate model \n",
    "rf = RandomForestRegressor(n_estimators= 1000, random_state=42)\n",
    "\n",
    "test_model(rf, test_features, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.01\n",
      "Accuracy: 99.66 %.\n",
      "The depth of this tree is: 12\n",
      "precision: 0.947368421053\n",
      "recall: 0.885245901639\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.94736842105263153, 0.88524590163934425)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Forest 2nd variation of model - just for reference - not used\n",
    "rf_new = RandomForestRegressor(n_estimators = 100, criterion = 'mse', max_depth = None, \n",
    "                               min_samples_split = 2, min_samples_leaf = 1)\n",
    "rf_new.fit(train_features, train_labels)\n",
    "\n",
    "test_model(rf_new, test_features, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.01\n",
      "Accuracy: 99.69 %.\n",
      "The depth of this tree is: 10\n",
      "precision: 0.968253968254\n",
      "recall: 0.884057971014\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.96825396825396826, 0.88405797101449279)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Forest 3rd model - Limit depth of tree to 2 levels - not used\n",
    "rf_small = RandomForestRegressor(n_estimators=10, max_depth = 3, random_state=42)\n",
    "rf_small.fit(train_features, train_labels)\n",
    "\n",
    "test_model(rf_small, test_features, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rndFstBasic.pkl']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finally - use the 1st model and this time train on the entire set \n",
    "rf.fit(features, labels);\n",
    "\n",
    "joblib.dump(rf, 'rndFstBasic.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run on the output of the voting and classify them\n",
    "# Read in data as pandas dataframe\n",
    "orig_features = pd.read_csv('cubes_X3_e.csv') #('real_cubes_all_vote.csv')\n",
    "\n",
    "# Remove the irrelevant texts from the features\n",
    "# axis 1 refers to the columns\n",
    "features = orig_features.drop('fragmanetAndSide', axis = 1)\n",
    "features = features.drop('fragment', axis = 1)\n",
    "features = features.drop('fragmentAndSideTrend', axis = 1)\n",
    "features = features.drop('fragmentAndSideCubes', axis = 1)\n",
    "features = features.drop('origCoordinates', axis = 1)\n",
    "features = features.drop(\"fitstFileName\", axis = 1)\n",
    "features = features.drop(\"firstCroppedWidth\", axis = 1)\n",
    "features = features.drop(\"firstOffsetX\", axis = 1)\n",
    "features = features.drop(\"firstOffsetY\", axis = 1)\n",
    "features = features.drop(\"firstHorizontalFlip\", axis = 1)\n",
    "features = features.drop(\"secondFileName\", axis = 1)\n",
    "features = features.drop(\"secondCroppedWidth\", axis = 1)\n",
    "features = features.drop(\"secondOffsetX\", axis = 1)\n",
    "features = features.drop(\"secondOffsetY\", axis = 1)\n",
    "features = features.drop(\"secondHorizontalFlip\", axis = 1)\n",
    "\n",
    "forest_model = joblib.load('rndFstBasic.pkl') \n",
    "\n",
    "predictions = np.round(forest_model.predict(features))-1\n",
    "orig_features[\"class\"] = predictions\n",
    "filtered = orig_features[orig_features[\"class\"] == 1]\n",
    "filtered.to_csv('match_X3_e.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "hide_code_all_hidden": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
