{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# RUN Main import block and TODO list\n",
    "\n",
    "# TODO: see how uri calculated the ridges\n",
    "\n",
    "# TODO: Perform Histogram equalization - start with it\n",
    "# TODO: \n",
    "# take integral from the Highest peak+-0.005 divide by integral of the entire graph \n",
    "# This will be the peakness measure for the PSD ==> The desired ridge index\n",
    "# TODO:\n",
    "# take integral from the Highest peak+-0.005 divide by integral of the entire graph - it's the peakness measure for the PSD\n",
    "# must select a peak above a min threshold in order to ignore noisy frequency\n",
    "# must ignore peaks above a certain threshold in order to detect meaningful frequency\n",
    "# run the PSD in moving windows every 200 px (deduced from the below PSD pointing to a freq of 1/0.02=50-> times 4= 200px)\n",
    "# and medianf the result of the windows\n",
    "# TODO:\n",
    "# Another alternative: (with Yariv)\n",
    "# Run PSD column by column - get the phase, freq, peakness and reconstruct an artificial ridge slice\n",
    "# from this - reconstruct a \"clean\" artificial ridge image\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.image as img\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import urllib.request\n",
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "from scipy import ndimage\n",
    "from scipy import signal\n",
    "#import cv2\n",
    "\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "import mahotas as mh\n",
    "from mahotas import polygon\n",
    "# import pymorph as pm\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "from scipy import ndimage as nd\n",
    "import skimage.transform as transform\n",
    "import skimage.morphology as mp\n",
    "import skimage.io as sio\n",
    "import scipy.misc as sm\n",
    "from skimage.filters import threshold_otsu, threshold_adaptive\n",
    "from skimage.feature import hessian_matrix, hessian_matrix_eigvals\n",
    "from skimage import exposure\n",
    "from skimage import data, img_as_float\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "from bisect import bisect_left\n",
    "import math\n",
    "import warnings\n",
    "import csv\n",
    "import tensorflow as tf\n",
    "# Pandas is used for data manipulation\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Constants\n",
    "X_START = 1000\n",
    "X_END = 6000\n",
    "Y_START = 800\n",
    "Y_END = 4300\n",
    "BG_2_OBJ_RATIO = 0.91\n",
    "CUBE_SIZE = 250\n",
    "EDGE_GAP = 50\n",
    "# ROOT_FOLDER = \"/home/il239838/files/\"\n",
    "ROOT_FOLDER = \"/Users/il239838/Downloads/private/Thesis/Papyrus/PX303/files/\"\n",
    "LEARNING_RATE = 0.001\n",
    "BATCHES = 800\n",
    "BATCH_SIZE = 50\n",
    "BREAK_VAL = 1000\n",
    "\n",
    "cube_size = 250\n",
    "HORIZ_TOLERANCE_FACTOR = 50\n",
    "VERT_TOLERANCE_FACTOR = 75\n",
    "EDGE_GAP = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "code_folding": [],
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# UTILS\n",
    "def renameFragmentsFiles(path):\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for file_ in files:\n",
    "            split = file_.split(\"_\")\n",
    "            if len(split) > 1 and split[0] != '.DS':\n",
    "                fileSplit = split[0].split(\"-\")\n",
    "\n",
    "                # next line for testing !!!\n",
    "                # newFileName = fileSplit[0] + fileSplit[1] + \"_\" + split[1] + \"_\" + split[2]\n",
    "\n",
    "                # next line for validation !!!\n",
    "                newFileName = fileSplit[0] + fileSplit[1] + \".jpg\"\n",
    "\n",
    "                os.rename(os.path.join(root, file_), \n",
    "                          os.path.join(root, newFileName))\n",
    "    \n",
    "\n",
    "def handle_match_row(df, idx, df_row):\n",
    "    rectanglesArr = eval(df_row[\"fragmentAndSideDrawRect\"])\n",
    "    if len(rectanglesArr) > 0:\n",
    "        firstImg = Image.open(ROOT_FOLDER+\"fragments/\"+df_row[\"firstFileName\"]+\".jpg\")\n",
    "        secondImg = Image.open(ROOT_FOLDER+\"fragments/\"+df_row[\"secondFileName\"]+\".jpg\")\n",
    "        # import pdb; pdb.set_trace()\n",
    "        firstRotate = (df_row[\"fragmentAndSide\"][df_row[\"fragmentAndSide\"].rfind(\"P\")-2] == \"0\")\n",
    "        secondRotate = (df_row[\"fragmentAndSide\"][-1] == \"1\")\n",
    "\n",
    "        # rotate the images if needed\n",
    "        if firstRotate:\n",
    "            firstImg = firstImg.rotate(180)\n",
    "        if secondRotate:\n",
    "            secondImg = secondImg.rotate(180)\n",
    "\n",
    "        cubesArr = eval(df_row[\"fragmentAndSideCubes\"])\n",
    "        pointsArr = eval(df_row[\"fragmentAndSideMatchPoint\"])\n",
    "\n",
    "        # correct the cubes, rects and points incase we had a rotation\n",
    "        for cube, rect, point in zip(cubesArr, rectanglesArr, pointsArr):\n",
    "            if firstRotate:\n",
    "                cube[0] = firstImg.size[0] - cube[0] - cube_size # reduce cube_size cause we measure from top left corner of the cube\n",
    "                cube[1] = firstImg.size[1] - cube[1] - cube_size # reduce cube_size - see above\n",
    "                rect[0] = cube[0] + cube_size + EDGE_GAP - HORIZ_TOLERANCE_FACTOR\n",
    "                rect[2] = cube[0] + cube_size + EDGE_GAP + HORIZ_TOLERANCE_FACTOR\n",
    "                point[0] = cube[0] + cube_size + EDGE_GAP\n",
    "            if secondRotate:\n",
    "                cube[2] = secondImg.size[0] - cube[2] - cube_size # reduce cube_size - see above\n",
    "                cube[3] = secondImg.size[1] - cube[3] - cube_size # reduce cube_size - see above\n",
    "            if firstRotate or secondRotate:\n",
    "                rect[1] = cube[1] - cube[3] - VERT_TOLERANCE_FACTOR\n",
    "                rect[3] = cube[1] - cube[3] + VERT_TOLERANCE_FACTOR\n",
    "                point[1] = cube[1] - cube[3]\n",
    "        \n",
    "        # if we rotated - need to write the updated values to the enhanced output file\n",
    "        if firstRotate or secondRotate:\n",
    "            df.at[idx, \"fragmentAndSideCubes\"] = cubesArr\n",
    "            df.at[idx, \"fragmentAndSideDrawRect\"] = rectanglesArr\n",
    "            df.at[idx, \"fragmentAndSideDrawRect\"] = rectanglesArr\n",
    "        \n",
    "        mins = np.amin(rectanglesArr, 0)\n",
    "        maxs = np.amax(rectanglesArr, 0)\n",
    "        minsmaxs = [mins[0], mins[1], maxs[2], maxs[3]]\n",
    "        minsmins = [mins[0], mins[1], mins[0], mins[1]]\n",
    "        width = maxs[2] - mins[0]\n",
    "        height = maxs[3] - mins[1]\n",
    "        slate = np.zeros((width, height))\n",
    "\n",
    "        for rect in rectanglesArr:\n",
    "            rect_slide = np.zeros((width, height))\n",
    "            rect_adjusted =  np.subtract(rect, minsmins)\n",
    "            rect_slide[rect_adjusted[0]:rect_adjusted[2], rect_adjusted[1]:rect_adjusted[3]] = 1\n",
    "            slate = slate + rect_slide\n",
    "\n",
    "        slate_max = np.amax(slate)\n",
    "        df.at[idx, \"votesOverlapMax\"] = slate_max\n",
    "        df.at[idx, \"divideOverlapMaxBySideTotal\"] = float(slate_max) / df_row[\"fragmentAndSideTotal\"]\n",
    "        max_indices = np.where(slate == slate_max)\n",
    "        df.at[idx, \"votesOverlapHeight\"] = (max_indices[1][-1]+1) - max_indices[1][0]\n",
    "\n",
    "        slate_mask = np.copy(slate)\n",
    "        slate_mask[slate_mask < slate_max] = 0\n",
    "        slate_mask[slate_mask == slate_max] = 1\n",
    "        slate_mask_size = float(len(np.where(slate_mask == 1)[0]))\n",
    "\n",
    "        overlaps_percent_arr = []\n",
    "        for rect in rectanglesArr:\n",
    "            rect_slide = np.zeros((width, height))\n",
    "            rect_adjusted =  np.subtract(rect, minsmins)\n",
    "            rect_slide[rect_adjusted[0]:rect_adjusted[2], rect_adjusted[1]:rect_adjusted[3]] = 1\n",
    "            overlap_indices = np.where((rect_slide == slate_mask) & (rect_slide == 1))\n",
    "            overlaps_percent_arr.append(float(len(overlap_indices[0]))/slate_mask_size)\n",
    "\n",
    "        # FIXME: need to fix next line as the square might be a jigsaw - need to pick the overall min and max indices\n",
    "        voted_square = [max_indices[0][0], max_indices[1][0], max_indices[0][-1]+1, max_indices[1][-1]+1]\n",
    "        adjusted_vote = np.add(minsmins,voted_square)\n",
    "        mid_point = [(adjusted_vote[0] + adjusted_vote[2])/2, (adjusted_vote[1] + adjusted_vote[3])/2]\n",
    "        \n",
    "        con_width = firstImg.size[0] + secondImg.size[0]\n",
    "        con_height = 0\n",
    "        first_offset = (-adjusted_vote[1]) if adjusted_vote[1] < 0 else 0\n",
    "        second_offset = int(mid_point[1] + first_offset)\n",
    "        adjusted_vote[1] += first_offset\n",
    "        adjusted_vote[3] += first_offset\n",
    "        con_height = int(np.maximum(firstImg.size[1] + first_offset, secondImg.size[1] + second_offset))\n",
    "\n",
    "        conImage = Image.new('RGBA', (con_width, con_height))\n",
    "        conImage.paste(firstImg, (0, first_offset))\n",
    "        conImage.paste(secondImg, (firstImg.size[0]+1, second_offset))\n",
    "\n",
    "        draw = ImageDraw.Draw(conImage)\n",
    "        draw.rectangle(adjusted_vote.tolist(), fill=\"green\", outline=\"green\")\n",
    "\n",
    "        cubeMid = CUBE_SIZE / 2\n",
    "        for overlap_percent, cube_pair in zip(overlaps_percent_arr, cubesArr):\n",
    "            # import pdb; pdb.set_trace()\n",
    "            color=\"\"\n",
    "            lwidth=1\n",
    "            if (overlap_percent < 0.1):\n",
    "                color=\"red\"\n",
    "            elif (overlap_percent < 0.5):\n",
    "                color=\"yellow\"\n",
    "                lwidth=3\n",
    "            else:\n",
    "                color=\"green\"\n",
    "                lwidth=5\n",
    "                df.at[idx, \"votesSupportOverlapRect\"] += 1 # if the matched pair overlaps the rectangle more than 50% - we consider this to be supporting\n",
    "            draw.line((cube_pair[0] + cubeMid, cube_pair[1] + cubeMid + first_offset,\n",
    "                      firstImg.size[0] + 1 + cube_pair[2] + cubeMid, cube_pair[3] + cubeMid + second_offset), \n",
    "                      fill=color, width=lwidth)\n",
    "\n",
    "        df.at[idx, \"divideSupportOverlapBySideTotal\"] = \\\n",
    "            float(df.at[idx, \"votesSupportOverlapRect\"]) / df_row[\"fragmentAndSideTotal\"]\n",
    "        df.at[idx, \"divideSupportOverlapBySideVote\"] = \\\n",
    "            float(float(df.at[idx, \"votesSupportOverlapRect\"])) / df_row[\"fragmentAndSideVote\"]\n",
    "\n",
    "        conImage.save(ROOT_FOLDER+\"squares/\"+str(df_row[\"class\"])+\"=\"+df_row[\"fragmentAndSide\"]+\".jpg\")\n",
    "    \n",
    "    \n",
    "def draw_histogram_for_row(df_row, bins):\n",
    "    matchPointArr = eval(df_row[\"fragmentAndSideMatchPoint\"])\n",
    "    vals = [row[1] for row in matchPointArr]\n",
    "    plt.hist(vals, bins, facecolor='green')\n",
    "    plt.title(df_row[\"fragment\"])\n",
    "    plt.show()\n",
    "    # import pdb; pdb.set_trace()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "code_folding": [],
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# RUN ONCE ONLY!!!\n",
    "# renameFragmentsFiles(ROOT_FOLDER+\"fragments/\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'fragmentAndSide'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/pandas/indexes/base.py\u001b[0m in \u001b[0;36mget_value\u001b[0;34m(self, series, key)\u001b[0m\n\u001b[1;32m   2174\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2175\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mtslib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value_box\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2176\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/tslib.pyx\u001b[0m in \u001b[0;36mpandas.tslib.get_value_box (pandas/tslib.c:19053)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/tslib.pyx\u001b[0m in \u001b[0;36mpandas.tslib.get_value_box (pandas/tslib.c:18687)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'str' object cannot be interpreted as an integer",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-817492f22775>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m#if row[\"fragment\"] == \"PX303Fg006_7X5_5X2_PX303Fg006_7X5_6X2\":\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# print(idx)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mhandle_match_row\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_matches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mall_matches\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'20181020_212330_pairs_votes_enhanced.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-5ad2453d4a38>\u001b[0m in \u001b[0;36mhandle_match_row\u001b[0;34m(df, idx, df_row)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0msecondImg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mROOT_FOLDER\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"fragments/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mdf_row\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"secondFileName\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\".jpg\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;31m# import pdb; pdb.set_trace()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_row\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"fragmentAndSide\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mfirstRotate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdf_row\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"fragmentAndSide\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_row\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"fragmentAndSide\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"P\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0msecondRotate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdf_row\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"fragmentAndSide\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    601\u001b[0m         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 603\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    604\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/pandas/indexes/base.py\u001b[0m in \u001b[0;36mget_value\u001b[0;34m(self, series, key)\u001b[0m\n\u001b[1;32m   2181\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2182\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2183\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0me1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2184\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pragma: no cover\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2185\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0me1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/pandas/indexes/base.py\u001b[0m in \u001b[0;36mget_value\u001b[0;34m(self, series, key)\u001b[0m\n\u001b[1;32m   2167\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2168\u001b[0m             return self._engine.get_value(s, k,\n\u001b[0;32m-> 2169\u001b[0;31m                                           tz=getattr(series.dtype, 'tz', None))\n\u001b[0m\u001b[1;32m   2170\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2171\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minferred_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'integer'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'boolean'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_value (pandas/index.c:3557)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_value (pandas/index.c:3240)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas/index.c:4279)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/src/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas/hashtable.c:13742)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/src/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas/hashtable.c:13696)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'fragmentAndSide'"
     ]
    }
   ],
   "source": [
    "# EITHER RUN THIS: CREATE CUBES WITH VOTES\n",
    "all_matches = pd.read_csv('20181020_212330_pairs_votes.csv')\n",
    "# all_matches = all_matches[all_matches[\"class\"] == 1] # run only the classified or all?\n",
    "all_matches[\"votesOverlapMax\"] = 0\n",
    "all_matches[\"divideOverlapMaxBySideTotal\"] = 0.0\n",
    "all_matches[\"votesOverlapHeight\"] = 0\n",
    "all_matches[\"votesSupportOverlapRect\"] = 0\n",
    "all_matches[\"divideSupportOverlapBySideTotal\"] = 0.0\n",
    "all_matches[\"divideSupportOverlapBySideVote\"] = 0.0\n",
    "for idx, row in all_matches.iterrows():\n",
    "    #if row[\"fragment\"] == \"PX303Fg006_7X5_5X2_PX303Fg006_7X5_6X2\":\n",
    "    # print(idx)\n",
    "    handle_match_row(all_matches, idx, row)\n",
    "\n",
    "all_matches.to_csv('20181020_212330_pairs_votes_enhanced.csv')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# OR RUN THIS: CREATE HISTOGRAM\n",
    "\n",
    "all_matches = pd.read_csv('votes_cubes_match_synt.csv') #('real_cubes_all_vote.csv')\n",
    "all_matches = all_matches[all_matches[\"class\"] == 1]\n",
    "for idx, row in all_matches.iterrows():\n",
    "    draw_histogram_for_row(row, 15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
