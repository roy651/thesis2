{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# RUN Main import block and TODO list\n",
    "\n",
    "# TODO: see how uri calculated the ridges\n",
    "\n",
    "# TODO: Perform Histogram equalization - start with it\n",
    "# TODO: \n",
    "# take integral from the Highest peak+-0.005 divide by integral of the entire graph \n",
    "# This will be the peakness measure for the PSD ==> The desired ridge index\n",
    "# TODO:\n",
    "# take integral from the Highest peak+-0.005 divide by integral of the entire graph - it's the peakness measure for the PSD\n",
    "# must select a peak above a min threshold in order to ignore noisy frequency\n",
    "# must ignore peaks above a certain threshold in order to detect meaningful frequency\n",
    "# run the PSD in moving windows every 200 px (deduced from the below PSD pointing to a freq of 1/0.02=50-> times 4= 200px)\n",
    "# and medianf the result of the windows\n",
    "# TODO:\n",
    "# Another alternative: (with Yariv)\n",
    "# Run PSD column by column - get the phase, freq, peakness and reconstruct an artificial ridge slice\n",
    "# from this - reconstruct a \"clean\" artificial ridge image\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.image as img\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import urllib.request\n",
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "from scipy import ndimage\n",
    "from scipy import signal\n",
    "#import cv2\n",
    "\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "import mahotas as mh\n",
    "from mahotas import polygon\n",
    "# import pymorph as pm\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "from scipy import ndimage as nd\n",
    "import skimage.transform as transform\n",
    "import skimage.morphology as mp\n",
    "import skimage.io as sio\n",
    "import scipy.misc as sm\n",
    "from skimage.filters import threshold_otsu, threshold_adaptive\n",
    "from skimage.feature import hessian_matrix, hessian_matrix_eigvals\n",
    "from skimage import exposure\n",
    "from skimage import data, img_as_float\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "from bisect import bisect_left\n",
    "import math\n",
    "import warnings\n",
    "import csv\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [
     0,
     55,
     69,
     75,
     81,
     95,
     104,
     119,
     137,
     154,
     172,
     329,
     366,
     551,
     557,
     574,
     589
    ],
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# RUN Utility functions\n",
    "\n",
    "# One time init\n",
    "# with open('results.csv', 'w') as csvfile:\n",
    "#     csvout = csv.writer(csvfile)\n",
    "#     csvout.writerow([\"File\", \"Model\", \"Gap\", \"Slice_size\", \"Count\", \"Precision\", \"Recall\", \"F-score\", \"True Count\", \"Error Rate\"])\n",
    "\n",
    "#BASIC CROP FRAME\n",
    "X_START = 1000\n",
    "X_END = 6000\n",
    "Y_START = 800\n",
    "Y_END = 4300\n",
    "BG_2_OBJ_RATIO = 0.91\n",
    "CUBE_SIZE = 250\n",
    "EDGE_GAP = 50\n",
    "ROOT_FOLDER = \"/Users/il239838/Downloads/private/Thesis/Papyrus/\"\n",
    "LEARNING_RATE = 0.001\n",
    "BATCHES = 400\n",
    "BATCH_SIZE = 50\n",
    "BREAK_VAL = 1000\n",
    "\n",
    "# Simple crop by x/y ranges\n",
    "def crop(image, ymin, ymax, xmin, xmax):\n",
    "    return image[ymin:ymax, xmin:xmax]\n",
    "\n",
    "# returns a logical matrix of values beyond a threshld\n",
    "def thresholded(image, val): \n",
    "    return np.logical_and(*[image[...] > val  for t in enumerate([0, 0])])\n",
    "\n",
    "def find_min_max_without_orphand_pixels(nonzero_dimension, crop_filter=20):\n",
    "    sorted = np.sort(nonzero_dimension)\n",
    "    prev=-1\n",
    "    min_val = sorted[0]\n",
    "    for i, x in enumerate(sorted[:100]):\n",
    "        if prev >= 0 and x - prev > crop_filter:\n",
    "            min_val = x\n",
    "        prev = x\n",
    "    prev=-1\n",
    "    max_val = sorted[-1]\n",
    "    for i, x in enumerate(sorted[-100:]):\n",
    "        if prev >= 0 and x - prev > crop_filter:\n",
    "            max_val = prev\n",
    "            break\n",
    "        prev = x\n",
    "    \n",
    "    return min_val, max_val\n",
    "\n",
    "def calc_min_max_coordinates(image, crop_val=50):\n",
    "    temp = thresholded(image, crop_val)\n",
    "    temp = temp * 1\n",
    "    temp = np.nonzero(temp)\n",
    "    ymin, ymax = find_min_max_without_orphand_pixels(temp[0])\n",
    "    xmin,xmax = find_min_max_without_orphand_pixels(temp[1])\n",
    "    return ymin, ymax, xmin, xmax\n",
    "\n",
    "def calc_min_max_coordinates_dynamic(image, cutoff=1):\n",
    "    temp = exposure.equalize_adapthist(image, clip_limit=0.03)\n",
    "    flat = np.sort(np.matrix.getA1(temp))\n",
    "    sum_all = np.sum(flat)\n",
    "    index = np.argmin(flat.cumsum() < (sum_all * cutoff))\n",
    "\n",
    "    temp = thresholded(temp, flat[index])\n",
    "    temp = temp * 1\n",
    "    temp = np.nonzero(temp)\n",
    "    ymin, ymax = find_min_max_without_orphand_pixels(temp[0])\n",
    "    xmin,xmax = find_min_max_without_orphand_pixels(temp[1])\n",
    "    return ymin, ymax, xmin, xmax\n",
    "\n",
    "# initial static crop and a seondary dynamic crop based on signal2noise ratio\n",
    "def crop_full_scan(image, x_start, x_end, y_start, y_end):\n",
    "    temp = crop(image, y_start, y_end, x_start, x_end)\n",
    "    ymin, ymax, xmin, xmax = calc_min_max_coordinates_dynamic(temp, cutoff=BG_2_OBJ_RATIO)\n",
    "    temp = crop(image, y_start+ymin, y_start+ymax, x_start+xmin, x_start+xmax)\n",
    "    return temp\n",
    "\n",
    "def crop_thresholded(image):\n",
    "    temp = crop(image, 0, image.shape[0]-1, 0, image.shape[1]-1)\n",
    "    ymin, ymax, xmin, xmax = calc_min_max_coordinates(temp)\n",
    "    temp = crop(image, ymin, ymax, xmin, xmax)\n",
    "    return temp\n",
    "\n",
    "def read_and_crop(image_name, x_start=X_START, x_end=X_END, y_start=Y_START, y_end=Y_END):\n",
    "    if \"il239838\" in os.getcwd():\n",
    "        image = img.imread(ROOT_FOLDER + image_name)\n",
    "    else:\n",
    "        f = urllib.request.urlopen(\"https://dl.dropboxusercontent.com/s/31b96942qdcn73k/\" + image_name)\n",
    "        image = img.imread(f, format='jpeg')\n",
    "\n",
    "    # Smart-crop the image to get rid of all the noise and redundant area\n",
    "    # return crop_full_scan(image)\n",
    "    cropped = crop_full_scan(image, x_start, x_end, y_start, y_end)\n",
    "    return exposure.equalize_adapthist(cropped, clip_limit=0.03)\n",
    "\n",
    "\n",
    "# TODO: fix performance!!! http://scikit-image.org/docs/dev/user_guide/tutorial_parallelization.html\n",
    "def combine_3_images_to_RGB(red, green, blue):\n",
    "    new_image = np.empty((blue.shape[0],blue.shape[1],3))\n",
    "    for x in range(0, blue.shape[0]):\n",
    "        for y in range(0, blue.shape[1]):\n",
    "            new_image[x,y,0] = red[x,y]\n",
    "            new_image[x,y,1] = green[x,y]\n",
    "            new_image[x,y,2] = blue[x,y]\n",
    "    return new_image\n",
    "\n",
    "def slice_image_left_edge(original, width=200, rotate=0):\n",
    "    rot = ndimage.rotate(original, rotate)\n",
    "    # Slice the left slice of the so-called \"blue\" image\n",
    "    left_edge_orig = crop(rot, 1, 1400, 1, width)\n",
    "    left_edge_orig = crop_thresholded(left_edge_orig)\n",
    "\n",
    "    # Copy to a new array so we don't thrash the origin\n",
    "    left_edge = np.empty_like (left_edge_orig)\n",
    "    np.copyto(left_edge, left_edge_orig)\n",
    "\n",
    "    # Zero down low level \"noise\" values\n",
    "    low_values_indices = left_edge < 30  # Where values are low\n",
    "    left_edge[low_values_indices] = 0  # All low values set to 0\n",
    "    return left_edge\n",
    "\n",
    "def get_best_angle_rotation(original, crop=True, width=200):\n",
    "    min_var = 99999999999\n",
    "    best_angle = -10\n",
    "    for x in range(-5,5):\n",
    "        if crop:            \n",
    "            rot_edge = slice_image_left_edge(original, width, x)\n",
    "        else:\n",
    "            rot_edge = ndimage.rotate(original, x)\n",
    "        left_var = np.var(rot_edge, axis=1)\n",
    "        # left_var = np.apply_along_axis(lambda v: np.var(v[np.nonzero(v)]), 1, rot_edge)\n",
    "        var_sum = np.sum(left_var)\n",
    "        if (var_sum < min_var):\n",
    "            min_var = var_sum\n",
    "            best_angle = x\n",
    "    print (\"best_angle=\"+str(best_angle))\n",
    "    return best_angle\n",
    "\n",
    "#     import pdb; pdb.set_trace()\n",
    "def calc_neighbors(slice_map, col, row):\n",
    "    # import pdb; pdb.set_trace()\n",
    "    if ((col-1, row) in slice_map and slice_map[(col-1, row)] != None):\n",
    "        slice_map[(col, row)][\"left\"] = slice_map[(col-1, row)]\n",
    "        slice_map[(col-1, row)][\"right\"] = slice_map[(col, row)]\n",
    "    if ((col+1, row) in slice_map and slice_map[(col+1, row)] != None):\n",
    "        slice_map[(col, row)][\"right\"] = slice_map[(col+1, row)]\n",
    "        slice_map[(col+1, row)][\"left\"] = slice_map[(col, row)]\n",
    "    if ((col, row-1) in slice_map and slice_map[(col, row-1)] != None):\n",
    "        slice_map[(col, row)][\"top\"] = slice_map[(col, row-1)]\n",
    "        slice_map[(col, row-1)][\"bottom\"] = slice_map[(col, row)]\n",
    "    if ((col, row+1) in slice_map and slice_map[(col, row+1)] != None):\n",
    "        slice_map[(col, row)][\"bottom\"] = slice_map[(col, row+1)]\n",
    "        slice_map[(col, row+1)][\"top\"] = slice_map[(col, row)]\n",
    "    \n",
    "\n",
    "\n",
    "def VAL_create_cube(name, raw, x, y):\n",
    "    cube = {}\n",
    "    cube[\"cube\"] = raw\n",
    "    cube[\"file\"] = name\n",
    "    if name.find('P') == 0:\n",
    "        cube[\"index\"] = int(name[name.find('P')+1:name.find('P')+4]) * 1000 + int(name[name.find('Fg')+2:name.find('Fg')+5])\n",
    "    else:\n",
    "        # print(\"Found a ZERO index cube with the name:\"+name)\n",
    "        cube[\"index\"] = 0\n",
    "    cube[\"top_row\"] = x\n",
    "    cube[\"left_col\"] = y\n",
    "    cube[\"right_col\"] = y + CUBE_SIZE\n",
    "    return cube\n",
    "    \n",
    "\n",
    "ZERO_CUBE = VAL_create_cube(\"ZERO\", np.zeros((CUBE_SIZE, CUBE_SIZE), dtype=np.int), -1, -2)\n",
    "\n",
    "# slice an image to cubes with 250X250 pixel size\n",
    "def VAL_slice_TEAR_to_static_slices(name, cropped_original):\n",
    "    structure = {}\n",
    "    # cropped_original = cropped_original / 256 # divide by 256 to \"normalize\" between 0 and 1\n",
    "\n",
    "    # import pdb; pdb.set_trace()\n",
    "    x, y = cropped_original[\"cut\"].shape\n",
    "    print (x,y)\n",
    "    n = 0\n",
    "    # every 250 pixels on the x axis == rows\n",
    "    while ((n + 1) * CUBE_SIZE < x):\n",
    "        # cut a cube of 250X250 at the first column\n",
    "        # import pdb; pdb.set_trace()\n",
    "        cube = (crop(cropped_original[\"cut\"], n * CUBE_SIZE, (n + 1) * CUBE_SIZE, EDGE_GAP, CUBE_SIZE + EDGE_GAP))\n",
    "        # keep only cubes for which half of the pixels have some \"color\"\n",
    "        if np.median(cube) > 0.2: # aligned with the normalization 0.2 correlates to 50\n",
    "            # keep the cube\n",
    "            new_cube = VAL_create_cube(name, cube, n * CUBE_SIZE, EDGE_GAP)\n",
    "            new_cube[\"col\"] = 0\n",
    "            new_cube[\"row\"] = n\n",
    "            new_cube[\"last\"] = False\n",
    "            new_cube[\"orig\"] = cropped_original\n",
    "            new_cube[\"col_px_left\"] = cropped_original[\"col_px\"] + EDGE_GAP\n",
    "            new_cube[\"col_px_right\"] = cropped_original[\"col_px\"] + CUBE_SIZE + EDGE_GAP\n",
    "            new_cube[\"row_px_top\"] = cropped_original[\"row_px\"] + n * CUBE_SIZE\n",
    "            new_cube[\"row_px_bottom\"] = cropped_original[\"row_px\"] + (n + 1) * CUBE_SIZE\n",
    "            structure[(0, n)] = new_cube\n",
    "\n",
    "        # cut a cube of 250X250 at the last column\n",
    "        cube = (crop(cropped_original[\"cut\"], n * CUBE_SIZE, (n + 1) * CUBE_SIZE, y - CUBE_SIZE - EDGE_GAP, y - EDGE_GAP))\n",
    "        # keep only cubes for which half of the pixels have some \"color\"\n",
    "        # aligned with the normalization 0.2 correlates to 50\n",
    "        if np.median(cube) > 0.2:\n",
    "            # keep the cube\n",
    "            new_cube = VAL_create_cube(name, cube, n * CUBE_SIZE, y - CUBE_SIZE - EDGE_GAP)\n",
    "            new_cube[\"col\"] = 1\n",
    "            new_cube[\"row\"] = n\n",
    "            new_cube[\"last\"] = True\n",
    "            new_cube[\"orig\"] = cropped_original\n",
    "            new_cube[\"col_px_left\"] = cropped_original[\"col_px\"] + y - CUBE_SIZE - EDGE_GAP\n",
    "            new_cube[\"col_px_right\"] = cropped_original[\"col_px\"] + y - EDGE_GAP\n",
    "            new_cube[\"row_px_top\"] = cropped_original[\"row_px\"] + n * CUBE_SIZE\n",
    "            new_cube[\"row_px_bottom\"] = cropped_original[\"row_px\"] + (n + 1) * CUBE_SIZE\n",
    "            structure[(1, n)] = new_cube\n",
    "\n",
    "    #         m = 0\n",
    "    #         # every 250 pixels on the y axis == cols\n",
    "    #         while ((m + 1) * CUBE_SIZE < y):            \n",
    "    #             if ((m == 0) or ((m + 2) * CUBE_SIZE >= y)): # Only keep the left and right edges of the piece for matching!!\n",
    "    #                 # cut a cube of 250X250\n",
    "    #                 cube = crop(cropped_original[\"cut\"], n * CUBE_SIZE, (n + 1) * CUBE_SIZE, m * CUBE_SIZE, (m + 1) * CUBE_SIZE)\n",
    "    #                 # keep only cubes for which half of the pixels have some \"color\"\n",
    "    #                 # print(np.median(cube))\n",
    "    #                 if np.median(cube) > 0.2: # aligned with the normalization 0.2 correlates to 50\n",
    "    #                     # keep the cube\n",
    "    #                     new_cube = VAL_create_cube(name, cube, n * CUBE_SIZE, m * CUBE_SIZE)\n",
    "    #                     new_cube[\"col\"] = m\n",
    "    #                     new_cube[\"row\"] = n\n",
    "    #                     new_cube[\"orig\"] = cropped_original\n",
    "    #                     new_cube[\"col_px_left\"] = cropped_original[\"col_px\"] + m * CUBE_SIZE\n",
    "    #                     new_cube[\"col_px_right\"] = cropped_original[\"col_px\"] + (m + 1) * CUBE_SIZE\n",
    "    #                     new_cube[\"row_px_top\"] = cropped_original[\"row_px\"] + n * CUBE_SIZE\n",
    "    #                     new_cube[\"row_px_bottom\"] = cropped_original[\"row_px\"] + (n + 1) * CUBE_SIZE\n",
    "    #                     if ((m + 2) * CUBE_SIZE >= y):\n",
    "    #                         new_cube[\"last\"] = True\n",
    "    #                     else:\n",
    "    #                         new_cube[\"last\"] = False\n",
    "    #                     structure[(m, n)] = new_cube\n",
    "    #             m += 1\n",
    "        n += 1\n",
    "            \n",
    "    # this loop has to be performed only after we've established all the None cubes\n",
    "    for cube in structure.values():\n",
    "        # set the reference to neighbor cubes\n",
    "        if cube != None:\n",
    "            calc_neighbors(structure, cube[\"col\"], cube[\"row\"])\n",
    "\n",
    "    # return the data structure with all the cubes and the counters of the rows and columns\n",
    "    return structure.values()\n",
    "\n",
    "def pad_above(original, above, amount):\n",
    "    res = np.insert(original[\"cube\"], np.zeros(amount), above[\"cube\"][-amount:], axis=0)\n",
    "    res = np.delete(res, np.arange(CUBE_SIZE,CUBE_SIZE+amount), axis=0)\n",
    "    return VAL_create_cube(original[\"file\"], res, original[\"top_row\"] - amount, original[\"left_col\"])\n",
    "  \n",
    "\n",
    "def pad_below(original, below, amount):\n",
    "    res = np.insert(original[\"cube\"], np.full(amount, CUBE_SIZE), below[\"cube\"][:amount], axis=0)\n",
    "    res = np.delete(res, np.arange(0, amount), axis=0)\n",
    "    return VAL_create_cube(original[\"file\"], res, original[\"top_row\"] + amount, original[\"left_col\"])\n",
    "\n",
    "def pad_left(original, left, amount):\n",
    "    res = np.insert(original[\"cube\"], np.zeros(amount, dtype=int), left[\"cube\"][:,-amount:], axis=1)\n",
    "    res = np.delete(res, np.arange(CUBE_SIZE, CUBE_SIZE+amount), axis=1)\n",
    "    return VAL_create_cube(original[\"file\"], res, original[\"top_row\"], original[\"left_col\"] - amount)\n",
    "\n",
    "def pad_right(original, right, amount):\n",
    "    res = np.insert(original[\"cube\"], [CUBE_SIZE], right[\"cube\"][:,:amount], axis=1)\n",
    "    res = np.delete(res, np.arange(0, amount), axis=1)\n",
    "    return VAL_create_cube(original[\"file\"], res, original[\"top_row\"], original[\"left_col\"] + amount)\n",
    "    \n",
    "\n",
    "# \"Shave\" the right edge of the cube with <gap> pixels and pad with zeros on the left\n",
    "def shave_right(original, amount):\n",
    "    return pad_left(original, ZERO_CUBE, amount)\n",
    "    \n",
    "\n",
    "# \"Shave\" the left edge of the cube with <gap> pixels and pad with zeros on the right    \n",
    "def shave_left(original, amount):\n",
    "    return pad_right(original, ZERO_CUBE, amount)\n",
    "    \n",
    "\n",
    "    # concatenate cubes \n",
    "def concatenate_cubes(left, right, slice_size):\n",
    "    con = np.concatenate((left[\"cube\"][:,-slice_size:], right[\"cube\"][:,:slice_size]), axis=1)\n",
    "    x_delta = right[\"top_row\"] - left[\"top_row\"]\n",
    "    y_delta = right[\"left_col\"] - left[\"right_col\"] \n",
    "    return con, x_delta, y_delta\n",
    "\n",
    "# concatenate cubes \n",
    "def VAL_concatenate_cubes(left, right, slice_size):\n",
    "    right_img = right[\"cube\"]\n",
    "    # next block is not relevant for training not that we moved to euclidean distance... or at all ...\n",
    "    #     # if the left cube is matched to another left cube (or right cube to another right cube) then rotate the right\n",
    "    #     # cube by 180 so we try to match it upside down, covering the option that the cube was pictured rotated\n",
    "    #     if ((left[\"col\"] == 0 and right[\"col\"] == 0) or (left[\"col\"] != 0 and right[\"col\"] != 0)):\n",
    "    #         right_img = np.rot90(right[\"cube\"], 2);\n",
    "\n",
    "    con = np.concatenate((left[\"cube\"][:,-slice_size:], right_img[:,:slice_size]), axis=1)\n",
    "\n",
    "    # next block calculates distance based on the distance between left's right-top corner and right's left-top corner    \n",
    "    #     x_delta = right[\"top_row\"] - left[\"top_row\"]\n",
    "    #     y_delta = right[\"left_col\"] - left[\"right_col\"] \n",
    "\n",
    "    # next block calculates the distance between the centers of cubes, accounting for test set's possibility of reverse slices (left instead of right and vice versa)\n",
    "    x_delta = right[\"top_row\"] - left[\"top_row\"] # equivalent to distance between vertical centers\n",
    "    y_delta = (right[\"left_col\"] + (slice_size / 2)) - (left[\"right_col\"] - (slice_size / 2)) # measuring the distance between horizontal centers of the slices\n",
    "\n",
    "    return con, x_delta, y_delta, left[\"file\"], right[\"file\"]\n",
    "    \n",
    "\n",
    "# concatenate cubes while artificially creating a gap between them. Pad the other end of the cube with zeros\n",
    "def concatenate_cubes_zero_pad_gaps(left_orig, right_orig, gap):\n",
    "    left = left_orig if gap == 0 else shave_right(left_orig, gap)\n",
    "    right = right_orig if gap == 0 else shave_left(right_orig, gap)\n",
    "    return concatenate_cubes(left, right)    \n",
    "\n",
    "# concatenate cubes while artificially creating a gap between them. Pad the other end of the cobe with the nearby\n",
    "# continuation of the cubes\n",
    "def concatenate_cubes_with_gap(left_orig, right_orig, gap, left_pad, right_pad, slice_size):\n",
    "    # import pdb; pdb.set_trace()\n",
    "    left = left_orig if gap == 0 else pad_left(left_orig, left_pad, gap)\n",
    "    right = right_orig if gap == 0 else pad_right(right_orig, right_pad, gap)\n",
    "    return concatenate_cubes(left, right, slice_size)        \n",
    "\n",
    "# convert the data structure of cubes into a train set of 2 arrays of images and labels\n",
    "# each image is a concatanation of 2 images from the original cubes set, covering all combinations of images\n",
    "# effectively creating Nx(N-1) images\n",
    "def VAL_build_train_set_for_euclidean_distance(cubes, slice_size, folder):\n",
    "    # clean folder before starting\n",
    "    for root, dirs, files in os.walk(folder):\n",
    "        for f in files:\n",
    "            os.unlink(os.path.join(root, f))\n",
    "\n",
    "    #import pdb; pdb.set_trace()\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "    train_imgs = []\n",
    "    train_x_delta = []\n",
    "    train_y_delta = []\n",
    "    train_left_obj = []\n",
    "    train_right_obj = []\n",
    "    # iterate over all cubes   \n",
    "    for curr in cubes:\n",
    "        # iterate over the others (effectively n^2)\n",
    "        for adj in cubes:\n",
    "            if (adj[\"file\"] != curr[\"file\"]): # no need to test against self CURRENTLY checking from directions!!!\n",
    "                #import pdb; pdb.set_trace()\n",
    "                # append the adjacent image to the current image\n",
    "                conc, x_delta, y_delta, x_file, y_file = VAL_concatenate_cubes(curr, adj, slice_size)\n",
    "                output = folder+x_file+\"_\"+str(curr[\"top_row\"])+\"_\"+str(curr[\"left_col\"])+\"---\"+y_file+\"_\"+str(adj[\"top_row\"])+\"_\"+str(adj[\"left_col\"])\n",
    "                np.save(output, conc)\n",
    "                train_imgs.append(output)\n",
    "                train_x_delta.append(x_delta)\n",
    "                train_y_delta.append(y_delta)\n",
    "                train_left_obj.append(curr)\n",
    "                train_right_obj.append(adj)\n",
    "\n",
    "    warnings.filterwarnings(\"default\")\n",
    "    return train_imgs, train_x_delta, train_y_delta, train_left_obj, train_right_obj\n",
    "\n",
    "\n",
    "# convert the data structure of cubes into a train set of 2 arrays of images and labels\n",
    "# each image is a concatanation of 2 images from the original cubes set, covering all combinations of images\n",
    "# effectively creating Nx(N-1) images\n",
    "def ORIG_build_train_set(cubes, gap):\n",
    "    # import pdb; pdb.set_trace()\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "    train_imgs = []\n",
    "    train_lbls = []\n",
    "    train_x_delta = []\n",
    "    train_y_delta = []\n",
    "    # iterate over the rows and cols, essentially going over the grid of sliced cubes\n",
    "    for row in range(0, rows):\n",
    "        for col in range(0, cols):\n",
    "            # if this cube exists (could have been removed previously due to lack of data)\n",
    "            if (cubes[(col, row)] != None):\n",
    "                # for each \"current\" image in the iteration\n",
    "                curr = cubes[(col, row)]\n",
    "                # iterate over all the cubes to find all the \"other\" (adjacent) cubes\n",
    "                for adj_row in range(0, rows):\n",
    "                    for adj_col in range(0, cols):\n",
    "                        if (adj_row != row or adj_col != col):\n",
    "                            if (cubes[(adj_col, adj_row)] != None):\n",
    "                                adj = cubes[(adj_col, adj_row)]\n",
    "                                # append the adjacent image to the current image\n",
    "                                # pass the filling cubes on the right and left to pad against the gap\n",
    "                                if (gap == 0 or (\"left\" in curr.keys() and \"right\" in adj.keys())):\n",
    "                                    if (gap == 0):\n",
    "                                        conc, x_delta, y_delta = concatenate_cubes(curr, adj, slice_size)\n",
    "                                    else:\n",
    "                                        conc, x_delta, y_delta = concatenate_cubes_with_gap(curr, adj, gap, curr[\"left\"], adj[\"right\"], slice_size)\n",
    "                                    train_imgs.append(conc)\n",
    "                                    train_x_delta.append(x_delta)\n",
    "                                    train_y_delta.append(y_delta)\n",
    "                                    # if the adj image is on the same row and on the right of the curr image - it will be marked as match    \n",
    "                                    if (adj_row == row and adj_col == (col + 1)):\n",
    "                                        # mark the image as matched\n",
    "                                        train_lbls.append([0,1])\n",
    "                                        # need to enrich the set with a few more tru positive samples - so we offset \n",
    "                                        # the matched images up ad down a few times and create more matches\n",
    "                                        if (\"top\" in curr.keys() and \"top\"in adj.keys()):\n",
    "                                            for i in range(5, 101, 5):\n",
    "                                                curr1 = pad_above(curr, curr[\"top\"],i)\n",
    "                                                adj1 = pad_above(adj, adj[\"top\"],i)\n",
    "                                                if (gap == 0 or (\"left\" in curr.keys() and \"right\" in adj.keys() and \"top\" in curr[\"left\"].keys() and \"top\"in curr[\"right\"].keys())):\n",
    "                                                    if (gap == 0):\n",
    "                                                        conc, x_delta, y_delta = concatenate_cubes(curr1, adj1, slice_size)\n",
    "                                                    else:\n",
    "                                                        curr1Left = pad_above(curr[\"left\"], curr[\"left\"][\"top\"], i) # FIXIT?\n",
    "                                                        adj1Right = pad_above(adj[\"right\"], curr[\"right\"][\"top\"], i) # FIXIT?\n",
    "                                                        conc, x_delta, y_delta = concatenate_cubes_with_gap(curr1, adj1, gap, curr1Left, adj1Right, slice_size)\n",
    "                                                    train_imgs.append(conc)\n",
    "                                                    train_x_delta.append(x_delta)\n",
    "                                                    train_y_delta.append(y_delta)\n",
    "                                                    # mark the image as matched\n",
    "                                                    train_lbls.append([0,1])\n",
    "                                        if (\"bottom\" in curr.keys() and \"bottom\"in adj.keys()):\n",
    "                                            for i in range(5, 101, 5):\n",
    "                                                curr1 = pad_below(curr, curr[\"bottom\"],i)\n",
    "                                                adj1 = pad_below(adj, adj[\"bottom\"],i)\n",
    "                                                if (gap == 0 or (\"left\" in curr.keys() and \"right\" in adj.keys() and \"bottom\" in curr[\"left\"].keys() and \"bottom\"in curr[\"right\"].keys())):\n",
    "                                                    if (gap == 0):\n",
    "                                                        conc, x_delta, y_delta = concatenate_cubes(curr1, adj1, slice_size)\n",
    "                                                    else:\n",
    "                                                        curr1Left = pad_below(curr[\"left\"], curr[\"left\"][\"bottom\"], i) # FIXIT?\n",
    "                                                        adj1Right = pad_below(adj[\"right\"], curr[\"right\"][\"bottom\"], i) # FIXIT?\n",
    "                                                        conc, x_delta, y_delta = concatenate_cubes_with_gap(curr1, adj1, gap, curr1Left, adj1Right, slice_size)\n",
    "                                                    train_imgs.append(conc)\n",
    "                                                    train_x_delta.append(x_delta)\n",
    "                                                    train_y_delta.append(y_delta)\n",
    "                                                    # mark the image as matched\n",
    "                                                    train_lbls.append([0,1])\n",
    "                                        if (\"left\" in curr.keys()): # enough to check only the curr as the left of the adj is the curr\n",
    "                                            for i in range(5, 101, 5):\n",
    "                                                curr1 = pad_left(curr, curr[\"left\"],i)\n",
    "                                                adj1 = pad_left(adj, adj[\"left\"],i) # essentially the curr\n",
    "                                                if (gap == 0 or (\"left\" in curr.keys() and \"right\" in adj.keys())):\n",
    "                                                    if (gap == 0):\n",
    "                                                        conc, x_delta, y_delta = concatenate_cubes(curr1, adj1, slice_size)\n",
    "                                                    else:\n",
    "                                                        curr1Left = pad_left(curr[\"left\"], ZERO_CUBE, i) # FIXIT? + assuming the gap will not be more than 150\n",
    "                                                        adj1Right = pad_left(adj[\"right\"], ZERO_CUBE, i) # FIXIT? + assuming the gap will not be more than 150\n",
    "                                                        conc, x_delta, y_delta = concatenate_cubes_with_gap(curr1, adj1, gap, curr1Left, adj1Right, slice_size)\n",
    "                                                    train_imgs.append(conc)\n",
    "                                                    train_x_delta.append(x_delta)\n",
    "                                                    train_y_delta.append(y_delta)\n",
    "                                                    # mark the image as matched\n",
    "                                                    train_lbls.append([0,1])\n",
    "                                        if (\"right\" in adj.keys()): # enough to check only the adj as the right of the curr is the adj\n",
    "                                            for i in range(5, 101, 5):\n",
    "                                                curr1 = pad_right(curr, curr[\"right\"],i) # essentially the adj\n",
    "                                                adj1 = pad_right(adj, adj[\"right\"],i)\n",
    "                                                if (gap == 0 or (\"left\" in curr.keys() and \"right\" in adj.keys())):\n",
    "                                                    if (gap == 0):\n",
    "                                                        conc, x_delta, y_delta = concatenate_cubes(curr1, adj1, slice_size)\n",
    "                                                    else:\n",
    "                                                        curr1Left = pad_right(curr[\"left\"], ZERO_CUBE, i) # FIXIT? + assuming the gap will not be more than 150\n",
    "                                                        adj1Right = pad_right(adj[\"right\"], ZERO_CUBE, i) # FIXIT? + assuming the gap will not be more than 150\n",
    "                                                        conc, x_delta, y_delta = concatenate_cubes_with_gap(curr1, adj1, gap, curr1Left, adj1Right, slice_size)\n",
    "                                                    train_imgs.append(conc)\n",
    "                                                    train_x_delta.append(x_delta)\n",
    "                                                    train_y_delta.append(y_delta)\n",
    "                                                    # mark the image as matched\n",
    "                                                    train_lbls.append([0,1])\n",
    "                                    else:\n",
    "                                        # mark the image as not matched\n",
    "                                        train_lbls.append([1,0])\n",
    "                                \n",
    "    warnings.filterwarnings(\"default\")\n",
    "    return train_imgs, train_lbls, train_x_delta, train_y_delta\n",
    "\n",
    "# IMPORTANT: enrich_factor determines how many \"duplications\" of TRUE values will we have in the train set\n",
    "# This allows for a more balanced train set however, it reduces the strictness of the matches \n",
    "# i.e. (not sure why) when we have multiple nearby \"duplicates\" matches we get much more matches in the validation\n",
    "def NEW_build_train_set_for_binary_labeling(cubes, slice_size, folder, enrich_factor=1): # 1 means no enrich\n",
    "    # enrich_factor is split by 2 because it is dual-sided and 1 means actually no enrichment - i.e. 0.5\n",
    "    enrich_factor = enrich_factor / 2 \n",
    "    # clean folder before starting\n",
    "    for root, dirs, files in os.walk(folder):\n",
    "        for f in files:\n",
    "            os.unlink(os.path.join(root, f))\n",
    "\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "    train_imgs = []\n",
    "    train_lbls = []\n",
    "    train_x_delta = []\n",
    "    train_y_delta = []\n",
    "\n",
    "    # iterate over the cubes\n",
    "    for curr in cubes:\n",
    "        # iterate over the others (effectively n^2)\n",
    "        for adj in cubes:\n",
    "            if (adj[\"file\"] != curr[\"file\"]) and \\\n",
    "                (adj[\"tear\"] == curr[\"tear\"]) and \\\n",
    "                curr[\"piece_col\"] < adj[\"piece_col\"]: # no need to test against self and avoid checking from both directions\n",
    "                # append the adjacent image to the current image\n",
    "                conc, x_delta, y_delta, x_file, y_file = VAL_concatenate_cubes(curr, adj, slice_size)\n",
    "                output = folder+x_file[:x_file.rfind(' ')+1]+\"_\"+str(curr[\"top_row\"])+\"_\"+str(curr[\"left_col\"])+\"---\"+y_file[:y_file.rfind(' ')+1]+\"_\"+str(adj[\"top_row\"])+\"_\"+str(adj[\"left_col\"])\n",
    "                np.save(output, conc)\n",
    "                train_imgs.append(output)\n",
    "                train_x_delta.append(x_delta)\n",
    "                train_y_delta.append(y_delta)\n",
    "                if (curr[\"piece_col\"] + 1 == adj[\"piece_col\"]) and \\\n",
    "                    (curr[\"col\"] != 0 or curr[\"last\"]) and \\\n",
    "                    adj[\"col\"] == 0:\n",
    "                    # mark the image as matched\n",
    "                    train_lbls.append([0,1])\n",
    "                    #import pdb; pdb.set_trace()\n",
    "\n",
    "                    # need to enrich the set with a few more true positive samples - so we offset \n",
    "                    # the matched images up and down a few times and create more matches\n",
    "                    if (\"top\" in curr.keys() and \"top\"in adj.keys()):\n",
    "                        for i in range(0, 121, int(120/enrich_factor)):\n",
    "                            if i == 0:\n",
    "                                continue\n",
    "                            curr1 = pad_above(curr, curr[\"top\"],i)\n",
    "                            adj1 = pad_above(adj, adj[\"top\"],i)\n",
    "                            conc, x_delta, y_delta, x_file, y_file = VAL_concatenate_cubes(curr1, adj1, slice_size)\n",
    "                            output = folder+x_file[:x_file.rfind(' ')+1]+\"_\"+str(curr1[\"top_row\"])+\"_\"+str(curr1[\"left_col\"])+\"---\"+y_file[:y_file.rfind(' ')+1]+\"_\"+str(adj1[\"top_row\"])+\"_\"+str(adj1[\"left_col\"])\n",
    "                            np.save(output, conc)\n",
    "                            train_imgs.append(output)\n",
    "                            train_x_delta.append(x_delta)\n",
    "                            train_y_delta.append(y_delta)\n",
    "                            # mark the image as matched\n",
    "                            train_lbls.append([0,1])\n",
    "                    if (\"bottom\" in curr.keys() and \"bottom\"in adj.keys()):\n",
    "                        for i in range(0, 121, int(120/enrich_factor)):\n",
    "                            if i == 0:\n",
    "                                continue\n",
    "                            curr1 = pad_below(curr, curr[\"bottom\"],i)\n",
    "                            adj1 = pad_below(adj, adj[\"bottom\"],i)\n",
    "                            conc, x_delta, y_delta, x_file, y_file = VAL_concatenate_cubes(curr1, adj1, slice_size)\n",
    "                            output = folder+x_file[:x_file.rfind(' ')+1]+\"_\"+str(curr1[\"top_row\"])+\"_\"+str(curr1[\"left_col\"])+\"---\"+y_file[:y_file.rfind(' ')+1]+\"_\"+str(adj1[\"top_row\"])+\"_\"+str(adj1[\"left_col\"])\n",
    "                            np.save(output, conc)\n",
    "                            train_imgs.append(output)\n",
    "                            train_x_delta.append(x_delta)\n",
    "                            train_y_delta.append(y_delta)\n",
    "                            # mark the image as matched\n",
    "                            train_lbls.append([0,1])\n",
    " \n",
    "                else:\n",
    "                    # mark the image as not matched\n",
    "                    train_lbls.append([1,0])\n",
    "\n",
    "    warnings.filterwarnings(\"default\")\n",
    "    return train_imgs, train_lbls, train_x_delta, train_y_delta\n",
    "        \n",
    "def frame_to_n_by_m(orig, start_vector, end_vector, is_col):\n",
    "    max_val = np.amax(end_vector)\n",
    "    min_val = np.amin(start_vector)\n",
    "    width = max_val - min_val\n",
    "    if (is_col):\n",
    "        result = np.zeros((start_vector.size, width))\n",
    "    else:\n",
    "        result = np.zeros((width, start_vector.size))\n",
    "    \n",
    "    for i in range(0, start_vector.size):\n",
    "        if (is_col):\n",
    "            row_vec = orig[i, start_vector[i]:end_vector[i]]\n",
    "        else:\n",
    "            row_vec = orig[start_vector[i]:end_vector[i],i]\n",
    "        temp = np.lib.pad(row_vec, (start_vector[i]-min_val, max_val-end_vector[i]), 'constant', constant_values=(0.09, 0.09))\n",
    "        if (is_col):\n",
    "            if (result[i].size != width):\n",
    "                import pdb; pdb.set_trace()\n",
    "            result[i] = temp[0:width]\n",
    "        else:\n",
    "            result[:,i] = temp[0:width]\n",
    "    return min_val, result\n",
    "\n",
    "def rough_tear_line(orig, start_vector, cut_mean, is_col, chew_factor):\n",
    "    end_vector = np.empty(start_vector.size).astype(int)\n",
    "    if (is_col and np.absolute(cut_mean-orig.shape[1]) < 10):\n",
    "        end_vector.fill(orig.shape[1])\n",
    "    elif (not is_col and np.absolute(cut_mean-orig.shape[0]) < 10):\n",
    "        end_vector.fill(orig.shape[0])\n",
    "    else:\n",
    "        deviation_vector = np.random.normal(0, chew_factor, start_vector.size).astype(int)\n",
    "        end_vector[0] = cut_mean + deviation_vector[0]\n",
    "        for i in range(1, end_vector.size):\n",
    "            end_vector[i] = end_vector[i - 1] + deviation_vector[i]\n",
    "    \n",
    "    start_px, cut_piece = frame_to_n_by_m(orig, start_vector, end_vector, is_col)    \n",
    "    return start_px, cut_piece, end_vector\n",
    "\n",
    "def rough_tear_image(image, cols, rows):\n",
    "    pieces = []\n",
    "    col_width = int(image.shape[1] / cols)\n",
    "    row_height = int(image.shape[0] / rows)\n",
    "    print(col_width, row_height)\n",
    "    next_col_start_vec = np.zeros((image.shape[0],), dtype=int)\n",
    "    for col_idx in range(0, cols):\n",
    "    #         import pdb; pdb.set_trace()\n",
    "        start_col_px, cut_column, next_col_start_vec =  rough_tear_line(image, next_col_start_vec, col_width * (col_idx + 1), True, 5)\n",
    "        next_row_start_vec = np.zeros((cut_column.shape[1],), dtype=int)\n",
    "        for row_idx in range(0, rows):\n",
    "            start_row_px, cut_piece, next_row_start_vec = rough_tear_line(cut_column, next_row_start_vec, row_height * (row_idx + 1), False, 1)\n",
    "\n",
    "            ymin, ymax, xmin, xmax = calc_min_max_coordinates_dynamic(cut_piece, cutoff=BG_2_OBJ_RATIO)\n",
    "            temp = crop(cut_piece, ymin, ymax, xmin, xmax)\n",
    "            \n",
    "            #import pdb; pdb.set_trace()\n",
    "            piece = {}\n",
    "            piece[\"orig\"] = cut_piece\n",
    "            piece[\"cut\"] = temp\n",
    "            piece[\"col\"] = col_idx\n",
    "            piece[\"row\"] = row_idx\n",
    "            piece[\"col_px\"] = start_col_px + xmin\n",
    "            piece[\"row_px\"] = start_row_px + ymin\n",
    "            pieces.append(piece)\n",
    "            \n",
    "    return pieces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# RUN Define model util functions\n",
    "\n",
    "# initialize a shaped matrix of weights with random values\n",
    "def weight_variable(shape):\n",
    "  initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "  return tf.Variable(initial)\n",
    "\n",
    "# initialize a shaped matrix of bias with random values\n",
    "def bias_variable(shape):\n",
    "  initial = tf.constant(0.1, shape=shape)\n",
    "  return tf.Variable(initial)\n",
    "\n",
    "def conv2d(x, W):\n",
    "  return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "  return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                        strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "def max_pool_1x2(x):\n",
    "  return tf.nn.max_pool(x, ksize=[1, 1, 2, 1],\n",
    "                        strides=[1, 1, 2, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2x1(x):\n",
    "  return tf.nn.max_pool(x, ksize=[1, 2, 1, 1],\n",
    "                        strides=[1, 2, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_1x1(x):\n",
    "  return tf.nn.max_pool(x, ksize=[1, 1, 1, 1],\n",
    "                        strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_5x5(x):\n",
    "  return tf.nn.max_pool(x, ksize=[1, 5, 5, 1],\n",
    "                        strides=[1, 5, 5, 1], padding='SAME')\n",
    "\n",
    "def max_pool_5x2(x):\n",
    "  return tf.nn.max_pool(x, ksize=[1, 5, 2, 1],\n",
    "                        strides=[1, 5, 2, 1], padding='SAME')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# RUN Image utility functions (external source)\n",
    "def branchedPoints(skel):\n",
    "    branch1=np.array([[2, 1, 2], [1, 1, 1], [2, 2, 2]])\n",
    "    branch2=np.array([[1, 2, 1], [2, 1, 2], [1, 2, 1]])\n",
    "    branch3=np.array([[1, 2, 1], [2, 1, 2], [1, 2, 2]])\n",
    "    branch4=np.array([[2, 1, 2], [1, 1, 2], [2, 1, 2]])\n",
    "    branch5=np.array([[1, 2, 2], [2, 1, 2], [1, 2, 1]])\n",
    "    branch6=np.array([[2, 2, 2], [1, 1, 1], [2, 1, 2]])\n",
    "    branch7=np.array([[2, 2, 1], [2, 1, 2], [1, 2, 1]])\n",
    "    branch8=np.array([[2, 1, 2], [2, 1, 1], [2, 1, 2]])\n",
    "    branch9=np.array([[1, 2, 1], [2, 1, 2], [2, 2, 1]])\n",
    "    br1=mh.morph.hitmiss(skel,branch1)\n",
    "    br2=mh.morph.hitmiss(skel,branch2)\n",
    "    br3=mh.morph.hitmiss(skel,branch3)\n",
    "    br4=mh.morph.hitmiss(skel,branch4)\n",
    "    br5=mh.morph.hitmiss(skel,branch5)\n",
    "    br6=mh.morph.hitmiss(skel,branch6)\n",
    "    br7=mh.morph.hitmiss(skel,branch7)\n",
    "    br8=mh.morph.hitmiss(skel,branch8)\n",
    "    br9=mh.morph.hitmiss(skel,branch9)\n",
    "    return br1+br2+br3+br4+br5+br6+br7+br8+br9\n",
    "\n",
    "def endPoints(skel):\n",
    "    endpoint1=np.array([[0, 0, 0],\n",
    "                        [0, 1, 0],\n",
    "                        [2, 1, 2]])\n",
    "    \n",
    "    endpoint2=np.array([[0, 0, 0],\n",
    "                        [0, 1, 2],\n",
    "                        [0, 2, 1]])\n",
    "    \n",
    "    endpoint3=np.array([[0, 0, 2],\n",
    "                        [0, 1, 1],\n",
    "                        [0, 0, 2]])\n",
    "    \n",
    "    endpoint4=np.array([[0, 2, 1],\n",
    "                        [0, 1, 2],\n",
    "                        [0, 0, 0]])\n",
    "    \n",
    "    endpoint5=np.array([[2, 1, 2],\n",
    "                        [0, 1, 0],\n",
    "                        [0, 0, 0]])\n",
    "    \n",
    "    endpoint6=np.array([[1, 2, 0],\n",
    "                        [2, 1, 0],\n",
    "                        [0, 0, 0]])\n",
    "    \n",
    "    endpoint7=np.array([[2, 0, 0],\n",
    "                        [1, 1, 0],\n",
    "                        [2, 0, 0]])\n",
    "    \n",
    "    endpoint8=np.array([[0, 0, 0],\n",
    "                        [2, 1, 0],\n",
    "                        [1, 2, 0]])\n",
    "    \n",
    "    ep1=mh.morph.hitmiss(skel,endpoint1)\n",
    "    ep2=mh.morph.hitmiss(skel,endpoint2)\n",
    "    ep3=mh.morph.hitmiss(skel,endpoint3)\n",
    "    ep4=mh.morph.hitmiss(skel,endpoint4)\n",
    "    ep5=mh.morph.hitmiss(skel,endpoint5)\n",
    "    ep6=mh.morph.hitmiss(skel,endpoint6)\n",
    "    ep7=mh.morph.hitmiss(skel,endpoint7)\n",
    "    ep8=mh.morph.hitmiss(skel,endpoint8)\n",
    "    ep = ep1+ep2+ep3+ep4+ep5+ep6+ep7+ep8\n",
    "    return ep\n",
    "\n",
    "def pruning(skeleton, size):\n",
    "    '''remove iteratively end points \"size\" \n",
    "       times from the skeleton\n",
    "    '''\n",
    "    for i in range(0, size):\n",
    "        endpoints = endPoints(skeleton)\n",
    "        endpoints = np.logical_not(endpoints)\n",
    "        skeleton = np.logical_and(skeleton,endpoints)\n",
    "    return skeleton\n",
    "\n",
    "def plot_comparison(original, filtered, filter_name):\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(8, 4), sharex=True, sharey=True)\n",
    "    ax1.imshow(original, cmap=plt.cm.gray)\n",
    "    ax1.set_title('original')\n",
    "    ax1.axis('off')\n",
    "    ax1.set_adjustable('box-forced')\n",
    "    ax2.imshow(filtered, cmap=plt.cm.gray)\n",
    "    ax2.set_title(filter_name)\n",
    "    ax2.axis('off')\n",
    "    ax2.set_adjustable('box-forced')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# RUN model_tf - Define the model - 250, 125, 62, 25\n",
    "def model_tf(input_width): \n",
    "    global accuracy, correct_prediction, train_step, x, y_, y_conv, keep_prob #, W_fc, b_fc, cost, y_conv_temp\n",
    "    \n",
    "    # foundation of the model - the input layer of the image 250 x input_width*2\n",
    "    x = tf.placeholder(tf.float32, [None, 250, input_width*2], \"001\")\n",
    "    x_image = tf.reshape(x, [-1,250,input_width*2,1], \"0011\") # 1 is the number of color channels\n",
    "\n",
    "    # the target digits of the model\n",
    "    y_ = tf.placeholder(tf.float32, [None, 2], \"002\") # 1\n",
    "\n",
    "    # zero convolutional layer: one input image and 32 output filters of 5x5\n",
    "    W_conv0 = weight_variable([5, 5, 1, 32])\n",
    "    b_conv0 = bias_variable([32])\n",
    "    h_conv0 = tf.nn.relu(conv2d(x_image, W_conv0) + b_conv0, \"0020\")\n",
    "    h_pool0 = max_pool_1x1(h_conv0) # size is maintained\n",
    "\n",
    "    # first convolutional layer: one input image and 32 output filters of 5x5\n",
    "    W_conv1 = weight_variable([5, 5, 32, 32])\n",
    "    b_conv1 = bias_variable([32])\n",
    "    h_conv1 = tf.nn.relu(conv2d(h_pool0, W_conv1) + b_conv1, \"0021\")\n",
    "    if (input_width == 250):\n",
    "        h_pool1 = max_pool_2x2(h_conv1) # size is reduced to 125x250\n",
    "    elif (input_width == 125):\n",
    "        h_pool1 = max_pool_2x1(h_conv1) # size is reduced to 125x250\n",
    "    elif (input_width == 62):\n",
    "        h_pool1 = max_pool_2x1(h_conv1) # size is reduced to 125x125\n",
    "    elif (input_width == 25):\n",
    "        h_pool1 = max_pool_2x1(h_conv1) # size is reduced to 125x50\n",
    "    else:\n",
    "        print(\"ERROR - unsupported slice width\")\n",
    "        return\n",
    "\n",
    "    # second convolutional layer: 32 input (filtered) images and 32 output filters of 5x5\n",
    "    W_conv2 = weight_variable([5, 5, 32, 32])\n",
    "    b_conv2 = bias_variable([32])\n",
    "    h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2, \"0022\")\n",
    "    if (input_width == 62):\n",
    "        h_pool2 = max_pool_1x1(h_conv2) # size is reduced to 125x125\n",
    "    elif (input_width == 25):\n",
    "        h_pool2 = max_pool_1x1(h_conv2) # size is reduced to 125x50\n",
    "    else:\n",
    "        h_pool2 = max_pool_1x2(h_conv2) # size is reduced to 125x125\n",
    "\n",
    "\n",
    "    # third convolutional layer: 32 input (filtered) images and 32 output filters of 5x5\n",
    "    W_conv3 = weight_variable([5, 5, 32, 32])\n",
    "    b_conv3 = bias_variable([32])\n",
    "    h_conv3 = tf.nn.relu(conv2d(h_pool2, W_conv3) + b_conv3, \"0023\")\n",
    "    if (input_width == 25):\n",
    "        h_pool3 = max_pool_5x2(h_conv3) # size is reduced to 25x25\n",
    "    else:\n",
    "        h_pool3 = max_pool_5x5(h_conv3) # size is reduced to 25x25\n",
    "\n",
    "\n",
    "    h_pool3_flat = tf.reshape(h_pool3, [-1, 25*25*32]) # shape as an array \n",
    "\n",
    "    # fourth layer - fully connected with input 25*25*128 and output 1024\n",
    "    W_fc1 = weight_variable([25*25*32, 1024])\n",
    "    b_fc1 = bias_variable([1024])\n",
    "    h_fc1 = tf.nn.relu(tf.matmul(h_pool3_flat, W_fc1) + b_fc1, \"0024\")\n",
    "\n",
    "    # a drop layer with probability \n",
    "    keep_prob = tf.placeholder(tf.float32, name=\"003\")\n",
    "    h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob, name=\"0031\")\n",
    "\n",
    "    #     # final layer - reduce to one \"class\" for the linear regression\n",
    "    #     W_fc = weight_variable([1024, 1]) \n",
    "    #     b_fc = bias_variable([1])         \n",
    "    #     y_conv_temp = tf.matmul(h_fc1_drop, W_fc, name=\"0032\") + b_fc\n",
    "    #     y_conv = tf.minimum(y_conv_temp, tf.constant(BREAK_VAL, tf.float32))\n",
    "\n",
    "    #     #     # minimize loss function\n",
    "    #     #     cross_entropy = tf.reduce_mean(\n",
    "    #     #       tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y_conv))\n",
    "    #     # cost = tf.reduce_sum(tf.pow(y_conv - y_, 2))/(2*BATCHES*BATCH_SIZE) # Mean squared error\n",
    "    #     cost = tf.reduce_mean(tf.square(y_conv_temp - y_), name=\"0033\") # Mean squared error\n",
    "\n",
    "    #     #     # define train step and rate\n",
    "    #     #     train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "    #     train_step = tf.train.AdamOptimizer(LEARNING_RATE).minimize(cost) # Gradient descent\n",
    "\n",
    "    #     # evaluate the prediction and the accuracy on the train test - needed only for printing during the training\n",
    "    #     correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y_,1))\n",
    "    #     accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    \n",
    "    # final layer - softmax reduction 2 outputs\n",
    "    W_fc2 = weight_variable([1024, 2])\n",
    "    b_fc2 = bias_variable([2])\n",
    "    y_conv = tf.matmul(h_fc1_drop, W_fc2) + b_fc2\n",
    "\n",
    "    # minimize loss function\n",
    "    cross_entropy = tf.reduce_mean(\n",
    "      tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y_conv))\n",
    "\n",
    "    # define train step and rate\n",
    "    train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "\n",
    "    # evaluate the prediction and the accuracy on the train test - needed only for printing during the training\n",
    "    correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y_,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# RUN train\n",
    "def train(train_imgs, train_lbls, output_model, input_model=\"\"):\n",
    "    print(\"#####################################################################\")\n",
    "    print(\"TRAINING:\")\n",
    "    print(\"MODEL:\"+output_model)\n",
    "    print(\"#####################################################################\")\n",
    "\n",
    "    from random import randrange\n",
    "    \n",
    "    # TRAIN Prepare the session\n",
    "\n",
    "    # create a saver object\n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "    # start session and initialize variables\n",
    "    sess = tf.InteractiveSession()\n",
    "    if input_model != \"\":\n",
    "        # Restore variables from disk.\n",
    "        saver.restore(sess, input_model)\n",
    "        print(\"Model restored.\")\n",
    "    else:\n",
    "        sess.run(tf.initialize_all_variables())\n",
    "\n",
    "    # TRAIN Train the model\n",
    "    x_batch = []\n",
    "    y_batch = []\n",
    "    # run the train batches\n",
    "    for i in range(BATCHES):\n",
    "        x_batch = []\n",
    "        y_batch = []\n",
    "        for _ in range(BATCH_SIZE):\n",
    "            random_index = randrange(0,len(train_imgs))\n",
    "            image = np.load(train_imgs[random_index]+\".npy\")\n",
    "            x_batch.append(image)\n",
    "            y_batch.append(train_lbls[random_index])\n",
    "\n",
    "        # train\n",
    "        # print(\"step %d\"%(i))\n",
    "        train_step.run(feed_dict={x: x_batch, y_: y_batch, keep_prob: 0.5})\n",
    "\n",
    "        # print the accuracy thus far\n",
    "        if (i+1)%50 == 0:\n",
    "            train_accuracy = accuracy.eval(feed_dict={\n",
    "                x:x_batch, y_: y_batch, keep_prob: 1.0})\n",
    "            print(\"step %d, training accuracy %g\"%(i, train_accuracy))\n",
    "\n",
    "\n",
    "    print(\"Optimization Finished!\")\n",
    "    train_accuracy = accuracy.eval(feed_dict={\n",
    "        x:x_batch, y_: y_batch, keep_prob: 1.0})\n",
    "    print(\"step %d, training accuracy %g\"%(i, train_accuracy))\n",
    "\n",
    "    # Save the variables to disk.\n",
    "    save_path = saver.save(sess, output_model)\n",
    "    print(\"Model saved in file: %s\" % save_path)\n",
    "\n",
    "    # Close the Session when we're done. If un-commented - need to run next bock of restore...\n",
    "    sess.close()   \n",
    "    print(\"#####################################################################\")\n",
    "    print(\"TRAINING ENDED\")\n",
    "    print(\"#####################################################################\")\n",
    "    print(\" \")\n",
    "    print(\" \")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# RUN pre_process - OLD?\n",
    "def pre_process(folder):\n",
    "    print(\"#####################################################################\")\n",
    "    print(\"PRE_PROCESS:\"+folder)\n",
    "    print(\"#####################################################################\")\n",
    "    result = []\n",
    "    \n",
    "    for root, dirs, files in os.walk(folder):\n",
    "        for file_ in files:\n",
    "            # Read the image\n",
    "            # image = img.imread(os.path.join(root, file_))\n",
    "            image = np.load(os.path.join(root, file_))\n",
    "            # import pdb; pdb.set_trace()\n",
    "            cubes = VAL_slice_to_static_slices(file_, image)\n",
    "            print(\"File: %s >>> cubes: %d\"%(file_, len(cubes)))\n",
    "            result.extend(cubes)\n",
    "    \n",
    "    return result\n",
    "    print(\"#####################################################################\")\n",
    "    print(\"PRE_PROCESS ENDED\")\n",
    "    print(\"#####################################################################\")\n",
    "    print(\" \")\n",
    "    print(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# RUN pre_process_training - crop image, then tear it randomly to various tears, then per tear create cubes out of the edges, return cube set\n",
    "def pre_process_training(img_name, x_start=X_START, x_end=X_END, y_start=Y_START, y_end=Y_END):\n",
    "    print(\"#####################################################################\")\n",
    "    print(\"PRE_PROCESS:\"+img_name)\n",
    "    print(\"#####################################################################\")\n",
    "    image = read_and_crop(img_name, x_start, x_end, y_start, y_end)\n",
    "    result = []\n",
    "    \n",
    "    for col_cut in range(4, 7): # 3...10\n",
    "        for row_cut in range(3, 5): # 2...5\n",
    "            print(\"PRE_PROCESS:::\"+\"TEAR_\"+str(col_cut)+\"X\"+str(row_cut))\n",
    "            pieces = rough_tear_image(image, col_cut, row_cut)\n",
    "            \n",
    "            for piece in pieces:\n",
    "                print(\"PRE_PROCESS:::\"+\"PIECE_\"+str(piece[\"col\"])+\"X\"+str(piece[\"row\"]))\n",
    "                file_ = \"TEAR_\"+str(col_cut)+\"X\"+str(row_cut)+\"_PIECE_\"+str(piece[\"col\"])+\"X\"+str(piece[\"row\"])\n",
    "                cubes = VAL_slice_TEAR_to_static_slices(file_, piece)\n",
    "                for cube in cubes:\n",
    "                    cube[\"tear\"] = str(col_cut)+\"X\"+str(row_cut)\n",
    "                    cube[\"piece_col\"] = piece[\"col\"]\n",
    "                    cube[\"piece_row\"] = piece[\"row\"]\n",
    "                print(\"File: %s >>> cubes: %d\"%(file_, len(cubes)))\n",
    "                result.extend(cubes)\n",
    "    \n",
    "    return result\n",
    "    print(\"#####################################################################\")\n",
    "    print(\"PRE_PROCESS ENDED\")\n",
    "    print(\"#####################################################################\")\n",
    "    print(\" \")\n",
    "    print(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def validate1(cubes, model, slice_size, folder, curr_cube):    \n",
    "    # VALIDATE prepare the data sets\n",
    "    test_imgs, test_x_delta, test_y_delta, test_x_file, test_y_file = VAL_build_train_set(cubes, slice_size, folder, curr_cube)\n",
    "    print(\"loaded %d images\"%(len(test_imgs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def validate2(folder, model, slice_size):\n",
    "    test_imgs = []\n",
    "    test_x_file = []\n",
    "    test_y_file = []\n",
    "    the_root = \"\"\n",
    "    for root, dirs, files in os.walk(folder):\n",
    "        the_root = root\n",
    "        for file_ in files:\n",
    "            test_imgs.append( os.path.join(root, file_) )\n",
    "            test_x_file.append(file_[:file_.rfind('---P')])\n",
    "            test_y_file.append(file_[file_.rfind('---P')+3:])\n",
    "            \n",
    "    print(len(test_imgs))\n",
    "    \n",
    "    # VALIDATE Prepare a test session \n",
    "\n",
    "    # Add ops to save and restore all the variables.\n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "    # start session and initialize variables\n",
    "    sess = tf.InteractiveSession()\n",
    "\n",
    "    # Restore variables from disk.\n",
    "    saver.restore(sess, model)\n",
    "    print(\"Model restored.\")\n",
    "\n",
    "    # VALIDATE Validate the model\n",
    "\n",
    "    # import pdb; pdb.set_trace()\n",
    "    v1t = []\n",
    "    count = 0\n",
    "    length = len(test_imgs)\n",
    "    batch = 100\n",
    "    x_batch = []\n",
    "    # change the ranges in the loop below - first number is the start point (multiplied by batch size)\n",
    "    # second number is the end point (multiplied by batch size)\n",
    "    # third number is the jump from batch to batch\n",
    "    # use the length about to set the batch length\n",
    "    for start in range(0, length, batch):\n",
    "        for i in range(start, start+batch):\n",
    "            if (i < length):\n",
    "                image = np.load(test_imgs[i])\n",
    "                x_batch.append(image)\n",
    "                count += 1\n",
    "\n",
    "        # print(\"Validating start at #%d end at %d\"%(start*batch,(start+length)*batch))\n",
    "        my_prediction=tf.argmax(y_conv,1)\n",
    "        v1 = my_prediction.eval(feed_dict={x:x_batch, keep_prob: 1.0})\n",
    "        v1t = np.concatenate((v1t, v1), axis=0)\n",
    "        x_batch = []\n",
    "        print(\">>> step %d\"%(start+batch))\n",
    "\n",
    "\n",
    "    match_indexes = np.nonzero(v1t)[0]\n",
    "    A = np.array(test_x_file)\n",
    "    B = np.array(test_y_file)\n",
    "    C = np.array(test_imgs)\n",
    "    match_x_files = A[match_indexes]\n",
    "    match_y_files = B[match_indexes]\n",
    "    match_images = C[match_indexes]\n",
    "    \n",
    "    for matched_img in match_images:\n",
    "        load_img = np.load(matched_img)\n",
    "        plt.imsave(os.path.join(\"/Volumes/250GB/matched/\",matched_img[matched_img.rfind('/')+1:]+\".png\"), load_img, cmap=plt.cm.gray)\n",
    "    \n",
    "    for root, dirs, files in os.walk(folder):\n",
    "        for file_ in files:\n",
    "            os.remove( os.path.join(root, file_) ) # delete it from the FS\n",
    "                \n",
    "    with open('matches.csv', 'a') as csvfile:\n",
    "        csvout = csv.writer(csvfile)\n",
    "        for match_index in match_indexes:\n",
    "            print(\"MATCH %s === %s\"%(test_x_file[match_index], test_y_file[match_index]))\n",
    "            # print(\"MATCH %s === %s\"%(A[match_index], B[match_index]))\n",
    "            # csvout.writerow([A[match_index], B[match_index]])\n",
    "            csvout.writerow([test_x_file[match_index], test_y_file[match_index]])\n",
    "            # plt.imsave(\"match_\"+match_index+\".jpg\", C[match_index])\n",
    "\n",
    "    # Close the Session when we're done.\n",
    "    sess.close()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def validate2_for_cross_validation(test_imgs, test_lbls, model):\n",
    "    print(len(test_imgs))\n",
    "    \n",
    "    # VALIDATE Prepare a test session \n",
    "\n",
    "    # Add ops to save and restore all the variables.\n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "    # start session and initialize variables\n",
    "    sess = tf.InteractiveSession()\n",
    "\n",
    "    # Restore variables from disk.\n",
    "    saver.restore(sess, model)\n",
    "    print(\"Model restored.\")\n",
    "\n",
    "    # VALIDATE Validate the model\n",
    "\n",
    "    # import pdb; pdb.set_trace()\n",
    "    count = 0\n",
    "    se = 0\n",
    "    st = 0\n",
    "    v1t = []\n",
    "    v2t = []\n",
    "    v1tt = []\n",
    "    v2tt = []\n",
    "    length = len(test_imgs)\n",
    "    batch = 100\n",
    "    x_batch = []\n",
    "    y_batch = []\n",
    "    # change the ranges in the loop below - first number is the start point (multiplied by batch size)\n",
    "    # second number is the end point (multiplied by batch size)\n",
    "    # third number is the jump from batch to batch\n",
    "    # use the length about to set the batch length\n",
    "    for start in range(0, length, batch):\n",
    "        for i in range(start, start+batch):\n",
    "            if (i < length):\n",
    "                image = np.load(test_imgs[i]+\".npy\")\n",
    "                x_batch.append(image)\n",
    "                y_batch.append(train_lbls[i])                \n",
    "                \n",
    "        # print the accuracy thus far\n",
    "    #         train_accuracy = accuracy.eval(feed_dict={\n",
    "    #             x:x_batch, y_: y_batch, keep_prob: 1.0})\n",
    "    #         print(\"step %d, training accuracy %g\"%(i, train_accuracy))\n",
    "\n",
    "        # print(\"Validating start at #%d end at %d\"%(start*batch,(start+length)*batch))\n",
    "    #         my_prediction=tf.argmax(y_conv,1)\n",
    "    #         v1 = my_prediction.eval(feed_dict={x:x_batch, keep_prob: 1.0})\n",
    "    #         v1t = np.concatenate((v1t, v1), axis=0)\n",
    "\n",
    "        my_prediction=tf.argmax(y_conv,1)\n",
    "        my_target=tf.argmax(y_,1)\n",
    "        v1 = my_prediction.eval(feed_dict={x:x_batch, y_: y_batch, keep_prob: 1.0})\n",
    "        v2 = my_target.eval(feed_dict={x:x_batch, y_: y_batch, keep_prob: 1.0})\n",
    "        v1t = np.concatenate((v1t, v1), axis=0)\n",
    "        v2t = np.concatenate((v2t, v2), axis=0)\n",
    "\n",
    "        c1 = np.sum(np.absolute(np.subtract(v2, v1)))\n",
    "        c2 = np.sum(np.absolute(v2))\n",
    "        se += c1\n",
    "        st += c2\n",
    "\n",
    "        x_batch = []\n",
    "        y_batch = []\n",
    "        print(\">>> step %d\"%(start+batch))\n",
    "        \n",
    "        count += ((i+1)*batch - start*batch)\n",
    "        precision, recall, f_score, support = precision_recall_fscore_support(v2t, v1t, average='binary')\n",
    "        print(\"step %d-%d, precision %f, recall %f, f_score %f\"%(start, i, precision, recall, f_score))\n",
    "        # print(\"Accumulated total true = %d\"%(st));\n",
    "        # print(\"Accumulated total error rate = %f\"%(se/count));\n",
    "        v1tt = np.concatenate((v1tt, v1t), axis=0)\n",
    "        v2tt = np.concatenate((v2tt, v2t), axis=0)\n",
    "\n",
    "    precision, recall, f_score, support = precision_recall_fscore_support(v2tt, v1tt, average='binary')\n",
    "    print(\"TOTAL %d, precision %f, recall %f, f_score %f\"%(count, precision, recall, f_score))\n",
    "    print(\"TOTAL true = %d\"%(st));\n",
    "    print(\"TOTAL error rate = %f\"%(se/count));\n",
    "\n",
    "    match_indexes = np.nonzero(v1t)[0]\n",
    "    C = np.array(test_imgs)\n",
    "    match_images = C[match_indexes]\n",
    "    \n",
    "    for matched_img in match_images:\n",
    "        load_img = np.load(matched_img+\".npy\")\n",
    "        plt.imsave(os.path.join(ROOT_FOLDER+\"synt_matched/\",matched_img[matched_img.rfind('/')+1:]+\".png\"), load_img, cmap=plt.cm.gray)\n",
    "                    \n",
    "    #     with open('synt_matches.csv', 'a') as csvfile:\n",
    "    #         csvout = csv.writer(csvfile)\n",
    "    #         for match_index in match_indexes:\n",
    "    #             print(\"MATCH %s === %s\"%(test_x_file[match_index], test_y_file[match_index]))\n",
    "    #             # print(\"MATCH %s === %s\"%(A[match_index], B[match_index]))\n",
    "    #             # csvout.writerow([A[match_index], B[match_index]])\n",
    "    #             csvout.writerow([test_x_file[match_index], test_y_file[match_index]])\n",
    "    #             # plt.imsave(\"match_\"+match_index+\".jpg\", C[match_index])\n",
    "\n",
    "    # Close the Session when we're done.\n",
    "    sess.close()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def iter_validate(cubes, model, slice_size, folder):\n",
    "    print(\"#####################################################################\")\n",
    "    print(\"VALIDATING\")\n",
    "    print(\"#####################################################################\")\n",
    "    cubes_len = len(cubes)\n",
    "    batch_size = 100\n",
    "    count = 0\n",
    "    # iterate over the cubes\n",
    "    for curr in cubes:\n",
    "        count += 1\n",
    "        if count < batch_size: ### TEMP LIMITATION\n",
    "            print(\"CUBE:%s\"%(curr[\"file\"]+\"_\"+str(curr[\"top_row\"])+\"_\"+str(curr[\"left_col\"])))\n",
    "            validate1(cubes, model, slice_size, folder, curr)\n",
    "            validate2(folder, model, slice_size)\n",
    "        \n",
    "    print(\"#####################################################################\")\n",
    "    print(\"VALIDATION ENDED\")\n",
    "    print(\"#####################################################################\")\n",
    "    print(\" \")\n",
    "    print(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def run_all(folder, model, slice_size):\n",
    "    model_tf(slice_size)\n",
    "    cubes_set = pre_process(folder)\n",
    "    validate(cubes_set, model, slice_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# HELPER block\n",
    "# image = read_and_crop(\"PX303/FG001/PX303-Fg001-V-C01-R01-D05032015-T112602-ML924__012.jpg\")\n",
    "## image = read_and_crop(\"PX303/FG004/PX303-Fg004-V-C01-R01-D08032015-T110900-ML924__012.jpg\", 100, -1, 400, -1)\n",
    "# image = read_and_crop(\"PX303/FG004/PX303-Fg004-V-C01-R02-D08032015-T105147-ML924__012.jpg\")\n",
    "# image = read_and_crop(\"PX303/FG004/PX303-Fg004-V-C02-R01-D08032015-T110025-ML924__012.jpg\")\n",
    "# image = read_and_crop(\"PX303/FG004/PX303-Fg004-V-C02-R02-D08032015-T105553-ML924__012.jpg\")\n",
    "# image = read_and_crop(\"PX303/FG006/PX303-Fg006-V-C01-R01-D08032015-T120605-ML924__012.jpg\")\n",
    "# image = read_and_crop(\"PX303/FG006/PX303-Fg006-V-C01-R02-D08032015-T115230-ML924__012.jpg\")\n",
    "# image = read_and_crop(\"PX303/FG006/PX303-Fg006-V-C02-R01-D08032015-T120158-ML924__012.jpg\")\n",
    "##image = read_and_crop(\"PX303/FG006/PX303-Fg006-V-C02-R02-D08032015-T115704-ML924__012.jpg\", 0, 6200, 0, 4400)\n",
    "##plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#####################################################################\n",
      "PRE_PROCESS:PX303/FG001/PX303-Fg001-V-C01-R01-D05032015-T112520-ML638__006.jpg\n",
      "#####################################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/il239838/anaconda/envs/tf_gpu/lib/python3.5/site-packages/PIL/Image.py:678: ResourceWarning: unclosed file <_io.BufferedReader name='/Users/il239838/Downloads/private/Thesis/Papyrus/PX303/FG001/PX303-Fg001-V-C01-R01-D05032015-T112520-ML638__006.jpg'>\n",
      "  self.load()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRE_PROCESS:::TEAR_4X3\n",
      "1171 685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/il239838/anaconda/envs/tf_gpu/lib/python3.5/site-packages/skimage/util/dtype.py:110: UserWarning: Possible precision loss when converting from float64 to uint16\n",
      "  \"%s to %s\" % (dtypeobj_in, dtypeobj))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRE_PROCESS:::PIECE_0X0\n",
      "691 1253\n",
      "File: TEAR_4X3_PIECE_0X0 >>> cubes: 3\n",
      "PRE_PROCESS:::PIECE_0X1\n",
      "728 1234\n",
      "File: TEAR_4X3_PIECE_0X1 >>> cubes: 3\n",
      "PRE_PROCESS:::PIECE_0X2\n",
      "665 946\n",
      "File: TEAR_4X3_PIECE_0X2 >>> cubes: 4\n",
      "PRE_PROCESS:::PIECE_1X0\n",
      "679 1157\n",
      "File: TEAR_4X3_PIECE_1X0 >>> cubes: 4\n",
      "PRE_PROCESS:::PIECE_1X1\n",
      "738 1238\n",
      "File: TEAR_4X3_PIECE_1X1 >>> cubes: 4\n",
      "PRE_PROCESS:::PIECE_1X2\n",
      "686 1130\n",
      "File: TEAR_4X3_PIECE_1X2 >>> cubes: 3\n",
      "PRE_PROCESS:::PIECE_2X0\n",
      "685 1388\n",
      "File: TEAR_4X3_PIECE_2X0 >>> cubes: 4\n",
      "PRE_PROCESS:::PIECE_2X1\n",
      "690 1324\n",
      "File: TEAR_4X3_PIECE_2X1 >>> cubes: 4\n",
      "PRE_PROCESS:::PIECE_2X2\n",
      "707 1492\n",
      "File: TEAR_4X3_PIECE_2X2 >>> cubes: 4\n",
      "PRE_PROCESS:::PIECE_3X0\n",
      "715 1269\n",
      "File: TEAR_4X3_PIECE_3X0 >>> cubes: 4\n",
      "PRE_PROCESS:::PIECE_3X1\n",
      "702 1183\n",
      "File: TEAR_4X3_PIECE_3X1 >>> cubes: 4\n",
      "PRE_PROCESS:::PIECE_3X2\n",
      "682 1309\n",
      "File: TEAR_4X3_PIECE_3X2 >>> cubes: 4\n",
      "PRE_PROCESS:::TEAR_4X4\n",
      "1171 514\n",
      "PRE_PROCESS:::PIECE_0X0\n",
      "518 1110\n",
      "File: TEAR_4X4_PIECE_0X0 >>> cubes: 4\n",
      "PRE_PROCESS:::PIECE_0X1\n",
      "537 1137\n",
      "File: TEAR_4X4_PIECE_0X1 >>> cubes: 3\n",
      "PRE_PROCESS:::PIECE_0X2\n",
      "534 1243\n",
      "File: TEAR_4X4_PIECE_0X2 >>> cubes: 3\n",
      "PRE_PROCESS:::PIECE_0X3\n",
      "528 945\n",
      "File: TEAR_4X4_PIECE_0X3 >>> cubes: 4\n",
      "PRE_PROCESS:::PIECE_1X0\n",
      "522 1312\n",
      "File: TEAR_4X4_PIECE_1X0 >>> cubes: 4\n",
      "PRE_PROCESS:::PIECE_1X1\n",
      "539 1579\n",
      "File: TEAR_4X4_PIECE_1X1 >>> cubes: 3\n",
      "PRE_PROCESS:::PIECE_1X2\n",
      "525 1623\n",
      "File: TEAR_4X4_PIECE_1X2 >>> cubes: 4\n",
      "PRE_PROCESS:::PIECE_1X3\n",
      "533 1534\n",
      "File: TEAR_4X4_PIECE_1X3 >>> cubes: 3\n",
      "PRE_PROCESS:::PIECE_2X0\n",
      "549 1248\n",
      "File: TEAR_4X4_PIECE_2X0 >>> cubes: 4\n",
      "PRE_PROCESS:::PIECE_2X1\n",
      "525 1111\n",
      "File: TEAR_4X4_PIECE_2X1 >>> cubes: 3\n",
      "PRE_PROCESS:::PIECE_2X2\n",
      "573 1017\n",
      "File: TEAR_4X4_PIECE_2X2 >>> cubes: 4\n",
      "PRE_PROCESS:::PIECE_2X3\n",
      "481 1004\n",
      "File: TEAR_4X4_PIECE_2X3 >>> cubes: 2\n",
      "PRE_PROCESS:::PIECE_3X0\n",
      "574 1189\n",
      "File: TEAR_4X4_PIECE_3X0 >>> cubes: 4\n",
      "PRE_PROCESS:::PIECE_3X1\n",
      "524 1186\n",
      "File: TEAR_4X4_PIECE_3X1 >>> cubes: 4\n",
      "PRE_PROCESS:::PIECE_3X2\n",
      "512 1145\n",
      "File: TEAR_4X4_PIECE_3X2 >>> cubes: 4\n",
      "PRE_PROCESS:::PIECE_3X3\n",
      "516 1191\n",
      "File: TEAR_4X4_PIECE_3X3 >>> cubes: 4\n",
      "PRE_PROCESS:::TEAR_5X3\n",
      "937 685\n",
      "PRE_PROCESS:::PIECE_0X0\n",
      "728 1059\n",
      "File: TEAR_5X3_PIECE_0X0 >>> cubes: 3\n",
      "PRE_PROCESS:::PIECE_0X1\n",
      "667 999\n",
      "File: TEAR_5X3_PIECE_0X1 >>> cubes: 3\n",
      "PRE_PROCESS:::PIECE_0X2\n",
      "710 820\n",
      "File: TEAR_5X3_PIECE_0X2 >>> cubes: 4\n",
      "PRE_PROCESS:::PIECE_1X0\n",
      "700 948\n",
      "File: TEAR_5X3_PIECE_1X0 >>> cubes: 4\n",
      "PRE_PROCESS:::PIECE_1X1\n",
      "698 1021\n",
      "File: TEAR_5X3_PIECE_1X1 >>> cubes: 3\n",
      "PRE_PROCESS:::PIECE_1X2\n",
      "682 1047\n",
      "File: TEAR_5X3_PIECE_1X2 >>> cubes: 4\n",
      "PRE_PROCESS:::PIECE_2X0\n",
      "695 1065\n",
      "File: TEAR_5X3_PIECE_2X0 >>> cubes: 4\n",
      "PRE_PROCESS:::PIECE_2X1\n",
      "710 962\n",
      "File: TEAR_5X3_PIECE_2X1 >>> cubes: 4\n",
      "PRE_PROCESS:::PIECE_2X2\n",
      "705 972\n",
      "File: TEAR_5X3_PIECE_2X2 >>> cubes: 4\n",
      "PRE_PROCESS:::PIECE_3X0\n",
      "696 1126\n",
      "File: TEAR_5X3_PIECE_3X0 >>> cubes: 4\n",
      "PRE_PROCESS:::PIECE_3X1\n",
      "695 1375\n",
      "File: TEAR_5X3_PIECE_3X1 >>> cubes: 3\n",
      "PRE_PROCESS:::PIECE_3X2\n",
      "696 1348\n",
      "File: TEAR_5X3_PIECE_3X2 >>> cubes: 4\n",
      "PRE_PROCESS:::PIECE_4X0\n",
      "679 997\n",
      "File: TEAR_5X3_PIECE_4X0 >>> cubes: 4\n",
      "PRE_PROCESS:::PIECE_4X1\n",
      "754 969\n",
      "File: TEAR_5X3_PIECE_4X1 >>> cubes: 5\n",
      "PRE_PROCESS:::PIECE_4X2\n",
      "668 873\n",
      "File: TEAR_5X3_PIECE_4X2 >>> cubes: 4\n",
      "PRE_PROCESS:::TEAR_5X4\n",
      "937 514\n",
      "PRE_PROCESS:::PIECE_0X0\n",
      "513 876\n",
      "File: TEAR_5X4_PIECE_0X0 >>> cubes: 4\n",
      "PRE_PROCESS:::PIECE_0X1\n",
      "533 957\n",
      "File: TEAR_5X4_PIECE_0X1 >>> cubes: 3\n",
      "PRE_PROCESS:::PIECE_0X2\n",
      "558 887\n",
      "File: TEAR_5X4_PIECE_0X2 >>> cubes: 3\n",
      "PRE_PROCESS:::PIECE_0X3\n",
      "514 641\n",
      "File: TEAR_5X4_PIECE_0X3 >>> cubes: 4\n",
      "PRE_PROCESS:::PIECE_1X0\n",
      "524 1054\n",
      "File: TEAR_5X4_PIECE_1X0 >>> cubes: 4\n",
      "PRE_PROCESS:::PIECE_1X1\n",
      "525 1075\n",
      "File: TEAR_5X4_PIECE_1X1 >>> cubes: 4\n",
      "PRE_PROCESS:::PIECE_1X2\n",
      "534 1184\n",
      "File: TEAR_5X4_PIECE_1X2 >>> cubes: 4\n",
      "PRE_PROCESS:::PIECE_1X3\n",
      "513 1340\n",
      "File: TEAR_5X4_PIECE_1X3 >>> cubes: 2\n",
      "PRE_PROCESS:::PIECE_2X0\n",
      "521 964\n",
      "File: TEAR_5X4_PIECE_2X0 >>> cubes: 3\n",
      "PRE_PROCESS:::PIECE_2X1\n",
      "553 700\n",
      "File: TEAR_5X4_PIECE_2X1 >>> cubes: 4\n",
      "PRE_PROCESS:::PIECE_2X2\n",
      "535 758\n",
      "File: TEAR_5X4_PIECE_2X2 >>> cubes: 4\n",
      "PRE_PROCESS:::PIECE_2X3\n",
      "524 577\n",
      "File: TEAR_5X4_PIECE_2X3 >>> cubes: 3\n",
      "PRE_PROCESS:::PIECE_3X0\n",
      "529 1170\n",
      "File: TEAR_5X4_PIECE_3X0 >>> cubes: 4\n",
      "PRE_PROCESS:::PIECE_3X1\n",
      "528 1346\n",
      "File: TEAR_5X4_PIECE_3X1 >>> cubes: 4\n",
      "PRE_PROCESS:::PIECE_3X2\n",
      "529 1314\n",
      "File: TEAR_5X4_PIECE_3X2 >>> cubes: 4\n",
      "PRE_PROCESS:::PIECE_3X3\n",
      "527 1519\n",
      "File: TEAR_5X4_PIECE_3X3 >>> cubes: 4\n",
      "PRE_PROCESS:::PIECE_4X0\n",
      "505 958\n",
      "File: TEAR_5X4_PIECE_4X0 >>> cubes: 4\n",
      "PRE_PROCESS:::PIECE_4X1\n",
      "571 1023\n",
      "File: TEAR_5X4_PIECE_4X1 >>> cubes: 4\n",
      "PRE_PROCESS:::PIECE_4X2\n",
      "519 1062\n",
      "File: TEAR_5X4_PIECE_4X2 >>> cubes: 4\n",
      "PRE_PROCESS:::PIECE_4X3\n",
      "522 990\n",
      "File: TEAR_5X4_PIECE_4X3 >>> cubes: 4\n",
      "PRE_PROCESS:::TEAR_6X3\n",
      "781 685\n",
      "PRE_PROCESS:::PIECE_0X0\n",
      "708 806\n",
      "File: TEAR_6X3_PIECE_0X0 >>> cubes: 3\n",
      "PRE_PROCESS:::PIECE_0X1\n",
      "676 761\n",
      "File: TEAR_6X3_PIECE_0X1 >>> cubes: 2\n",
      "PRE_PROCESS:::PIECE_0X2\n",
      "673 409\n",
      "File: TEAR_6X3_PIECE_0X2 >>> cubes: 4\n",
      "PRE_PROCESS:::PIECE_1X0\n",
      "671 952\n",
      "File: TEAR_6X3_PIECE_1X0 >>> cubes: 4\n",
      "PRE_PROCESS:::PIECE_1X1\n",
      "762 1060\n",
      "File: TEAR_6X3_PIECE_1X1 >>> cubes: 4\n",
      "PRE_PROCESS:::PIECE_1X2\n",
      "679 1229\n",
      "File: TEAR_6X3_PIECE_1X2 >>> cubes: 3\n",
      "PRE_PROCESS:::PIECE_2X0\n",
      "695 808\n",
      "File: TEAR_6X3_PIECE_2X0 >>> cubes: 4\n",
      "PRE_PROCESS:::PIECE_2X1\n",
      "696 785\n",
      "File: TEAR_6X3_PIECE_2X1 >>> cubes: 4\n",
      "PRE_PROCESS:::PIECE_2X2\n",
      "707 773\n",
      "File: TEAR_6X3_PIECE_2X2 >>> cubes: 3\n",
      "PRE_PROCESS:::PIECE_3X0\n",
      "686 1025\n",
      "File: TEAR_6X3_PIECE_3X0 >>> cubes: 4\n",
      "PRE_PROCESS:::PIECE_3X1\n",
      "699 1025\n",
      "File: TEAR_6X3_PIECE_3X1 >>> cubes: 3\n",
      "PRE_PROCESS:::PIECE_3X2\n",
      "720 951\n",
      "File: TEAR_6X3_PIECE_3X2 >>> cubes: 4\n",
      "PRE_PROCESS:::PIECE_4X0\n",
      "691 810\n",
      "File: TEAR_6X3_PIECE_4X0 >>> cubes: 4\n",
      "PRE_PROCESS:::PIECE_4X1\n",
      "702 888\n",
      "File: TEAR_6X3_PIECE_4X1 >>> cubes: 4\n",
      "PRE_PROCESS:::PIECE_4X2\n",
      "709 943\n",
      "File: TEAR_6X3_PIECE_4X2 >>> cubes: 4\n",
      "PRE_PROCESS:::PIECE_5X0\n",
      "711 879\n",
      "File: TEAR_6X3_PIECE_5X0 >>> cubes: 4\n",
      "PRE_PROCESS:::PIECE_5X1\n",
      "688 959\n",
      "File: TEAR_6X3_PIECE_5X1 >>> cubes: 4\n",
      "PRE_PROCESS:::PIECE_5X2\n",
      "696 944\n",
      "File: TEAR_6X3_PIECE_5X2 >>> cubes: 4\n",
      "PRE_PROCESS:::TEAR_6X4\n",
      "781 514\n",
      "PRE_PROCESS:::PIECE_0X0\n",
      "507 696\n",
      "File: TEAR_6X4_PIECE_0X0 >>> cubes: 4\n",
      "PRE_PROCESS:::PIECE_0X1\n",
      "568 773\n",
      "File: TEAR_6X4_PIECE_0X1 >>> cubes: 2\n",
      "PRE_PROCESS:::PIECE_0X2\n",
      "553 785\n",
      "File: TEAR_6X4_PIECE_0X2 >>> cubes: 3\n",
      "PRE_PROCESS:::PIECE_0X3\n",
      "498 618\n",
      "File: TEAR_6X4_PIECE_0X3 >>> cubes: 2\n",
      "PRE_PROCESS:::PIECE_1X0\n",
      "529 989\n",
      "File: TEAR_6X4_PIECE_1X0 >>> cubes: 3\n",
      "PRE_PROCESS:::PIECE_1X1\n",
      "527 961\n",
      "File: TEAR_6X4_PIECE_1X1 >>> cubes: 4\n",
      "PRE_PROCESS:::PIECE_1X2\n",
      "550 871\n",
      "File: TEAR_6X4_PIECE_1X2 >>> cubes: 4\n",
      "PRE_PROCESS:::PIECE_1X3\n",
      "498 726\n",
      "File: TEAR_6X4_PIECE_1X3 >>> cubes: 1\n",
      "PRE_PROCESS:::PIECE_2X0\n",
      "523 869\n",
      "File: TEAR_6X4_PIECE_2X0 >>> cubes: 4\n",
      "PRE_PROCESS:::PIECE_2X1\n",
      "525 793\n",
      "File: TEAR_6X4_PIECE_2X1 >>> cubes: 4\n",
      "PRE_PROCESS:::PIECE_2X2\n",
      "551 927\n",
      "File: TEAR_6X4_PIECE_2X2 >>> cubes: 4\n",
      "PRE_PROCESS:::PIECE_2X3\n",
      "503 989\n",
      "File: TEAR_6X4_PIECE_2X3 >>> cubes: 4\n",
      "PRE_PROCESS:::PIECE_3X0\n",
      "518 962\n",
      "File: TEAR_6X4_PIECE_3X0 >>> cubes: 4\n",
      "PRE_PROCESS:::PIECE_3X1\n",
      "573 1091\n",
      "File: TEAR_6X4_PIECE_3X1 >>> cubes: 4\n",
      "PRE_PROCESS:::PIECE_3X2\n",
      "528 1099\n",
      "File: TEAR_6X4_PIECE_3X2 >>> cubes: 4\n",
      "PRE_PROCESS:::PIECE_3X3\n",
      "521 1057\n",
      "File: TEAR_6X4_PIECE_3X3 >>> cubes: 3\n",
      "PRE_PROCESS:::PIECE_4X0\n",
      "548 883\n",
      "File: TEAR_6X4_PIECE_4X0 >>> cubes: 4\n",
      "PRE_PROCESS:::PIECE_4X1\n",
      "524 723\n",
      "File: TEAR_6X4_PIECE_4X1 >>> cubes: 4\n",
      "PRE_PROCESS:::PIECE_4X2\n",
      "514 764\n",
      "File: TEAR_6X4_PIECE_4X2 >>> cubes: 4\n",
      "PRE_PROCESS:::PIECE_4X3\n",
      "509 987\n",
      "File: TEAR_6X4_PIECE_4X3 >>> cubes: 4\n",
      "PRE_PROCESS:::PIECE_5X0\n",
      "517 766\n",
      "File: TEAR_6X4_PIECE_5X0 >>> cubes: 4\n",
      "PRE_PROCESS:::PIECE_5X1\n",
      "535 730\n",
      "File: TEAR_6X4_PIECE_5X1 >>> cubes: 4\n",
      "PRE_PROCESS:::PIECE_5X2\n",
      "539 801\n",
      "File: TEAR_6X4_PIECE_5X2 >>> cubes: 4\n",
      "PRE_PROCESS:::PIECE_5X3\n",
      "501 593\n",
      "File: TEAR_6X4_PIECE_5X3 >>> cubes: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/il239838/anaconda/envs/tf_gpu/lib/python3.5/site-packages/tensorflow/python/util/tf_inspect.py:45: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  if d.decorator_argspec is not None), _inspect.getargspec(target))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#####################################################################\n",
      "TRAINING:\n",
      "MODEL:/Users/il239838/Downloads/private/Thesis/Papyrus/model_binary_new_X6/tear_model1.ckpt\n",
      "#####################################################################\n",
      "step 49, training accuracy 0.84\n",
      "step 99, training accuracy 0.94\n",
      "step 149, training accuracy 0.86\n",
      "step 199, training accuracy 0.92\n",
      "step 249, training accuracy 0.88\n",
      "step 299, training accuracy 0.92\n",
      "step 349, training accuracy 0.96\n",
      "step 399, training accuracy 0.96\n",
      "Optimization Finished!\n",
      "step 399, training accuracy 0.96\n",
      "Model saved in file: /Users/il239838/Downloads/private/Thesis/Papyrus/model_binary_new_X6/tear_model1.ckpt\n",
      "#####################################################################\n",
      "TRAINING ENDED\n",
      "#####################################################################\n",
      " \n",
      " \n"
     ]
    }
   ],
   "source": [
    "# RUN - take 1st large pieces and train on it\n",
    "cubes_set = pre_process_training(\"PX303/FG001/PX303-Fg001-V-C01-R01-D05032015-T112520-ML638__006.jpg\")\n",
    "train_imgs, train_lbls, train_x_delta, train_y_delta = \\\n",
    "    NEW_build_train_set_for_binary_labeling(cubes_set, CUBE_SIZE, ROOT_FOLDER + \"train_concats/\", 2)\n",
    "tf.reset_default_graph()\n",
    "model_tf(250)\n",
    "train(train_imgs, train_lbls, ROOT_FOLDER + \"model_binary_new_X6/tear_model1.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#####################################################################\n",
      "PRE_PROCESS:PX303/FG004/PX303-Fg004-V-C01-R01-D08032015-T110817-ML638__006.jpg\n",
      "#####################################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/il239838/anaconda/envs/tf_gpu/lib/python3.5/site-packages/PIL/Image.py:678: ResourceWarning: unclosed file <_io.BufferedReader name='/Users/il239838/Downloads/private/Thesis/Papyrus/PX303/FG004/PX303-Fg004-V-C01-R01-D08032015-T110817-ML638__006.jpg'>\n",
      "  self.load()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRE_PROCESS:::TEAR_4X3\n",
      "1571 1597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/il239838/anaconda/envs/tf_gpu/lib/python3.5/site-packages/skimage/util/dtype.py:110: UserWarning: Possible precision loss when converting from float64 to uint16\n",
      "  \"%s to %s\" % (dtypeobj_in, dtypeobj))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRE_PROCESS:::PIECE_0X0\n",
      "1601 1372\n",
      "File: TEAR_4X3_PIECE_0X0 >>> cubes: 9\n",
      "PRE_PROCESS:::PIECE_0X1\n",
      "1630 1357\n",
      "File: TEAR_4X3_PIECE_0X1 >>> cubes: 10\n",
      "PRE_PROCESS:::PIECE_0X2\n",
      "1609 1531\n",
      "File: TEAR_4X3_PIECE_0X2 >>> cubes: 8\n",
      "PRE_PROCESS:::PIECE_1X0\n",
      "1472 2180\n",
      "File: TEAR_4X3_PIECE_1X0 >>> cubes: 6\n",
      "PRE_PROCESS:::PIECE_1X1\n",
      "1662 2160\n",
      "File: TEAR_4X3_PIECE_1X1 >>> cubes: 9\n",
      "PRE_PROCESS:::PIECE_1X2\n",
      "1588 2206\n",
      "File: TEAR_4X3_PIECE_1X2 >>> cubes: 8\n",
      "PRE_PROCESS:::PIECE_2X0\n",
      "1498 1586\n",
      "File: TEAR_4X3_PIECE_2X0 >>> cubes: 7\n",
      "PRE_PROCESS:::PIECE_2X1\n",
      "1632 1594\n",
      "File: TEAR_4X3_PIECE_2X1 >>> cubes: 8\n",
      "PRE_PROCESS:::PIECE_2X2\n",
      "1579 1758\n",
      "File: TEAR_4X3_PIECE_2X2 >>> cubes: 8\n",
      "PRE_PROCESS:::PIECE_3X0\n",
      "1597 1730\n",
      "File: TEAR_4X3_PIECE_3X0 >>> cubes: 9\n",
      "PRE_PROCESS:::PIECE_3X1\n",
      "1623 1757\n",
      "File: TEAR_4X3_PIECE_3X1 >>> cubes: 11\n",
      "PRE_PROCESS:::PIECE_3X2\n",
      "1601 1751\n",
      "File: TEAR_4X3_PIECE_3X2 >>> cubes: 8\n",
      "PRE_PROCESS:::TEAR_4X4\n",
      "1571 1197\n",
      "PRE_PROCESS:::PIECE_0X0\n",
      "1199 1479\n",
      "File: TEAR_4X4_PIECE_0X0 >>> cubes: 7\n",
      "PRE_PROCESS:::PIECE_0X1\n",
      "1242 1599\n",
      "File: TEAR_4X4_PIECE_0X1 >>> cubes: 7\n",
      "PRE_PROCESS:::PIECE_0X2\n",
      "1207 1569\n",
      "File: TEAR_4X4_PIECE_0X2 >>> cubes: 7\n",
      "PRE_PROCESS:::PIECE_0X3\n",
      "1219 1686\n",
      "File: TEAR_4X4_PIECE_0X3 >>> cubes: 8\n",
      "PRE_PROCESS:::PIECE_1X0\n",
      "1066 1711\n",
      "File: TEAR_4X4_PIECE_1X0 >>> cubes: 4\n",
      "PRE_PROCESS:::PIECE_1X1\n",
      "1233 1669\n",
      "File: TEAR_4X4_PIECE_1X1 >>> cubes: 7\n",
      "PRE_PROCESS:::PIECE_1X2\n",
      "1242 1729\n",
      "File: TEAR_4X4_PIECE_1X2 >>> cubes: 2\n",
      "PRE_PROCESS:::PIECE_1X3\n",
      "1208 1743\n",
      "File: TEAR_4X4_PIECE_1X3 >>> cubes: 5\n",
      "PRE_PROCESS:::PIECE_2X0\n",
      "1129 1807\n",
      "File: TEAR_4X4_PIECE_2X0 >>> cubes: 6\n",
      "PRE_PROCESS:::PIECE_2X1\n",
      "1250 1826\n",
      "File: TEAR_4X4_PIECE_2X1 >>> cubes: 6\n",
      "PRE_PROCESS:::PIECE_2X2\n",
      "1205 1610\n",
      "File: TEAR_4X4_PIECE_2X2 >>> cubes: 8\n",
      "PRE_PROCESS:::PIECE_2X3\n",
      "1222 1497\n",
      "File: TEAR_4X4_PIECE_2X3 >>> cubes: 5\n",
      "PRE_PROCESS:::PIECE_3X0\n",
      "1222 1663\n",
      "File: TEAR_4X4_PIECE_3X0 >>> cubes: 7\n",
      "PRE_PROCESS:::PIECE_3X1\n",
      "1224 1754\n",
      "File: TEAR_4X4_PIECE_3X1 >>> cubes: 5\n",
      "PRE_PROCESS:::PIECE_3X2\n",
      "1221 1806\n",
      "File: TEAR_4X4_PIECE_3X2 >>> cubes: 8\n",
      "PRE_PROCESS:::PIECE_3X3\n",
      "1206 1944\n",
      "File: TEAR_4X4_PIECE_3X3 >>> cubes: 8\n",
      "PRE_PROCESS:::TEAR_5X3\n",
      "1257 1597\n",
      "PRE_PROCESS:::PIECE_0X0\n",
      "1619 1094\n",
      "File: TEAR_5X3_PIECE_0X0 >>> cubes: 11\n",
      "PRE_PROCESS:::PIECE_0X1\n",
      "1609 1067\n",
      "File: TEAR_5X3_PIECE_0X1 >>> cubes: 10\n",
      "PRE_PROCESS:::PIECE_0X2\n",
      "1604 988\n",
      "File: TEAR_5X3_PIECE_0X2 >>> cubes: 12\n",
      "PRE_PROCESS:::PIECE_1X0\n",
      "1282 1547\n",
      "File: TEAR_5X3_PIECE_1X0 >>> cubes: 8\n",
      "PRE_PROCESS:::PIECE_1X1\n",
      "1600 1640\n",
      "File: TEAR_5X3_PIECE_1X1 >>> cubes: 10\n",
      "PRE_PROCESS:::PIECE_1X2\n",
      "1587 1892\n",
      "File: TEAR_5X3_PIECE_1X2 >>> cubes: 10\n",
      "PRE_PROCESS:::PIECE_2X0\n",
      "1468 1503\n",
      "File: TEAR_5X3_PIECE_2X0 >>> cubes: 7\n",
      "PRE_PROCESS:::PIECE_2X1\n",
      "1597 1672\n",
      "File: TEAR_5X3_PIECE_2X1 >>> cubes: 9\n",
      "PRE_PROCESS:::PIECE_2X2\n",
      "1606 1683\n",
      "File: TEAR_5X3_PIECE_2X2 >>> cubes: 5\n",
      "PRE_PROCESS:::PIECE_3X0\n",
      "1577 1508\n",
      "File: TEAR_5X3_PIECE_3X0 >>> cubes: 9\n",
      "PRE_PROCESS:::PIECE_3X1\n",
      "1598 1481\n",
      "File: TEAR_5X3_PIECE_3X1 >>> cubes: 5\n",
      "PRE_PROCESS:::PIECE_3X2\n",
      "1611 1280\n",
      "File: TEAR_5X3_PIECE_3X2 >>> cubes: 7\n",
      "PRE_PROCESS:::PIECE_4X0\n",
      "1557 1261\n",
      "File: TEAR_5X3_PIECE_4X0 >>> cubes: 11\n",
      "PRE_PROCESS:::PIECE_4X1\n",
      "1674 1293\n",
      "File: TEAR_5X3_PIECE_4X1 >>> cubes: 10\n",
      "PRE_PROCESS:::PIECE_4X2\n",
      "1609 1344\n",
      "File: TEAR_5X3_PIECE_4X2 >>> cubes: 11\n",
      "PRE_PROCESS:::TEAR_5X4\n",
      "1257 1197\n",
      "PRE_PROCESS:::PIECE_0X0\n",
      "1212 1550\n",
      "File: TEAR_5X4_PIECE_0X0 >>> cubes: 7\n",
      "PRE_PROCESS:::PIECE_0X1\n",
      "1277 1867\n",
      "File: TEAR_5X4_PIECE_0X1 >>> cubes: 9\n",
      "PRE_PROCESS:::PIECE_0X2\n",
      "1197 1649\n",
      "File: TEAR_5X4_PIECE_0X2 >>> cubes: 7\n",
      "PRE_PROCESS:::PIECE_0X3\n",
      "1228 1492\n",
      "File: TEAR_5X4_PIECE_0X3 >>> cubes: 8\n",
      "PRE_PROCESS:::PIECE_1X0\n",
      "860 956\n",
      "File: TEAR_5X4_PIECE_1X0 >>> cubes: 3\n",
      "PRE_PROCESS:::PIECE_1X1\n",
      "1199 1321\n",
      "File: TEAR_5X4_PIECE_1X1 >>> cubes: 3\n",
      "PRE_PROCESS:::PIECE_1X2\n",
      "1193 1573\n",
      "File: TEAR_5X4_PIECE_1X2 >>> cubes: 4\n",
      "PRE_PROCESS:::PIECE_1X3\n",
      "1230 1628\n",
      "File: TEAR_5X4_PIECE_1X3 >>> cubes: 7\n",
      "PRE_PROCESS:::PIECE_2X0\n",
      "1097 1280\n",
      "File: TEAR_5X4_PIECE_2X0 >>> cubes: 5\n",
      "PRE_PROCESS:::PIECE_2X1\n",
      "1226 1574\n",
      "File: TEAR_5X4_PIECE_2X1 >>> cubes: 2\n",
      "PRE_PROCESS:::PIECE_2X2\n",
      "1197 969\n",
      "File: TEAR_5X4_PIECE_2X2 >>> cubes: 5\n",
      "PRE_PROCESS:::PIECE_2X3\n",
      "1209 1032\n",
      "File: TEAR_5X4_PIECE_2X3 >>> cubes: 5\n",
      "PRE_PROCESS:::PIECE_3X0\n",
      "1190 1668\n",
      "File: TEAR_5X4_PIECE_3X0 >>> cubes: 6\n",
      "PRE_PROCESS:::PIECE_3X1\n",
      "1239 1687\n",
      "File: TEAR_5X4_PIECE_3X1 >>> cubes: 5\n",
      "PRE_PROCESS:::PIECE_3X2\n",
      "1227 1341\n",
      "File: TEAR_5X4_PIECE_3X2 >>> cubes: 7\n",
      "PRE_PROCESS:::PIECE_3X3\n",
      "1197 1222\n",
      "File: TEAR_5X4_PIECE_3X3 >>> cubes: 8\n",
      "PRE_PROCESS:::PIECE_4X0\n",
      "1189 1287\n",
      "File: TEAR_5X4_PIECE_4X0 >>> cubes: 8\n",
      "PRE_PROCESS:::PIECE_4X1\n",
      "1239 1391\n",
      "File: TEAR_5X4_PIECE_4X1 >>> cubes: 6\n",
      "PRE_PROCESS:::PIECE_4X2\n",
      "1282 1431\n",
      "File: TEAR_5X4_PIECE_4X2 >>> cubes: 7\n",
      "PRE_PROCESS:::PIECE_4X3\n",
      "1192 1556\n",
      "File: TEAR_5X4_PIECE_4X3 >>> cubes: 7\n",
      "PRE_PROCESS:::TEAR_6X3\n",
      "1047 1597\n",
      "PRE_PROCESS:::PIECE_0X0\n",
      "1595 1082\n",
      "File: TEAR_6X3_PIECE_0X0 >>> cubes: 11\n",
      "PRE_PROCESS:::PIECE_0X1\n",
      "1600 967\n",
      "File: TEAR_6X3_PIECE_0X1 >>> cubes: 8\n",
      "PRE_PROCESS:::PIECE_0X2\n",
      "1616 707\n",
      "File: TEAR_6X3_PIECE_0X2 >>> cubes: 8\n",
      "PRE_PROCESS:::PIECE_1X0\n",
      "1362 1192\n",
      "File: TEAR_6X3_PIECE_1X0 >>> cubes: 7\n",
      "PRE_PROCESS:::PIECE_1X1\n",
      "1663 1703\n",
      "File: TEAR_6X3_PIECE_1X1 >>> cubes: 3\n",
      "PRE_PROCESS:::PIECE_1X2\n",
      "1588 2121\n",
      "File: TEAR_6X3_PIECE_1X2 >>> cubes: 7\n",
      "PRE_PROCESS:::PIECE_2X0\n",
      "1469 1047\n",
      "File: TEAR_6X3_PIECE_2X0 >>> cubes: 9\n",
      "PRE_PROCESS:::PIECE_2X1\n",
      "1575 948\n",
      "File: TEAR_6X3_PIECE_2X1 >>> cubes: 7\n",
      "PRE_PROCESS:::PIECE_2X2\n",
      "1599 832\n",
      "File: TEAR_6X3_PIECE_2X2 >>> cubes: 5\n",
      "PRE_PROCESS:::PIECE_3X0\n",
      "1480 1509\n",
      "File: TEAR_6X3_PIECE_3X0 >>> cubes: 5\n",
      "PRE_PROCESS:::PIECE_3X1\n",
      "1586 1729\n",
      "File: TEAR_6X3_PIECE_3X1 >>> cubes: 8\n",
      "PRE_PROCESS:::PIECE_3X2\n",
      "1635 1677\n",
      "File: TEAR_6X3_PIECE_3X2 >>> cubes: 6\n",
      "PRE_PROCESS:::PIECE_4X0\n",
      "1577 1179\n",
      "File: TEAR_6X3_PIECE_4X0 >>> cubes: 10\n",
      "PRE_PROCESS:::PIECE_4X1\n",
      "1597 1282\n",
      "File: TEAR_6X3_PIECE_4X1 >>> cubes: 8\n",
      "PRE_PROCESS:::PIECE_4X2\n",
      "1621 1487\n",
      "File: TEAR_6X3_PIECE_4X2 >>> cubes: 6\n",
      "PRE_PROCESS:::PIECE_5X0\n",
      "1607 1053\n",
      "File: TEAR_6X3_PIECE_5X0 >>> cubes: 12\n",
      "PRE_PROCESS:::PIECE_5X1\n",
      "1631 1002\n",
      "File: TEAR_6X3_PIECE_5X1 >>> cubes: 11\n",
      "PRE_PROCESS:::PIECE_5X2\n",
      "1602 981\n",
      "File: TEAR_6X3_PIECE_5X2 >>> cubes: 10\n",
      "PRE_PROCESS:::TEAR_6X4\n",
      "1047 1197\n",
      "PRE_PROCESS:::PIECE_0X0\n",
      "1190 1085\n",
      "File: TEAR_6X4_PIECE_0X0 >>> cubes: 7\n",
      "PRE_PROCESS:::PIECE_0X1\n",
      "1240 1120\n",
      "File: TEAR_6X4_PIECE_0X1 >>> cubes: 5\n",
      "PRE_PROCESS:::PIECE_0X2\n",
      "1217 902\n",
      "File: TEAR_6X4_PIECE_0X2 >>> cubes: 7\n",
      "PRE_PROCESS:::PIECE_0X3\n",
      "1207 1187\n",
      "File: TEAR_6X4_PIECE_0X3 >>> cubes: 7\n",
      "PRE_PROCESS:::PIECE_1X0\n",
      "968 1220\n",
      "File: TEAR_6X4_PIECE_1X0 >>> cubes: 4\n",
      "PRE_PROCESS:::PIECE_1X1\n",
      "1202 1238\n",
      "File: TEAR_6X4_PIECE_1X1 >>> cubes: 7\n",
      "PRE_PROCESS:::PIECE_1X2\n",
      "1228 1358\n",
      "File: TEAR_6X4_PIECE_1X2 >>> cubes: 5\n",
      "PRE_PROCESS:::PIECE_1X3\n",
      "1229 1373\n",
      "File: TEAR_6X4_PIECE_1X3 >>> cubes: 3\n",
      "PRE_PROCESS:::PIECE_2X0\n",
      "1054 1126\n",
      "File: TEAR_6X4_PIECE_2X0 >>> cubes: 7\n",
      "PRE_PROCESS:::PIECE_2X1\n",
      "1290 1377\n",
      "File: TEAR_6X4_PIECE_2X1 >>> cubes: 6\n",
      "PRE_PROCESS:::PIECE_2X2\n",
      "1195 1196\n",
      "File: TEAR_6X4_PIECE_2X2 >>> cubes: 6\n",
      "PRE_PROCESS:::PIECE_2X3\n",
      "1234 1211\n",
      "File: TEAR_6X4_PIECE_2X3 >>> cubes: 8\n",
      "PRE_PROCESS:::PIECE_3X0\n",
      "1026 1070\n",
      "File: TEAR_6X4_PIECE_3X0 >>> cubes: 7\n",
      "PRE_PROCESS:::PIECE_3X1\n",
      "1222 1133\n",
      "File: TEAR_6X4_PIECE_3X1 >>> cubes: 8\n",
      "PRE_PROCESS:::PIECE_3X2\n",
      "1188 1279\n",
      "File: TEAR_6X4_PIECE_3X2 >>> cubes: 6\n",
      "PRE_PROCESS:::PIECE_3X3\n",
      "1237 1222\n",
      "File: TEAR_6X4_PIECE_3X3 >>> cubes: 7\n",
      "PRE_PROCESS:::PIECE_4X0\n",
      "1190 1217\n",
      "File: TEAR_6X4_PIECE_4X0 >>> cubes: 5\n",
      "PRE_PROCESS:::PIECE_4X1\n",
      "1195 1143\n",
      "File: TEAR_6X4_PIECE_4X1 >>> cubes: 7\n",
      "PRE_PROCESS:::PIECE_4X2\n",
      "1216 1090\n",
      "File: TEAR_6X4_PIECE_4X2 >>> cubes: 8\n",
      "PRE_PROCESS:::PIECE_4X3\n",
      "1220 1240\n",
      "File: TEAR_6X4_PIECE_4X3 >>> cubes: 2\n",
      "PRE_PROCESS:::PIECE_5X0\n",
      "1194 1179\n",
      "File: TEAR_6X4_PIECE_5X0 >>> cubes: 7\n",
      "PRE_PROCESS:::PIECE_5X1\n",
      "1258 1226\n",
      "File: TEAR_6X4_PIECE_5X1 >>> cubes: 9\n",
      "PRE_PROCESS:::PIECE_5X2\n",
      "1228 1278\n",
      "File: TEAR_6X4_PIECE_5X2 >>> cubes: 7\n",
      "PRE_PROCESS:::PIECE_5X3\n",
      "1188 1439\n",
      "File: TEAR_6X4_PIECE_5X3 >>> cubes: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/il239838/anaconda/envs/tf_gpu/lib/python3.5/site-packages/tensorflow/python/util/tf_inspect.py:45: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  if d.decorator_argspec is not None), _inspect.getargspec(target))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#####################################################################\n",
      "TRAINING:\n",
      "MODEL:/Users/il239838/Downloads/private/Thesis/Papyrus/model_binary_new_X6/tear_model2.ckpt\n",
      "#####################################################################\n",
      "INFO:tensorflow:Restoring parameters from /Users/il239838/Downloads/private/Thesis/Papyrus/model_binary_new_X6/tear_model1.ckpt\n",
      "Model restored.\n",
      "step 49, training accuracy 0.88\n",
      "step 99, training accuracy 0.88\n",
      "step 149, training accuracy 0.88\n",
      "step 199, training accuracy 0.88\n",
      "step 249, training accuracy 0.92\n",
      "step 299, training accuracy 0.92\n",
      "step 349, training accuracy 0.86\n",
      "step 399, training accuracy 0.94\n",
      "Optimization Finished!\n",
      "step 399, training accuracy 0.94\n",
      "Model saved in file: /Users/il239838/Downloads/private/Thesis/Papyrus/model_binary_new_X6/tear_model2.ckpt\n",
      "#####################################################################\n",
      "TRAINING ENDED\n",
      "#####################################################################\n",
      " \n",
      " \n"
     ]
    }
   ],
   "source": [
    "# RUN - take 2nd large pieces and train on it\n",
    "\n",
    "cubes_set = pre_process_training(\"PX303/FG004/PX303-Fg004-V-C01-R01-D08032015-T110817-ML638__006.jpg\", 100, -1, 400, -1)\n",
    "train_imgs, train_lbls, train_x_delta, train_y_delta = \\\n",
    "    NEW_build_train_set_for_binary_labeling(cubes_set, CUBE_SIZE, ROOT_FOLDER + \"train_concats/\", 5)\n",
    "tf.reset_default_graph()\n",
    "model_tf(250)\n",
    "train(train_imgs, train_lbls, ROOT_FOLDER + \"model_binary_new_X6/tear_model2.ckpt\", ROOT_FOLDER + \"model_binary_new_X6/tear_model1.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# OPTIONAL RUN - take 3rd large pieces and train on it OR TEST in next block\n",
    "\n",
    "# cubes_set = pre_process_training(\"PX303/FG006/PX303-Fg006-V-C02-R02-D08032015-T115622-ML638__006.jpg\", 0, 6200, 0, 4400)\n",
    "# train_imgs, train_lbls, train_x_delta, train_y_delta = \\\n",
    "#     NEW_build_train_set_for_binary_labeling(cubes_set, CUBE_SIZE, ROOT_FOLDER + \"train_concats/\")\n",
    "# tf.reset_default_graph()\n",
    "# model_tf(250)    \n",
    "# train(train_imgs, train_lbls, ROOT_FOLDER + \"model_binary/tear_model3.ckpt\", ROOT_FOLDER + \"model_binary/tear_model2.ckpt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TEST - take 1 piece and cross- validate on this (uncomment all for full test run)\n",
    "cubes_set = pre_process_training(\"PX303/FG006/PX303-Fg006-V-C02-R02-D08032015-T115622-ML638__006.jpg\", 0, 6200, 0, 4400)\n",
    "train_imgs, train_lbls, train_x_delta, train_y_delta = \\\n",
    "    NEW_build_train_set_for_binary_labeling(cubes_set, CUBE_SIZE, ROOT_FOLDER + \"train_concats/\", 2)\n",
    "tf.reset_default_graph()\n",
    "model_tf(250)    \n",
    "validate2_for_cross_validation(train_imgs, train_lbls, ROOT_FOLDER + \"model_binary_new_X6/tear_model2.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### STOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43305"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "747"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cubes_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8367"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(x[1] == 1 for x in train_lbls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#####################################################################\n",
    "TRAINING:\n",
    "MODEL:/Users/il239838/Downloads/private/Thesis/Papyrus/model_binary_new_X6/tear_model1.ckpt\n",
    "#####################################################################\n",
    "step 49, training accuracy 0.78\n",
    "step 99, training accuracy 0.84\n",
    "step 149, training accuracy 0.9\n",
    "step 199, training accuracy 0.92\n",
    "step 249, training accuracy 0.88\n",
    "step 299, training accuracy 0.84\n",
    "step 349, training accuracy 0.92\n",
    "step 399, training accuracy 0.86\n",
    "Optimization Finished!\n",
    "step 399, training accuracy 0.86\n",
    "Model saved in file: /Users/il239838/Downloads/private/Thesis/Papyrus/model_binary_new_X6/tear_model1.ckpt\n",
    "#####################################################################\n",
    "TRAINING ENDED\n",
    "#####################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#####################################################################\n",
    "TRAINING:\n",
    "MODEL:/Users/il239838/Downloads/private/Thesis/Papyrus/model_binary_new_X6/tear_model2.ckpt\n",
    "#####################################################################\n",
    "INFO:tensorflow:Restoring parameters from /Users/il239838/Downloads/private/Thesis/Papyrus/model_binary_new_X6/tear_model1.ckpt\n",
    "Model restored.\n",
    "step 49, training accuracy 0.76\n",
    "step 99, training accuracy 0.82\n",
    "step 149, training accuracy 0.96\n",
    "step 199, training accuracy 0.86\n",
    "step 249, training accuracy 0.76\n",
    "step 299, training accuracy 0.82\n",
    "step 349, training accuracy 0.86\n",
    "step 399, training accuracy 0.88\n",
    "Optimization Finished!\n",
    "step 399, training accuracy 0.88\n",
    "Model saved in file: /Users/il239838/Downloads/private/Thesis/Papyrus/model_binary_new_X6/tear_model2.ckpt\n",
    "#####################################################################\n",
    "TRAINING ENDED\n",
    "#####################################################################\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#####################################################################\n",
    ">>> step 100\n",
    "step 0-99, precision 0.695652, recall 0.640000, f_score 0.666667\n",
    ">>> step 200\n",
    "step 100-199, precision 0.512500, recall 0.732143, f_score 0.602941\n",
    ">>> step 300\n",
    "step 200-299, precision 0.350427, recall 0.732143, f_score 0.473988\n",
    ">>> step 400\n",
    "step 300-399, precision 0.408805, recall 0.677083, f_score 0.509804\n",
    ">>> step 500\n",
    "step 400-499, precision 0.366834, recall 0.651786, f_score 0.469453\n",
    ">>> step 600\n",
    "step 500-599, precision 0.349282, recall 0.651786, f_score 0.454829\n",
    ">>> step 700\n",
    "step 600-699, precision 0.376471, recall 0.662069, f_score 0.480000\n",
    ">>> step 800\n",
    "step 700-799, precision 0.383142, recall 0.595238, f_score 0.466200\n",
    ">>> step 900\n",
    "step 800-899, precision 0.394649, recall 0.617801, f_score 0.481633\n",
    ">>> step 1000\n",
    "step 900-999, precision 0.407821, recall 0.651786, f_score 0.501718\n",
    ">>> step 1100\n",
    "step 1000-1099, precision 0.404432, recall 0.651786, f_score 0.499145\n",
    ">>> step 1200\n",
    "step 1100-1199, precision 0.423559, recall 0.657588, f_score 0.515244\n",
    ">>> step 1300\n",
    "step 1200-1299, precision 0.408983, recall 0.662835, f_score 0.505848\n",
    ">>> step 1400\n",
    "step 1300-1399, precision 0.405640, recall 0.667857, f_score 0.504723\n",
    ">>> step 1500\n",
    "step 1400-1499, precision 0.415020, recall 0.670927, f_score 0.512821\n",
    ">>> step 1600\n",
    "step 1500-1599, precision 0.402852, recall 0.672619, f_score 0.503902\n",
    ">>> step 1700\n",
    "step 1600-1699, precision 0.401681, recall 0.647696, f_score 0.495851\n",
    ">>> step 1800\n",
    "step 1700-1799, precision 0.387987, recall 0.647696, f_score 0.485279\n",
    ">>> step 1900\n",
    "step 1800-1899, precision 0.385484, recall 0.647696, f_score 0.483316\n",
    ">>> step 2000\n",
    "step 1900-1999, precision 0.388802, recall 0.647668, f_score 0.485909\n",
    ">>> step 2100\n",
    "step 2000-2099, precision 0.379161, recall 0.650124, f_score 0.478976\n",
    ">>> step 2200\n",
    "step 2100-2199, precision 0.374286, recall 0.650124, f_score 0.475068\n",
    ">>> step 2300\n",
    "step 2200-2299, precision 0.381868, recall 0.651054, f_score 0.481385\n",
    ">>> step 2400\n",
    "step 2300-2399, precision 0.392622, recall 0.659292, f_score 0.492155\n",
    ">>> step 2500\n",
    "step 2400-2499, precision 0.393604, recall 0.665281, f_score 0.494590\n",
    ">>> step 2600\n",
    "step 2500-2599, precision 0.392601, recall 0.664646, f_score 0.493623\n",
    ">>> step 2700\n",
    "step 2600-2699, precision 0.389810, recall 0.664646, f_score 0.491412\n",
    ">>> step 2800\n",
    "step 2700-2799, precision 0.384884, recall 0.655446, f_score 0.484982\n",
    ">>> step 2900\n",
    "step 2800-2899, precision 0.390572, recall 0.664122, f_score 0.491873\n",
    ">>> step 3000\n",
    "step 2900-2999, precision 0.401064, recall 0.679279, f_score 0.504348\n",
    ">>> step 3100\n",
    "step 3000-3099, precision 0.418534, recall 0.695431, f_score 0.522568\n",
    ">>> step 3200\n",
    "step 3100-3199, precision 0.430129, recall 0.704545, f_score 0.534154\n",
    ">>> step 3300\n",
    "step 3200-3299, precision 0.446036, recall 0.716258, f_score 0.549735\n",
    ">>> step 3400\n",
    "step 3300-3399, precision 0.448563, recall 0.722388, f_score 0.553459\n",
    ">>> step 3500\n",
    "step 3400-3499, precision 0.455204, recall 0.719599, f_score 0.557650\n",
    ">>> step 3600\n",
    "step 3500-3599, precision 0.456560, recall 0.718271, f_score 0.558266\n",
    ">>> step 3700\n",
    "step 3600-3699, precision 0.457841, recall 0.724000, f_score 0.560950\n",
    ">>> step 3800\n",
    "step 3700-3799, precision 0.455285, recall 0.720721, f_score 0.558047\n",
    ">>> step 3900\n",
    "step 3800-3899, precision 0.459969, recall 0.724351, f_score 0.562650\n",
    ">>> step 4000\n",
    "step 3900-3999, precision 0.445289, recall 0.724351, f_score 0.551529\n",
    ">>> step 4100\n",
    "step 4000-4099, precision 0.442598, recall 0.724351, f_score 0.549461\n",
    ">>> step 4200\n",
    "step 4100-4199, precision 0.445596, recall 0.725301, f_score 0.552040\n",
    ">>> step 4300\n",
    "step 4200-4299, precision 0.429793, recall 0.724760, f_score 0.539597\n",
    ">>> step 4400\n",
    "step 4300-4399, precision 0.426450, recall 0.724760, f_score 0.536955\n",
    ">>> step 4500\n",
    "step 4400-4499, precision 0.427491, recall 0.727485, f_score 0.538528\n",
    ">>> step 4600\n",
    "step 4500-4599, precision 0.427310, recall 0.723820, f_score 0.537377\n",
    ">>> step 4700\n",
    "step 4600-4699, precision 0.422999, recall 0.723820, f_score 0.533956\n",
    ">>> step 4800\n",
    "step 4700-4799, precision 0.419893, recall 0.723820, f_score 0.531474\n",
    ">>> step 4900\n",
    "step 4800-4899, precision 0.423740, recall 0.723669, f_score 0.534504\n",
    ">>> step 5000\n",
    "step 4900-4999, precision 0.428387, recall 0.725683, f_score 0.538742\n",
    ">>> step 5100\n",
    "step 5000-5099, precision 0.417348, recall 0.725683, f_score 0.529928\n",
    ">>> step 5200\n",
    "step 5100-5199, precision 0.414482, recall 0.725683, f_score 0.527612\n",
    ">>> step 5300\n",
    "step 5200-5299, precision 0.412935, recall 0.725683, f_score 0.526358\n",
    ">>> step 5400\n",
    "step 5300-5399, precision 0.418093, recall 0.720759, f_score 0.529207\n",
    ">>> step 5500\n",
    "step 5400-5499, precision 0.409934, recall 0.720294, f_score 0.522502\n",
    ">>> step 5600\n",
    "step 5500-5599, precision 0.409280, recall 0.719665, f_score 0.521805\n",
    ">>> step 5700\n",
    "step 5600-5699, precision 0.411176, recall 0.716189, f_score 0.522422\n",
    ">>> step 5800\n",
    "step 5700-5799, precision 0.413056, recall 0.707921, f_score 0.521707\n",
    ">>> step 5900\n",
    "step 5800-5899, precision 0.408427, recall 0.701061, f_score 0.516152\n",
    ">>> step 6000\n",
    "step 5900-5999, precision 0.404113, recall 0.701061, f_score 0.512694\n",
    ">>> step 6100\n",
    "step 6000-6099, precision 0.399565, recall 0.700382, f_score 0.508839\n",
    ">>> step 6200\n",
    "step 6100-6199, precision 0.398913, recall 0.700382, f_score 0.508310\n",
    ">>> step 6300\n",
    "step 6200-6299, precision 0.402681, recall 0.704503, f_score 0.512453\n",
    ">>> step 6400\n",
    "step 6300-6399, precision 0.404178, recall 0.709441, f_score 0.514970\n",
    ">>> step 6500\n",
    "step 6400-6499, precision 0.402955, recall 0.713255, f_score 0.514974\n",
    ">>> step 6600\n",
    "step 6500-6599, precision 0.402532, recall 0.713645, f_score 0.514730\n",
    ">>> step 6700\n",
    "step 6600-6699, precision 0.413011, recall 0.712585, f_score 0.522933\n",
    ">>> step 6800\n",
    "step 6700-6799, precision 0.416506, recall 0.713813, f_score 0.526059\n",
    ">>> step 6900\n",
    "step 6800-6899, precision 0.421002, recall 0.712439, f_score 0.529253\n",
    ">>> step 7000\n",
    "step 6900-6999, precision 0.428773, recall 0.709176, f_score 0.534427\n",
    ">>> step 7100\n",
    "step 7000-7099, precision 0.430497, recall 0.704718, f_score 0.534488\n",
    ">>> step 7200\n",
    "step 7100-7199, precision 0.437929, recall 0.695273, f_score 0.537381\n",
    ">>> step 7300\n",
    "step 7200-7299, precision 0.440254, recall 0.693133, f_score 0.538483\n",
    ">>> step 7400\n",
    "step 7300-7399, precision 0.441348, recall 0.690577, f_score 0.538525\n",
    ">>> step 7500\n",
    "step 7400-7499, precision 0.439821, recall 0.688375, f_score 0.536719\n",
    ">>> step 7600\n",
    "step 7500-7599, precision 0.440693, recall 0.683196, f_score 0.535782\n",
    ">>> step 7700\n",
    "step 7600-7699, precision 0.440618, recall 0.676152, f_score 0.533547\n",
    ">>> step 7800\n",
    "step 7700-7799, precision 0.435618, recall 0.676152, f_score 0.529865\n",
    ">>> step 7900\n",
    "step 7800-7899, precision 0.431701, recall 0.674044, f_score 0.526316\n",
    ">>> step 8000\n",
    "step 7900-7999, precision 0.429482, recall 0.668651, f_score 0.523021\n",
    ">>> step 8100\n",
    "step 8000-8099, precision 0.428027, recall 0.667768, f_score 0.521672\n",
    ">>> step 8200\n",
    "step 8100-8199, precision 0.429717, recall 0.664057, f_score 0.521784\n",
    ">>> step 8300\n",
    "step 8200-8299, precision 0.428451, recall 0.664057, f_score 0.520849\n",
    ">>> step 8400\n",
    "step 8300-8399, precision 0.429589, recall 0.660438, f_score 0.520569\n",
    ">>> step 8500\n",
    "step 8400-8499, precision 0.428870, recall 0.660438, f_score 0.520041\n",
    ">>> step 8600\n",
    "step 8500-8599, precision 0.427618, recall 0.660438, f_score 0.519119\n",
    ">>> step 8700\n",
    "step 8600-8699, precision 0.424528, recall 0.655478, f_score 0.515310\n",
    ">>> step 8800\n",
    "step 8700-8799, precision 0.421074, recall 0.655478, f_score 0.512757\n",
    ">>> step 8900\n",
    "step 8800-8899, precision 0.420032, recall 0.650814, f_score 0.510555\n",
    ">>> step 9000\n",
    "step 8900-8999, precision 0.415667, recall 0.650814, f_score 0.507317\n",
    ">>> step 9100\n",
    "step 9000-9099, precision 0.414201, recall 0.646154, f_score 0.504808\n",
    ">>> step 9200\n",
    "step 9100-9199, precision 0.414510, recall 0.642944, f_score 0.504053\n",
    ">>> step 9300\n",
    "step 9200-9299, precision 0.413793, recall 0.639138, f_score 0.502352\n",
    ">>> step 9400\n",
    "step 9300-9399, precision 0.408101, recall 0.639138, f_score 0.498134\n",
    ">>> step 9500\n",
    "step 9400-9499, precision 0.407789, recall 0.639138, f_score 0.497902\n",
    ">>> step 9600\n",
    "step 9500-9599, precision 0.408248, recall 0.639218, f_score 0.498268\n",
    ">>> step 9700\n",
    "step 9600-9699, precision 0.406097, recall 0.639218, f_score 0.496663\n",
    ">>> step 9800\n",
    "step 9700-9799, precision 0.408482, recall 0.639487, f_score 0.498524\n",
    ">>> step 9900\n",
    "step 9800-9899, precision 0.407298, recall 0.639098, f_score 0.497524\n",
    ">>> step 10000\n",
    "step 9900-9999, precision 0.406250, recall 0.639098, f_score 0.496741\n",
    ">>> step 10100\n",
    "step 10000-10099, precision 0.407407, recall 0.636312, f_score 0.496758\n",
    ">>> step 10200\n",
    "step 10100-10199, precision 0.408892, recall 0.636415, f_score 0.497892\n",
    ">>> step 10300\n",
    "step 10200-10299, precision 0.407852, recall 0.636415, f_score 0.497120\n",
    ">>> step 10400\n",
    "step 10300-10399, precision 0.408796, recall 0.637079, f_score 0.498024\n",
    ">>> step 10500\n",
    "step 10400-10499, precision 0.406452, recall 0.637079, f_score 0.496280\n",
    ">>> step 10600\n",
    "step 10500-10599, precision 0.405540, recall 0.637989, f_score 0.495875\n",
    ">>> step 10700\n",
    "step 10600-10699, precision 0.403583, recall 0.636918, f_score 0.494087\n",
    ">>> step 10800\n",
    "step 10700-10799, precision 0.401748, recall 0.636918, f_score 0.492710\n",
    ">>> step 10900\n",
    "step 10800-10899, precision 0.402490, recall 0.636066, f_score 0.493011\n",
    ">>> step 11000\n",
    "step 10900-10999, precision 0.400619, recall 0.633496, f_score 0.490836\n",
    ">>> step 11100\n",
    "step 11000-11099, precision 0.396798, recall 0.633496, f_score 0.487958\n",
    ">>> step 11200\n",
    "step 11100-11199, precision 0.396944, recall 0.629510, f_score 0.486880\n",
    ">>> step 11300\n",
    "step 11200-11299, precision 0.397928, recall 0.628496, f_score 0.487316\n",
    ">>> step 11400\n",
    "step 11300-11399, precision 0.398474, recall 0.625521, f_score 0.486826\n",
    ">>> step 11500\n",
    "step 11400-11499, precision 0.397233, recall 0.620690, f_score 0.484435\n",
    ">>> step 11600\n",
    "step 11500-11599, precision 0.396189, recall 0.620690, f_score 0.483658\n",
    ">>> step 11700\n",
    "step 11600-11699, precision 0.397906, recall 0.620725, f_score 0.484945\n",
    ">>> step 11800\n",
    "step 11700-11799, precision 0.397856, recall 0.618999, f_score 0.484381\n",
    ">>> step 11900\n",
    "step 11800-11899, precision 0.396184, recall 0.618999, f_score 0.483139\n",
    ">>> step 12000\n",
    "step 11900-11999, precision 0.394779, recall 0.618999, f_score 0.482094\n",
    ">>> step 12100\n",
    "step 12000-12099, precision 0.397894, recall 0.619473, f_score 0.484554\n",
    ">>> step 12200\n",
    "step 12100-12199, precision 0.402704, recall 0.621242, f_score 0.488652\n",
    ">>> step 12300\n",
    "step 12200-12299, precision 0.408271, recall 0.618464, f_score 0.491852\n",
    ">>> step 12400\n",
    "step 12300-12399, precision 0.411149, recall 0.615207, f_score 0.492893\n",
    ">>> step 12500\n",
    "step 12400-12499, precision 0.414962, recall 0.612991, f_score 0.494902\n",
    ">>> step 12600\n",
    "step 12500-12599, precision 0.416262, recall 0.606275, f_score 0.493614\n",
    ">>> step 12700\n",
    "step 12600-12699, precision 0.419520, recall 0.603456, f_score 0.494951\n",
    ">>> step 12800\n",
    "step 12700-12799, precision 0.418013, recall 0.603456, f_score 0.493901\n",
    ">>> step 12900\n",
    "step 12800-12899, precision 0.417014, recall 0.600943, f_score 0.492362\n",
    ">>> step 13000\n",
    "step 12900-12999, precision 0.412596, recall 0.600943, f_score 0.489269\n",
    ">>> step 13100\n",
    "step 13000-13099, precision 0.410480, recall 0.599745, f_score 0.487383\n",
    ">>> step 13200\n",
    "step 13100-13199, precision 0.408577, recall 0.599745, f_score 0.486039\n",
    ">>> step 13300\n",
    "step 13200-13299, precision 0.407397, recall 0.599745, f_score 0.485203\n",
    ">>> step 13400\n",
    "step 13300-13399, precision 0.406178, recall 0.599409, f_score 0.484228\n",
    ">>> step 13500\n",
    "step 13400-13499, precision 0.401925, recall 0.599409, f_score 0.481193\n",
    ">>> step 13600\n",
    "step 13500-13599, precision 0.401584, recall 0.599409, f_score 0.480948\n",
    ">>> step 13700\n",
    "step 13600-13699, precision 0.400391, recall 0.600335, f_score 0.480389\n",
    ">>> step 13800\n",
    "step 13700-13799, precision 0.399224, recall 0.598753, f_score 0.479042\n",
    ">>> step 13900\n",
    "step 13800-13899, precision 0.395553, recall 0.598919, f_score 0.476442\n",
    ">>> step 14000\n",
    "step 13900-13999, precision 0.393915, recall 0.598432, f_score 0.475098\n",
    ">>> step 14100\n",
    "step 14000-14099, precision 0.393915, recall 0.598432, f_score 0.475098\n",
    ">>> step 14200\n",
    "step 14100-14199, precision 0.392741, recall 0.598432, f_score 0.474244\n",
    ">>> step 14300\n",
    "step 14200-14299, precision 0.393562, recall 0.597536, f_score 0.474560\n",
    ">>> step 14400\n",
    "step 14300-14399, precision 0.390675, recall 0.594374, f_score 0.471463\n",
    ">>> step 14500\n",
    "step 14400-14499, precision 0.389944, recall 0.592924, f_score 0.470474\n",
    ">>> step 14600\n",
    "step 14500-14599, precision 0.386943, recall 0.592924, f_score 0.468283\n",
    ">>> step 14700\n",
    "step 14600-14699, precision 0.386532, recall 0.592924, f_score 0.467983\n",
    ">>> step 14800\n",
    "step 14700-14799, precision 0.387326, recall 0.595152, f_score 0.469258\n",
    ">>> step 14900\n",
    "step 14800-14899, precision 0.386903, recall 0.595343, f_score 0.469007\n",
    ">>> step 15000\n",
    "step 14900-14999, precision 0.388658, recall 0.595694, f_score 0.470403\n",
    ">>> step 15100\n",
    "step 15000-15099, precision 0.387264, recall 0.595304, f_score 0.469260\n",
    ">>> step 15200\n",
    "step 15100-15199, precision 0.386923, recall 0.596679, f_score 0.469435\n",
    ">>> step 15300\n",
    "step 15200-15299, precision 0.387583, recall 0.597950, f_score 0.470315\n",
    ">>> step 15400\n",
    "step 15300-15399, precision 0.384228, recall 0.599214, f_score 0.468222\n",
    ">>> step 15500\n",
    "step 15400-15499, precision 0.383070, recall 0.599214, f_score 0.467361\n",
    ">>> step 15600\n",
    "step 15500-15599, precision 0.384500, recall 0.599143, f_score 0.468403\n",
    ">>> step 15700\n",
    "step 15600-15699, precision 0.386607, recall 0.601239, f_score 0.470606\n",
    ">>> step 15800\n",
    "step 15700-15799, precision 0.382607, recall 0.601239, f_score 0.467630\n",
    ">>> step 15900\n",
    "step 15800-15899, precision 0.382626, recall 0.603309, f_score 0.468269\n",
    ">>> step 16000\n",
    "step 15900-15999, precision 0.383248, recall 0.603296, f_score 0.468731\n",
    ">>> step 16100\n",
    "step 16000-16099, precision 0.382317, recall 0.603296, f_score 0.468034\n",
    ">>> step 16200\n",
    "step 16100-16199, precision 0.381946, recall 0.603296, f_score 0.467756\n",
    ">>> step 16300\n",
    "step 16200-16299, precision 0.379460, recall 0.603296, f_score 0.465887\n",
    ">>> step 16400\n",
    "step 16300-16399, precision 0.382472, recall 0.604669, f_score 0.468563\n",
    ">>> step 16500\n",
    "step 16400-16499, precision 0.385124, recall 0.605644, f_score 0.470843\n",
    ">>> step 16600\n",
    "step 16500-16599, precision 0.386226, recall 0.609174, f_score 0.472732\n",
    ">>> step 16700\n",
    "step 16600-16699, precision 0.385509, recall 0.609174, f_score 0.472195\n",
    ">>> step 16800\n",
    "step 16700-16799, precision 0.387558, recall 0.609641, f_score 0.473870\n",
    ">>> step 16900\n",
    "step 16800-16899, precision 0.389587, recall 0.611689, f_score 0.476004\n",
    ">>> step 17000\n",
    "step 16900-16999, precision 0.392534, recall 0.612858, f_score 0.478555\n",
    ">>> step 17100\n",
    "step 17000-17099, precision 0.393763, recall 0.611711, f_score 0.479115\n",
    ">>> step 17200\n",
    "step 17100-17199, precision 0.392442, recall 0.611711, f_score 0.478136\n",
    ">>> step 17300\n",
    "step 17200-17299, precision 0.394895, recall 0.614296, f_score 0.480746\n",
    ">>> step 17400\n",
    "step 17300-17399, precision 0.397101, recall 0.616644, f_score 0.483100\n",
    ">>> step 17500\n",
    "step 17400-17499, precision 0.401132, recall 0.617085, f_score 0.486208\n",
    ">>> step 17600\n",
    "step 17500-17599, precision 0.399220, recall 0.617085, f_score 0.484801\n",
    ">>> step 17700\n",
    "step 17600-17699, precision 0.400259, recall 0.617539, f_score 0.485707\n",
    ">>> step 17800\n",
    "step 17700-17799, precision 0.402402, recall 0.618734, f_score 0.487653\n",
    ">>> step 17900\n",
    "step 17800-17899, precision 0.403036, recall 0.617830, f_score 0.487836\n",
    ">>> step 18000\n",
    "step 17900-17999, precision 0.404838, recall 0.618076, f_score 0.489231\n",
    ">>> step 18100\n",
    "step 18000-18099, precision 0.407634, recall 0.618758, f_score 0.491482\n",
    ">>> step 18200\n",
    "step 18100-18199, precision 0.406473, recall 0.618682, f_score 0.490614\n",
    ">>> step 18300\n",
    "step 18200-18299, precision 0.407004, recall 0.619139, f_score 0.491144\n",
    ">>> step 18400\n",
    "step 18300-18399, precision 0.406982, recall 0.619472, f_score 0.491232\n",
    ">>> step 18500\n",
    "step 18400-18499, precision 0.405737, recall 0.619093, f_score 0.490206\n",
    ">>> step 18600\n",
    "step 18500-18599, precision 0.404076, recall 0.620025, f_score 0.489282\n",
    ">>> step 18700\n",
    "step 18600-18699, precision 0.401760, recall 0.620025, f_score 0.487581\n",
    ">>> step 18800\n",
    "step 18700-18799, precision 0.399308, recall 0.620025, f_score 0.485771\n",
    ">>> step 18900\n",
    "step 18800-18899, precision 0.398062, recall 0.620321, f_score 0.484938\n",
    ">>> step 19000\n",
    "step 18900-18999, precision 0.396462, recall 0.620321, f_score 0.483748\n",
    ">>> step 19100\n",
    "step 19000-19099, precision 0.396994, recall 0.620614, f_score 0.484234\n",
    ">>> step 19200\n",
    "step 19100-19199, precision 0.395224, recall 0.620431, f_score 0.482859\n",
    ">>> step 19300\n",
    "step 19200-19299, precision 0.393585, recall 0.620281, f_score 0.481589\n",
    ">>> step 19400\n",
    "step 19300-19399, precision 0.393508, recall 0.620281, f_score 0.481531\n",
    ">>> step 19500\n",
    "step 19400-19499, precision 0.393243, recall 0.621160, f_score 0.481597\n",
    ">>> step 19600\n",
    "step 19500-19599, precision 0.392549, recall 0.621160, f_score 0.481077\n",
    ">>> step 19700\n",
    "step 19600-19699, precision 0.392088, recall 0.621160, f_score 0.480730\n",
    ">>> step 19800\n",
    "step 19700-19799, precision 0.391704, recall 0.621160, f_score 0.480442\n",
    ">>> step 19900\n",
    "step 19800-19899, precision 0.391016, recall 0.621160, f_score 0.479923\n",
    ">>> step 20000\n",
    "step 19900-19999, precision 0.390358, recall 0.620519, f_score 0.479236\n",
    ">>> step 20100\n",
    "step 20000-20099, precision 0.390504, recall 0.620764, f_score 0.479419\n",
    ">>> step 20200\n",
    "step 20100-20199, precision 0.386887, recall 0.621114, f_score 0.476787\n",
    ">>> step 20300\n",
    "step 20200-20299, precision 0.384308, recall 0.621114, f_score 0.474824\n",
    ">>> step 20400\n",
    "step 20300-20399, precision 0.384161, recall 0.621114, f_score 0.474712\n",
    ">>> step 20500\n",
    "step 20400-20499, precision 0.383577, recall 0.621114, f_score 0.474266\n",
    ">>> step 20600\n",
    "step 20500-20599, precision 0.383660, recall 0.622861, f_score 0.474837\n",
    ">>> step 20700\n",
    "step 20600-20699, precision 0.383569, recall 0.624886, f_score 0.475355\n",
    ">>> step 20800\n",
    "step 20700-20799, precision 0.382785, recall 0.624886, f_score 0.474752\n",
    ">>> step 20900\n",
    "step 20800-20899, precision 0.384644, recall 0.627704, f_score 0.476995\n",
    ">>> step 21000\n",
    "step 20900-20999, precision 0.383092, recall 0.627704, f_score 0.475800\n",
    ">>> step 21100\n",
    "step 21000-21099, precision 0.383464, recall 0.626977, f_score 0.475878\n",
    ">>> step 21200\n",
    "step 21100-21199, precision 0.383045, recall 0.626977, f_score 0.475555\n",
    ">>> step 21300\n",
    "step 21200-21299, precision 0.383430, recall 0.626852, f_score 0.475816\n",
    ">>> step 21400\n",
    "step 21300-21399, precision 0.384685, recall 0.628119, f_score 0.477146\n",
    ">>> step 21500\n",
    "step 21400-21499, precision 0.383581, recall 0.628119, f_score 0.476296\n",
    ">>> step 21600\n",
    "step 21500-21599, precision 0.384506, recall 0.629446, f_score 0.477391\n",
    ">>> step 21700\n",
    "step 21600-21699, precision 0.382462, recall 0.629446, f_score 0.475813\n",
    ">>> step 21800\n",
    "step 21700-21799, precision 0.382716, recall 0.628439, f_score 0.475721\n",
    ">>> step 21900\n",
    "step 21800-21899, precision 0.380835, recall 0.628439, f_score 0.474265\n",
    ">>> step 22000\n",
    "step 21900-21999, precision 0.380235, recall 0.628439, f_score 0.473799\n",
    ">>> step 22100\n",
    "step 22000-22099, precision 0.380420, recall 0.629084, f_score 0.474126\n",
    ">>> step 22200\n",
    "step 22100-22199, precision 0.378838, recall 0.629758, f_score 0.473086\n",
    ">>> step 22300\n",
    "step 22200-22299, precision 0.378196, recall 0.628481, f_score 0.472225\n",
    ">>> step 22400\n",
    "step 22300-22399, precision 0.377388, recall 0.627647, f_score 0.471359\n",
    ">>> step 22500\n",
    "step 22400-22499, precision 0.377378, recall 0.626815, f_score 0.471117\n",
    ">>> step 22600\n",
    "step 22500-22599, precision 0.377937, recall 0.628183, f_score 0.471939\n",
    ">>> step 22700\n",
    "step 22600-22699, precision 0.376335, recall 0.628183, f_score 0.470688\n",
    ">>> step 22800\n",
    "step 22700-22799, precision 0.376016, recall 0.628183, f_score 0.470439\n",
    ">>> step 22900\n",
    "step 22800-22899, precision 0.375968, recall 0.629473, f_score 0.470762\n",
    ">>> step 23000\n",
    "step 22900-22999, precision 0.375210, recall 0.629473, f_score 0.470167\n",
    ">>> step 23100\n",
    "step 23000-23099, precision 0.374708, recall 0.630191, f_score 0.469973\n",
    ">>> step 23200\n",
    "step 23100-23199, precision 0.376144, recall 0.631564, f_score 0.471484\n",
    ">>> step 23300\n",
    "step 23200-23299, precision 0.376630, recall 0.632834, f_score 0.472219\n",
    ">>> step 23400\n",
    "step 23300-23399, precision 0.375021, recall 0.632834, f_score 0.470952\n",
    ">>> step 23500\n",
    "step 23400-23499, precision 0.374286, recall 0.633527, f_score 0.470564\n",
    ">>> step 23600\n",
    "step 23500-23599, precision 0.374068, recall 0.634763, f_score 0.470732\n",
    ">>> step 23700\n",
    "step 23600-23699, precision 0.373814, recall 0.635494, f_score 0.470731\n",
    ">>> step 23800\n",
    "step 23700-23799, precision 0.372496, recall 0.635494, f_score 0.469685\n",
    ">>> step 23900\n",
    "step 23800-23899, precision 0.372906, recall 0.635918, f_score 0.470127\n",
    ">>> step 24000\n",
    "step 23900-23999, precision 0.372976, recall 0.634865, f_score 0.469894\n",
    ">>> step 24100\n",
    "step 24000-24099, precision 0.373713, recall 0.634750, f_score 0.470448\n",
    ">>> step 24200\n",
    "step 24100-24199, precision 0.373123, recall 0.634750, f_score 0.469979\n",
    ">>> step 24300\n",
    "step 24200-24299, precision 0.374528, recall 0.635369, f_score 0.471263\n",
    ">>> step 24400\n",
    "step 24300-24399, precision 0.374765, recall 0.635397, f_score 0.471458"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
